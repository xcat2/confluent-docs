{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#confluent","title":"Confluent","text":"<p>Confluent is a software package to handle essential bootstrap and operation of scale-out server configurations. It incorporates a variety of functions relevant to that end:</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Console Management<ul> <li>Arbitrate multi-user access</li> <li>Full logging with fine grained timestamps</li> <li>VT-aware buffering for quality reconstitution of a console after reconnect</li> </ul> </li> <li>Hardware Control: Essential operations using ipmi, redfish, and/or implementation specific plugins to implement features including:<ul> <li>Power on/off</li> <li>Set next boot device (e.g. force network boot)</li> <li>Configure BIOS/UEFI/BMC settings</li> <li>Configure hardware storage controllers (e.g. create/delete raid arrays and set drive usage)</li> <li>Health check</li> <li>Telemetry (temperature, voltages, power, energy, etc)</li> <li>Virtual USB device mount management</li> <li>Retrieve support data</li> </ul> </li> <li>OS Deployment including:<ul> <li>Stateless images and stateful OS deployment</li> <li>Sample profiles for ESXi 6.7/7.0, RedHat/CentOS/Alma/Rocky 7.x/8.x/9.x, SuSE 15.x, RHV-H 4.\u00be.4 and Ubuntu 20.04/22.04/24.04</li> <li>Deployment over PXE, HTTP(S)boot, or removable media (real or virtual)</li> <li>Does not require a DHCP server, nor does it conflict with an external DHCP server for all deployment methods</li> <li>Support customization during phases of deployment (e.g. post, firstboot, onboot) by local commands or automatically launched remote ansible playbooks.</li> </ul> </li> <li>Centralized access to network topology information<ul> <li>Access mac address table and lldp information across all switches in one interface</li> </ul> </li> <li>Rich device on-boarding capabilities<ul> <li>Detect generic PXE systems and Lenovo hardware management devices at a glance</li> <li>Rapidly onboard devices manually, based on data such as serial number or mac address, or based on where things are physically plugged in to chassis or switches.</li> </ul> </li> <li>Scalability and Availability<ul> <li>Powerful noderange syntax to describe target systems simply but with great flexibility</li> <li>An attribute database with group inheritance and formulaic attribute derivation for structured data-centers</li> <li>Collective mode enables scaling a single confluent interface across multiple servers or virtual machines for HA and/or to manage thousands of systems</li> <li>Tools to quickly analyze data and highlight inconsistencies or to do quick statistical analysis</li> </ul> </li> <li>Security<ul> <li>Designed with secure default behaviors with opt-in to reduced security</li> <li>Use of fully validated TLS to protect collective, deployment and hardware management</li> <li>Take advantage of TPM2 to protect boot volumes for supported profiles</li> <li>Use TPM2 to persist node trust across reboots in stateless environments</li> <li>Node authentication options to balance convenience versus hardening to protect potentially sensitive data such as encrypted root password</li> <li>SSH PKI strategy to securely enable convenient SSH without users having to self-curate SSH keys or having to update known_hosts</li> <li>SecureBoot is supported for media and HTTP boot methods</li> </ul> </li> <li>Flexible usage scenarios<ul> <li>Collection of straightforward Linux commands</li> <li>Command line API browser that is like browsing a file-system</li> <li>Python client library</li> <li>REST API over HTTP</li> </ul> </li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>Generally speaking, there are two suggested approaches:</p> <ul> <li>Using confluent - It is strongly recommended for most of those without existing xCAT installations to use confluent directly.</li> <li>Using xCAT and confluent together (not recommended) - When you are used to xCAT or another currently xCAT exclusive feature and want to use it in conjunction with confluent.  For this situation, start with the xCAT documentation under Advanced topics.</li> </ul> <p>Note</p> <p>For specific topics, it may be easier to use the Search function of this site.</p>"},{"location":"downloads/","title":"Downloads","text":"<p>Lenovo provides yum repositories of relevant software for managing HPC as well as scale out Linux installations in general.  This includes xCAT and confluent.</p>"},{"location":"downloads/#adding-repository-for-red-hat-enterprise-linux","title":"Adding Repository for Red Hat Enterprise Linux","text":"<p>Select the repository appropriate for the major version, for Red Hat Enterprise Linux 8:</p> <pre><code>rpm -ivh https://hpc.lenovo.com/yum/latest/el8/x86_64/lenovo-hpc-yum-1-1.x86_64.rpm\n</code></pre> <p>For Red Hat Enterprise Linux 9:</p> <pre><code>rpm -ivh https://hpc.lenovo.com/yum/latest/el9/x86_64/lenovo-hpc-yum-1-1.x86_64.rpm\n</code></pre> <p>On a new Minimal Install without Red Hat Subscription Manager configured. You will need additional packages from the install media.  Follow instuctions to add the install media as a repository on https://access.redhat.com/solutions/1355683. </p>"},{"location":"downloads/#adding-repository-for-ubuntu-linux","title":"Adding Repository for Ubuntu Linux","text":"<p>Download our gpg key:</p> <pre><code># wget -O /etc/apt/trusted.gpg.d/confluent.gpg https://hpc.lenovo.com/apt/latest/lenovo-hpc.key\n</code></pre> <p>Create the following apt configuration if running Ubuntu 24.04 (noble), substitute the distribution name for other editions (e.g. jammy instead of noble):</p> <pre><code>Types: deb\nURIs: https://hpc.lenovo.com/apt/latest/noble\nSuites: noble\nComponents: main\nSigned-By: /etc/apt/trusted.gpg.d/confluent.gpg\n</code></pre> <p>Then run <code>apt update</code> to pull the repository information.</p>"},{"location":"downloads/#adding-repository-for-suse-linux-enterprise-15","title":"Adding Repository for SuSE Linux Enterprise 15","text":"<pre><code>rpm --import https://hpc.lenovo.com/yum/latest/suse15/x86_64/lenovohpckey.pub\nzypper install https://hpc.lenovo.com/yum/latest/suse15/x86_64/lenovo-hpc-zypper-1-1.x86_64.rpm\n</code></pre>"},{"location":"downloads/#adding-local-repository","title":"Adding Local Repository","text":"<p>If you cannot reach the repository from your target system, you can download the package from a system that can reach https://hpc.lenovo.com/downloads/ and then transfer and install the repositories locally on your target system. </p> <p>The files may be browsed at https://hpc.lenovo.com/downloads/:</p> <pre><code>#On a system that can reach https://hpc.lenovo.com/downloads/\n#Download the package for your specific OS version\nwget https://hpc.lenovo.com/downloads/latest-el9.tar.xz\n#or\nwget https://hpc.lenovo.com/downloads/latest-el8.tar.xz\n#or\nwget https://hpc.lenovo.com/downloads/latest-suse15.tar.xz\n\n#On your local system \n#Create folder for the local repository\nmkdir /mnt/local_repo\n\n#Extract the repository \ntar -xf latest-el8.tar.xz -C /mnt/local_repo\n#or\ntar -xf latest-suse15.tar.xz -C /mnt/local_repo\n\n#Create lenovo-hpc.repo to point to the local repository\ncd /mnt/local_repo/lenovo-hpc-el8/\n#or\ncd /mnt/local_repo/lenovo-hpc-suse15/\n./mklocalrepo.sh\n</code></pre>"},{"location":"downloads/#further-information","title":"Further information","text":"<p>See the documentation for information on how to install and configure software provided in these repositories.</p> <p>Sources are available at https://hpc.lenovo.com/downloads/sources/</p>"},{"location":"advanced_topics/collective/","title":"Confluent collective mode","text":"<p>The collective mode of confluent allows multiple confluent servers to act as one, providing both high availability as well as scaling out to cover a larger number of servers with better performance.</p>"},{"location":"advanced_topics/collective/#shared-storage-considerations","title":"Shared storage considerations","text":"<p>For operating system deployment, it is expected that /var/lib/confluent be identical across all collective members.  This may through use of an NFS mount, clustered filesystem, or synchronized local filesystem content. Confluent has no particular requirements of how this is done, but does expect it to be identical if OS deploymennt features are used.</p>"},{"location":"advanced_topics/collective/#creating-a-collective","title":"Creating a collective","text":"<p>To begin, select a confluent server to begin constructing the collective from.  This page will use <code>mgt1</code> as the server to start from.  All other confluent servers will lose their configuration and the starting server configuration will replace it. On this server, generate an invitation for another server:</p> <pre><code>[root@mgt1 ~]# collective invite mgt2\nbWd0MkD/e95FBKP6NrBP4VSZFbZkwDmH5XqiIi8kpf3B0hGWuP6bfAcimUrs/7mKfI78+sGOHz7+YFg5zBm7Ubzzpx2j\n</code></pre> <p>On mgt2, use the data above to join the collective:</p> <pre><code>[root@mgt2 ~]# collective join mgt1 -i bWd0MkD/e95FBKP6NrBP4VSZFbZkwDmH5XqiIi8kpf3B0hGWuP6bfAcimUrs/7mKfI78+sGOHz7+YFg5zBm7Ubzzpx2j\nCertificate generated successfully\nSuccess\n</code></pre> <p>On any member, <code>collective show</code> will show current status of the collective:</p> <pre><code>[root@mgt2 ~]# collective show\nQuorum: True\nLeader: mgt1\nActive collective members:\n    mgt2\n</code></pre> <p>Note that a two server collective is actually not redundant, as a minimun of 3 servers is required for redundancy.  Any member of a collective can invite an additional member.  For example, extending the collective above to include mgt3 could be done from mgt1, but we will do it from mgt2 in this case:</p> <pre><code>[root@mgt2 ~]# collective invite mgt3\nbWd0M0Bur9G7oFs31jkHiNeFNIoMI7lz8O354e7OhJ5Scqq6goztkoZsSnThbNxih45c3UYs5vc33F1gJ8XX+9FJCw51\n\n[root@mgt3 ~]# collective join mgt2 -i bWd0M0Bur9G7oFs31jkHiNeFNIoMI7lz8O354e7OhJ5Scqq6goztkoZsSnThbNxih45c3UYs5vc33F1gJ8XX+9FJCw51\nCertificate generated successfully\nSuccess\n\n[root@mgt3 ~]# collective show\nQuorum: True\nLeader: mgt1\nActive collective members:\n    mgt2\n    mgt3\n</code></pre>"},{"location":"advanced_topics/collective/#os-deployment-considerations","title":"OS Deployment considerations","text":"<p>OS Deployment initialization (<code>osdeploy initialize</code>) operations must be done once per collective member to properly enable each member to provide deployment services to nodes.  For the SSH material (automation (-a) and CA (-s)), it is important to wait until after joining the collective to perform the operation.  If those steps were performed prior to joining collective, then follow the guidance in the osdeploy initialize output to delete the prior CA and automation keys, and then run osdeploy initialize -ask. Further, after adding a new collective member and performing collective initialize on the new host, run osdeploy initialize -k on all other hosts to trust the new collective member's SSH certificate authority.</p>"},{"location":"advanced_topics/collective/#managing-the-nodes-active-manager","title":"Managing the nodes' active manager","text":"<p>Once in a collective, each managed system must have a designated manager.  This can be changed on the fly.  If unspecified and a node goes through the discovery process, the member that performs the discovery claims the node by default. Additionally, automatic assignment in event of the collective.manager failing can be requested by setting <code>collective.managercandidates</code> which accepts a noderange of collective members to take over management in the case of the current manager going out.</p> <p>Here are examples of setting it for a node or a group.  Issuing the same commands with different collective.manager is all that is required to move a node.</p> <pre><code># nodeattrib n1 collective.manager=mgt1\n# nodegroupattrib rack1 collective.manager=mgt1\n</code></pre>"},{"location":"advanced_topics/collective/#restoring-a-missing-collective-member-by-repeating-the-invite-process","title":"Restoring a missing collective member by repeating the invite process","text":"<p>At any point, the invite process can be repeated for a member as if it were joining new, and it will replace the stale entry.</p>"},{"location":"advanced_topics/collective/#limitations","title":"Limitations","text":"<p>Note that currently most functions are enabled to be identical across a collective, however /networking and /discovery apis are currently distinct per collective member.  This means that nodediscover commands and automatic discovery activity must be directly managed on the respective collective member.</p> <p>Also note that all members of a collective must be running the same version of confluent and pyghmi.</p>"},{"location":"advanced_topics/confluentdiscoverysetting/","title":"Confluent Discovery/Autosense setting","text":"<p>Confluent has a setting called \"discovery/autosense\" which acts to enable or disable scanning network switches for MAC addresses, but also has the effect of enabling or disabling network booting of systems from Confluent. Having the setting disabled has the effect of preventing network booting of systems from Confluent (including for OS deployment), but will not affect systems booting from operating systems installed on local storage.</p> <p>If no network booting or node discovery using switch port information for node identification is required, disabling the setting can be done to improve the performance of Confluent.</p> <p>The setting must be defined for each Confluent management node, including all members of the collective if collective mode is in use.</p> <p>In order to view the current value of the setting for a particular Confluent management node, run the following command locally:</p> <pre><code># confetty show discovery/autosense\nenabled: True\n</code></pre> <p>In order to define the value of the setting for a particular Confluent management node, run the following command locally:</p> <pre><code># confetty set discovery/autosense enabled=False\n\n# confetty show discovery/autosense\nenabled: False\n</code></pre> <p>Note that the setting defaults to \"True\".</p>"},{"location":"advanced_topics/confluentenclosuredisco/","title":"Confluent discovery of Enclosure based systems","text":"<p>When discovering SD530 servers with an SMM, the enclosure may be used as an indication of how location based discovery should go.</p> <p>For the SD530, ensure that <code>enclosure.manager</code> indicates a node meant to represent the SMM in the chassis, and that <code>enclosure.bay</code>  is set to indicate the bay in the chassis. For example:</p> <pre><code># nodeattrib n1 enclosure.manager=smm1 enclosure.bay=1\n</code></pre> <p>As with all attributes, this may be set at group level using formulaic expansion to vary the values per node if desired.</p> <p>The SMM node could in turn have <code>net.switch</code> and <code>net.switchport</code> set according to its location if directly connected to switches:</p> <pre><code># nodeattrib smm1 net.switch=r4e1 net.switchport=35\n</code></pre> <p>For chained enclosures, for all enclosures not directly connected to the switch, use the <code>enclosure.extends</code> to indicate the next enclosure the SMM would need to use to reach the switch:</p> <pre><code># nodeattrib smm2 enclosure.extends=smm1\n# nodeattrib smm3 enclosure.extends=smm2\n</code></pre> <p>With that, discovery will proceed identically to the procedure in using switch based discovery</p>"},{"location":"advanced_topics/confluentlimitationsosdeploy/","title":"Limitations of usage of Confluent osdeploy initialize across multiple management nodes","text":"<p>The Confluent \"osdeploy initialize\" command provides assistance in setting up facilities relating to deployment and access of managed nodes from one or more management nodes. Setting up these facilities involve accessing one or more shared files.</p> <p>In order to prevent multiple simultaneous attempts to access the same files, any usage of the Confluent \"osdeploy initialize\" command should be limited to a single member of a Confluent collective at a time. Further, operations involving SSH should be performed after joining a collective (if done before joining a collective, follow the guidance in <code>osdeploy initiliaze -s</code> to delete the stale certificate authority.</p>"},{"location":"advanced_topics/confluentnodeassign/","title":"Manual discovery with nodediscover assign","text":"<p>Note that discovery in confluent is an optional process intended to aid with automatic gathering of mac addresses, configuring IP addresses and authentication of management controllers (e.g. xClarity Controller) when they may not have a viable or known IP address. If wanting to use confluent in an environment where the onboarding is otherwise handled, you may want to skip ahead to managing hardware using confluent.</p> <p>Once parameters have been configured such as desired username and password, discovery can be performed to push that configuration from the confluent configuration into the actual configuration on the devices.</p> <p>Confluent is capable of fully automated onboarding of equipment based on either ethernet switch or server enclosure. However, sometimes this would require things that are either not applicable, not known, or not allowed. In such circumstancecs, there are manual methods to aid in simplified onboarding kicked off by manual data despite those devices still not yet having viable configuration.</p>"},{"location":"advanced_topics/confluentnodeassign/#showing-currently-known-data","title":"Showing currently known data","text":"<p>By default confluent is always trying to passively gather data about a network. It is however prudent to request that confluent actively scan the environment to recognize new devices or update stale information.  If wanting to purge all data to ensure no stale data is visible, clearing the discovery information can be done by executing:</p> <pre><code># nodediscover clear\n</code></pre> <p>Asking for confluent to merge new devices and data with already detected information can be done with:</p> <pre><code># nodediscover rescan\n</code></pre> <p>In order to examine detected systems, <code>nodediscover</code> can provide a view of detected device information: <pre><code># nodediscover list -f node,model,serial,mac,type,ip\n Node|      Model|     Serial|               Mac|          Type|                                           IP\n-----|-----------|-----------|------------------|--------------|---------------------------------------------\n     | 7X2104Z023|   DVJJ9986| 08:94:ef:2f:2b:c7|    lenovo-xcc|                fe80::a94:efff:fe2f:2bc7%eth0\n     | 7X2106Z009|   DVJJ1086| 08:94:ef:2f:2e:9d|    lenovo-xcc|    172.30.66.1,fe80::a94:efff:fe2f:2e9d%eth0\n     | 7X2104Z000|   DVJJ1042| 08:94:ef:3f:e0:af|    lenovo-xcc|    172.30.66.3,fe80::a94:efff:fe3f:e0af%eth0\n     | 7X2104Z000|   DVJJ1003| 08:94:ef:40:89:31|    lenovo-xcc|                fe80::a94:efff:fe40:8931%eth0\n</code></pre> To start, we will just configure one of the systems. First we define a new node to the confluent configuration. This doesn't change anything and merely declares an intent to use a particular name:</p> <pre><code># nodedefine t1\n</code></pre> <p>Further attributes may be defined on this line, in this example we are taking advantage of group inheritance to provide all information about a node. See configuring confluent for more information on how to configure data such as username and password. With a node defined, we can associate a specific system with the system, using data such as serial number or mac address. Here we associate the serial number DVJJ1003 with the name t1:</p> <pre><code># nodediscover assign -s DVJJ1003 -n t1\nAssigned: t1\n</code></pre> <p>The specified node at this point can be managed by confluent.</p>"},{"location":"advanced_topics/confluentnodeassign/#bulk-manual-discovery","title":"Bulk manual discovery","text":"<p>The <code>nodediscover</code> command can accept a csv file of data and handle defining and associating devices. Here we will use nodediscover list to create a starting point:</p> <pre><code># nodediscover list -f serial,node -t lenovo-xcc -c &gt; nodes.csv\n</code></pre> <p>This will produce a CSV that appears as:</p> <pre><code>Serial,Node\nDVJJ9986,\nDVJJ1086,\nDVJJ1042,\nDVJJ1003,\n</code></pre> <p>We will manually fill in our desired node names, in this case we will just number them n1 through n4, top to bottom, and will use the address already detected to communicate with the systems:</p> <pre><code>Serial,Node\nDVJJ9986,n1\nDVJJ1086,n2\nDVJJ1042,n3\nDVJJ1003,n4\n</code></pre> <p>If also desiring to reconfigure networking as the procedure executes, then add a <code>bmc</code> column to the CSV to specify the desired IP (which need not be the same as the current IP address, the discovery process will change whatever the current IP is to the one specified in the file):</p> <pre><code>Serial,Node,bmc\nDVJJ9986,n1,172.30.170.1\nDVJJ1086,n2,172.30.170.2\nDVJJ1042,n3,172.30.170.3\nDVJJ1003,n4,172.30.170.4\n</code></pre> <p>Note that if you receive an error like <code>Nodename is a required field</code>, check for any completely blank lines, for example at the end of the file. Delete any such lines and try again.</p> <p>This file can be processed by nodediscover to associate all the serial numbers with node names:</p> <pre><code># nodediscover assign -i nodes.csv \nDefined n1\nDiscovered n1\nDefined n2\nDiscovered n2\nDefined n3\nDiscovered n3\nDefined n4\nDiscovered n4\n</code></pre> <p>Within a few moments of this output, it should be possible to move on to managing the devices using confluent</p>"},{"location":"advanced_topics/confluentosdeploy/","title":"Preparing for Operating System Deployment","text":"<p>If opting to use the confluent OS deployment mechanism, some additional preparation steps are suggested.</p> <p>Some node attributes that may be particularly relevant are:</p> <ul> <li><code>crypted.grubpassword</code> - By default, no boot loader password is used, specify one here to configure deployed OS to require a password to modify grub configuration.</li> <li><code>crypted.rootpassword</code> - By default, password based login as root is disabled in deployed operating systems. Set this to a desired value to enable password login. If this is not set, then there will be no way to log into the console of the target system by default. Note that some OSes default to blocking password from root on ssh by default, and confluent by default honors the OS choice on this matter.  See 'PermitRootLogin' in sshd_config.</li> <li><code>deployment.encryptboot</code> - Only supported for RHEL or CentOS 8.2 or higher with TPM 2.0. This will cause the boot volume to be encrypted. If the system board is replaced or the TPM2 is otherwise unavailable or cleared, then the contents of the disk will be lost.</li> <li><code>deployment.useinsecureprotocols</code> - To support PXE boot or HTTP boot without HTTPS, set this to <code>firmware</code>.</li> <li><code>dns.domain</code> - Set this to the appropriate DNS domain for search path. It may in some scenarios be omitted, but it is highly recommended to have a domain.</li> <li><code>dns.servers</code> - Set to IP addresses that will provide name resolution services, separated by commas if more than one specified.</li> <li><code>hardwaremanagement.port</code> - If needing to change the XCC (xClarity Controller) network port to be shared with an OCP card or onboard network, set to 'ocp' or 'lom' respectively. Ignore for using the dedicated management port or the SMM (System Management Module) in dense, enclosure hosted systems.  Also ignore if you do not use the <code>configbmc</code> script.</li> <li><code>hardwaremanagement.vlan</code> - If needing to set the XCC to be on a tagged vlan, set this to the desired VLAN. Ignore if using the native VLAN. Again, this only applies if you use the <code>configbmc</code> script.</li> <li><code>net.hostname</code> - If wanting to include other aliases for an interface to use to SSH in, use this attribute to indicate aliases other than the nodename itself, using commas as needed to indicate multiple values. This attribute is not needed if the node name is the only desired hostname. Note that this setting may be done for multiple interfaces, e.g. <code>net.compute.hostname={node}-compute</code>, <code>net.fabric.hostname={node}-ib</code>.  See Confluent multi interface configuration  for more details on configuring multiple interfaces.</li> <li><code>net.ipv4_gateway</code> - Set to the gateway IP for the deployed system to use.  This also supports the multiple interface scheme as mentioned above.</li> <li><code>net.ipv4_method</code> - This defaults to <code>static</code>, based on a name lookup of the node.  Use <code>firmwaredhcp</code> if there is an external DHCP server that serves addresses during PXE, but static is desired in the OS.  Set to <code>dhcp</code> to delegate OS addresses entirely to a DHCP server.  This also supports the multiple interface scheme as mentioned above.</li> <li><code>ntp.servers</code> - NTP servers to use by deployed operating system, separated by commas if more than one specified.</li> </ul> <p>A somewhat minimalist example would be:</p> <pre><code># nodegroupattrib everything deployment.useinsecureprotocols=firmware dns.domain=mycluster.example dns.servers=172.30.0.1 net.ipv4_gateway=17.30.0.254\n</code></pre> <p>Again, if root login by password is desired (if unspecified, only key based login over SSH will be allowed):</p> <pre><code># nodegroupattrib everything -p crypted.rootpassword\n</code></pre> <p>Keep in mind that the OS being deployed may prohibit ssh password login by root as a default, see <code>PermitRootLogin</code> in sshd_config for your distribution for more details.</p>"},{"location":"advanced_topics/confluentosdeploy/#ipv6-configuration","title":"IPv6 configuration","text":"<p>Deployment interfaces must have IPv6 enabled, with at least an automatic fe80:: address.  Generally this is default network interface configuration.  IPv6 need only be enabled, it need not be given any address manually, by DHCP, or by route advertisements, the automatic fe80:: addresses suffice.  Full IPv6 and IPv6 exclusive deployment is supported if desired, but even a \"pure\" IPv4 network will leverage the automatic IPv6 fe80:: for some key features.</p>"},{"location":"advanced_topics/confluentosdeploy/#name-resolution-optional","title":"Name resolution (optional)","text":"<p>An existing or otherwise manually configured DNS solution is fine for a confluent managed cluster. If such a solution is unavailable, this section provides a strategy to quickly generate IP addresses and use <code>dnsmasq</code> as a name server.</p> <p>The <code>confluent2hosts</code> command may be used to manage entries in an /etc/hosts file. This can use attribute expressions to help form entries for a range. Here is an example to generate 8 entries for nodes d1 through d8:</p> <pre><code># nodegroupattrib everything dns.domain=cluster.lan\n# confluent2hosts d1-d8 -i 172.30.100.{n1}\n# grep d5 /etc/hosts\n172.30.100.5                            d5 d5.cluster.lan\n</code></pre> <p>Additionally, confluent2hosts can use the <code>net.*</code> attributes to derive entries based on <code>net.*hostname</code>, <code>net.*ipv4_address</code>, and <code>net.*ipv6_address</code>.  Here is an example mixing and matching behaviors to address multiple names on multiple interfaces with ipv6 on one of the interfaces:</p> <pre><code># nodegroupattrib dense net.compute.ipv4_address=172.30.100.{n1} net.fabric.ipv4_address=172.20.100.{n1} net.fabric.hostname={node}-ib net.compute.ipv6_address=fd98:8741:ae09::{n1}\n# confluent2hosts d1-d8 -a\n# grep d5 /etc/hosts\n172.30.100.5                            d5 d5.cluster.lan\n172.20.100.5                            d5-ib d5-ib.cluster.lan\nfd98:8741:ae09::5                       d5 d5.cluster.lan\n</code></pre> <p>With an /etc/hosts appropriately generated, use the package management software to install dnsmasq and then:</p> <pre><code># systemctl enable dnsmasq --now\n</code></pre> <p>If /etc/hosts is updated, restart dnsmasq, as dnsmasq does not automatically update on update of /etc/hosts.</p>"},{"location":"advanced_topics/confluentosdeploy/#dhcp-optional","title":"DHCP (optional)","text":"<p>DHCP is not required or if present, may be externally managed.  Skip this section if either a DHCP server is already in place or if there is no requirement for a dynamic pool of DHCP addresses on the network.  Confluent will not require any DHCP dynamic range if one is not available.  However, if wanting to provide a dynamic DHCP range for various devices that may also exist on the network, <code>dnsmasq</code> can provide that functionality.  If using <code>dnsmasq</code> on the same system as confluent for DHCP function, add the following to /etc/dnsmasq.conf to allow both dnsmasq and confluent to share the network:</p> <pre><code>bind-dynamic\n</code></pre> <p>The following lines in /etc/dnsmasq.conf would provide a dynamic DHCP range:</p> <pre><code>dhcp-range=172.30.242.1,172.30.242.254\n</code></pre> <p>Avoid suggesting to dnsmasq any directives that would influence PXE boot. See the dnsmasq man page and other documentation for more details on use of dnsmasq.</p> <p>If using a dynamic range on a network, instruct confluent to use <code>firmwaredhcp</code> for deployment:</p> <pre><code># nodegroupattrib everything net.ipv4_method=firmwaredhcp\n</code></pre>"},{"location":"advanced_topics/confluentosdeploy/#having-a-genesis-network-boot-environment-optional","title":"Having a Genesis network boot environment (optional)","text":"<p>The 'genesis' image is a very small network booted linux environment for servicing/rescue.  When deployed, the node can run linux commands and can be sshed into as if it were a normal OS, but it won't touch any disks.</p> <p>In confluent, core discovery and functionality like in-band configuration of BMC devices no longer require a Genesis image.  However, one is available for use if desired.  Install the package <code>confluent-genesis-x86_64</code> if a genesis profile is desired.</p> <p><code>osdeploy initialize</code> (see next step) has an option to generate a genesis profile. Once used, a genesis based profile would be in /var/lib/confluent/public/os/genesis-x86_64/.  Of particular interest is the <code>/var/lib/confluent/public/os/gensis-x86_64/scripts/onboot.sh</code> file to govern automatic action, or use ssh after nodes boot to manually perform actions.</p>"},{"location":"advanced_topics/confluentosdeploy/#preparing-for-tftp-optional","title":"Preparing for TFTP (optional)","text":"<p>Note that confluent now supports both PXE and HTTP Boot. If using purely HTTP boot, then you do not need a tftp server at all. Additionally,  Secureboot is only fully supported with HTTP Boot. To support clients that are PXE booting, ensure that tftp is installed.  Note that xCAT may have already installed and configured tftp. Otherwise an example of installing tftp for RedHat or CentOS would be:</p> <pre><code># yum install tftp-server\n</code></pre> <p><code>osdeploy initialize</code> in an upcoming step will help initialize needed tftp content.</p>"},{"location":"advanced_topics/confluentosdeploy/#configuring-nodes-for-http-boot-optional","title":"Configuring nodes for HTTP Boot (optional)","text":"<p>If wanting to use HTTP Boot instead, here is an example to configure Lenovo systems to use HTTP instead of PXE boot:</p> <pre><code># nodeconfig d3-d6 NetworkStackSettings.IPv4PXESupport=disable NetworkStackSettings.IPv4HTTPSupport=enable\n</code></pre>"},{"location":"advanced_topics/confluentosdeploy/#initializing-os-deployment-configuration","title":"Initializing OS deployment configuration","text":"<p>The <code>osdeploy initialize</code> command is used to prepare a confluent server to deploy operating systems.  For first time setup, run osdeploy initialize interactively to be walked through the various options:</p> <pre><code># osdeploy initialize -i\n</code></pre> <p>Every option provides a command line flag to use instead of -i if wanting to run osdeploy initialize in a non-interactive fashion opting into the specified options.</p>"},{"location":"advanced_topics/confluentosdeploy/#importing-an-install-source-from-media","title":"Importing an install source from media","text":"<p>The <code>osdeploy import</code> is used to take recognized installation media and produce stock OS deployment profiles:</p> <pre><code># osdeploy import rhel-server-8.2-x86_64-dvd.iso \nImporting from /var/lib/confluent/iso/rhel-server-8.2-x86_64-dvd.iso to /var/lib/confluent/distributions/rhel-8.2-x86_64\ncomplete: 100.00%    \nDeployment profile created: rhel-8.2-x86_64-default\n</code></pre>"},{"location":"advanced_topics/confluentosdeploy/#customizing-or-copying-a-profile","title":"Customizing or copying a profile","text":"<p>A deployment profile is simply the collection of files in /var/lib/confluent/public/os/.  The stock profile may be edited in place, however to create a copy for customization, it is as straightforward as: <pre><code># cd /var/lib/confluent/public/os/\n# cp -a rhel-8.2-x86_64-default rhel-8.2-x86_64-custom\n# cd /var/lib/confluent/private/os/\n# cp -a rhel-8.2-x86_64-default rhel-8.2-x86_64-custom\n</code></pre> <p>For Ubuntu profiles, you also need to modify profile.yaml to update the profile name embedded in the kernel arguments, and then run <code>osdeploy updateboot newprofilenamehere</code>.</p> <p>Note that not all profiles contain private data, by default diskless images and captured clones have an encryption key in private, but scripted installs do not. Further note that a profile name may experience problems if the profile name is longer than 73 characters.</p> <p>If having a lot of shared content, it may be wise to employ symbolic links to explicitly share content rather than creating several copies of the same content (scripts or otherwise). It may also be a good idea to use git to manage and track changes as well.</p> <p>Labels and kernel arguments are in the profile.yaml file in the directory.  If modifying that file or kernel or initramfs content, the boot payloads of a profile can be updated with:</p> <pre><code># osdeploy updateboot rhel-8.2-x86_64-custom\n</code></pre> <p>A profile by default will use symbolic links for some content, but most smaller configuration and script files are simply copied and may be freely edited. Updates to confluent will not automatically replace any kickstart, autoyast, autoinstall, or script content in existing profiles without manual intervention.  It is recommended to examine and modify kickstart.custom in CentOS and RedHat profiles, to make decisions about default firewall and SELinux configuration on nodes.</p> <p>Any content in a profile can be freely edited without worry about an update later overwriting it.  However, if an update is performed and it is desired for a profile to merge in content from the package updates, <code>osdeploy rebase</code> can be used:</p> <pre><code># osdeploy rebase alma-8.7-x86_64-custom\nUpdated: scripts/confignet\nSkipping update of scripts/firstboot.sh as current copy was customized or no manifest data was available\n</code></pre>"},{"location":"advanced_topics/confluentosdeploy/#specifying-custom-postscripts-or-ansible-plays","title":"Specifying custom postscripts or ansible plays","text":"<p>A number of phases are opened up for injecting custom scripts or ansible plays.  Scripts are executed directly on the deployment server while ansible plays are executed by the deployment server targeting the deploying system as if it were specified as a host in the play.</p> <p>The <code>pre</code> phase occurs prior to any disk formatting or installation.  This is a good time to manage RAID configuration, override install disk autodection, specify non-default partition plan, extend package list or otherwise dynamically modify the scripted install file prior to installation.  To override install disk, write the desired target disk to /tmp/installdisk.  Override default partitioning by writing to /tmp/partitioning.</p> <p>The <code>post</code> phase occurs after the installation has written content to disk, but prior to actually booting into the installation.  This is generally the optimal place to make most on-disk changes to an installed system to ensure they are in effect from the onset. This phase will be followed by an outage as the system reboots into the installed system.</p> <p>The <code>firstboot</code> phase occurs after the installed system has booted into the target system, has brought up the network and has sshd running. This is useful for changes that may depend upon drivers that would not have been configured yet in the <code>post</code> phase or else must run when the system is effectively immediately ready to be put into use.</p> <p>The <code>onboot</code> phase is only for diskless boots, and behaves similarly to <code>firstboot</code>, but runs on every boot, since each diskless boot must start from scratch. Where possible, doing modifications to the image itself (e.g. using <code>imgutil exec</code>) is recommended to keep memory consumption down and boot time down.</p> <p>All content are simple files stored under the respective profile (/var/lib/confluent/public/os/[profile]). For scripted install profiles and cloning, scripts may be placed in scripts/pre.d, scripts/post.d, and scripts/firstboot.d. For diskless installs, scripts/onboot.d is available.  Note that content under /var/lib/confluent/public is considered non-sensitive and must not include any passwords, secret keys, or similarly sensitive information. See the document Handling of security information in OS deployment for guidance.</p> <p>Additionally check files like kickstart.custom in the top level directory for some suggested alterations.</p>"},{"location":"advanced_topics/confluentosdeploy/#handling-xclarity-controller-or-tsm-on-shared-ports-on-board-network-or-ocp","title":"Handling xClarity Controller or TSM on shared ports (on board network or OCP)","text":"<p>If wanting to move the xClarity Controller or TSM to be accessed over a port shared with the operating system, see either <code>pre.custom</code> of an install profile or <code>onboot.sh</code> of the genesis profile for examples of how to incorporate <code>configbmc</code> into a Genesis boot or an install. This will move the network port to allow out of band discovery to continue and set username and password remotely.</p>"},{"location":"advanced_topics/confluentosdeploy/#requesting-os-deployment","title":"Requesting os deployment","text":"<p>Even before discovery, nodedeploy is able to request that the next boot be into a profile:</p> <pre><code># nodedeploy &lt;nodes&gt; -p rhel-8.2-x86_64-default\n</code></pre> <p>After the xClarity Controller or equivalents are accesible, it can also initiate a boot to network (whether manually configured or if running this after discovery has been done):</p> <pre><code># nodedeploy &lt;nodes&gt; -n rhel-8.2-x86_64-default\n</code></pre>"},{"location":"advanced_topics/confluentosdeploy/#requesting-node-identifiers-from-nodeinventory","title":"Requesting node identifiers from nodeinventory","text":"<p>If discovery has been skipped and a BMC has been added manually, then the following command will populate attributes needed for deployment for most scenarios:</p> <pre><code># nodeinventory node -s\n</code></pre>"},{"location":"advanced_topics/confluentosdeploy/#manually-indicating-node-identifiers","title":"Manually indicating node identifiers","text":"<p>For many users, node identifiers will be automatically gathered by node discovery process.  However, the discovery process is optional, and if not wanting to use the process, or using servers that are not supported by the discovery process, then it is possible to feed the data into the requisite attributes rather than using a discovery process.  For a MAC address:</p> <pre><code># nodeattrib node net.hwaddr=00:01:02:03:04:05\n</code></pre> <p>Note that in discovery, we tend to prefer the UUID, as it makes the boot process the most adaptive for dealing with multi-nic booting with only a single identifier.  It's also more commonly available in nodeinventory across systems.  However, for certain non-Lenovo systems, the UUID may not be reliable and the MAC address can be used.  Also if MAC addresses are more familiar, they may be used.</p> <p>Alternatively, a system UUID may be used instead:</p> <pre><code># nodeattrib node id.uuid=c70998ec-0585-45da-85f0-f06717ec97e6\n</code></pre>"},{"location":"advanced_topics/confluentosdeploy/#next-steps","title":"Next steps","text":"<p>With OS deployment ready, depending on circumstances it may be appropriate to move on to:</p> <ul> <li>Deploying operating systems without disks: Using confluent diskless support</li> <li>Discovering rackmount systems with dedicated management port in use based on physical location: Using switch based discovery</li> <li>Discovering systems in server enclosures based on physical location: Using enclosure based discovery</li> <li>Discovering systems that have management port shared with the on board network or OCP add-on based on physical location: PXE driven discovery</li> <li>Using criteria such as mac address or serial number to manually discover or discover from spreadsheet: Using nodediscover assign</li> </ul>"},{"location":"advanced_topics/confluentosdeployment/","title":"Confluent OS Deployment and Syslog","text":"<p>Current and previous users of xCAT may be aware that xCAT configures syslog on deployed systems to do its logging on the xCAT management node instead of the default behavior of logging locally on each system.</p> <p>It should be noted that Confluent does NOT currently configure syslog in this fashion as part of its OS deployment of systems. Users wishing this functionality will need to configure it themselves, perhaps using the xCAT postscript <code>/install/postscripts/syslog</code> as an example.</p> <p>Confluent may add the syslog configuration feature in a future version.</p>"},{"location":"advanced_topics/confluentswitchdisco/","title":"Using switch based discovery","text":"<p>Confluent can identify unknown devices based on what network port they are connected to.</p>"},{"location":"advanced_topics/confluentswitchdisco/#snmp","title":"SNMP","text":"<p>For many industry switches, standard SNMP mibs are supported (QBRIDGE, BRIDGE, IF) to get the information.  If wanting to use SNMPv1/SNMPv2c, use the attribute 'secret.snmpcommunity' instead of <code>switchuser</code> and <code>switchpass</code> referenced below.</p>"},{"location":"advanced_topics/confluentswitchdisco/#cumulus","title":"Cumulus","text":"<p>For cumulus switches, install the affluent agent as documented in 'Using a Cumulus switch with confluent'</p>"},{"location":"advanced_topics/confluentswitchdisco/#adding-the-ethernet-switch","title":"Adding the ethernet switch","text":"<p>Adding an ethernet switch is done simply by adding the IP or a name that resolves to the switch:</p> <pre><code># nodedefine r4e1 type=switch\n</code></pre> <p>If the username and password are not inherited from a group like everything, be sure to set the username and password:</p> <pre><code># nodeattrib r4e1 -p switchuser switchpass\n</code></pre> <p>With the switch added, run:</p> <pre><code># nodediscover rescan\n</code></pre> <p>Watching <code>/var/log/confluent/events</code> should indicate any problems that may be encountered.</p> <p>With that, the <code>nodediscover</code> command now can present data about network connectivity:</p> <pre><code># nodediscover list -f model,serial,type,mac,switch,port -o port | grep -v lenovo-switch| head \n      Model|     Serial|          Type|               Mac| Switch|       Port\n-----------|-----------|--------------|------------------|-------|-----------\n    5466AC1|    DVJICDA|   lenovo-imm2| 40:f2:e9:75:1f:bd|   r4e1| Ethernet14\n    5463AC1|    DVJPDPM|   lenovo-imm2| 40:f2:e9:b9:10:1d|   r4e1| Ethernet17\n    5462AC1|    DVJ3821|   lenovo-imm2| 40:f2:e9:af:45:a5|   r4e1| Ethernet27\n 7Z01CTOLWW|   DVJ328J5|    lenovo-tsm| 3c:e1:a1:c7:ea:79|   r4e1| Ethernet29\n 7Y0XCTOLWW|   DVJJ3891|    lenovo-tsm| 3c:e1:a1:c7:e6:27|   r4e1| Ethernet32\n 7Y02CTOLWW|   DVJJ8699|    lenovo-xcc| 08:94:ef:49:c3:55|   r4e1| Ethernet34\n 7X21CTOLWW|   DVJJ1086|    lenovo-xcc| 08:94:ef:2f:2e:9d|   r4e1| Ethernet35\n</code></pre> <p>The data can be used to guide a manual discovery, but nodes may also be defined to automatically configure devices based on where they are plugged in. This can either be based on where the management controller is connected (recommended for situtions where a port dedicated to management is connected) or the port that the system will be used to execute a network boot (required for scenarios where the management controller will be shared with the operating system). If using the network boot port, then discovery is delayed until PXE boot is attempted. For example, here is a node that has a TSM connected to switch port 29 of a switch:</p> <pre><code># nodedefine example1 net.switch=r4e1 net.switchport=29 discovery.policy=permissive,pxe\nexample1: created\n# nodediscover rescan\nRescan complete\n</code></pre> <p>When specifying switches and net.switch value, ensure the attribute values match. Do not use IP in one place and a DNS name in the other, for example.</p> <p>Results can be seen by following <code>/var/log/confluent/events</code> or by watching <code>nodediscover list</code>:</p> <pre><code># grep example1 /var/log/confluent/events\nSep 02 13:53:51 {\"info\": \"Discovered example1 (TSM)\"}\n# nodediscover list -f node,model,serial,mac|egrep 'J100GZG5|Node|----'\n     Node|      Model|     Serial|               Mac\n---------|-----------|-----------|------------------\n example1| 7Z01CTO1WW|   J100GZG5| 3c:e1:a1:c7:ea:79\n</code></pre> <p>Once the node has reported as 'Discovered', commands may be run against the node:</p> <pre><code># nodehealth example1\nexample1: ok\n</code></pre> <p>To scale out such a strategy to a structured environment easily, it makes sense to take advantage of the group inheritance and formulaic expansion.  In this example, we will have a name scheme of r{rack}u{u in rack} and we will plug u1 into port 1, u 2 in port 2, and so on:</p> <pre><code># nodegroupdefine rackmount net.switch=r{n1}e1 net.switchport={n2}\n# nodedefine r4u29 groups=rackmount\n# nodeattrib r4u29 net.switch net.switchport --blame\nr4u29: net.switch: r4e1 (inherited from group rackmount, derived from expression \"r{n1}e1\")\nr4u29: net.switchport: 29 (inherited from group rackmount, derived from expression \"{n2}\")\n# nodediscover rescan\nRescan complete\n</code></pre> <p>As above, after some time the node may be seen in nodediscover list or <code>/var/log/confluent/events</code></p> <pre><code># nodediscover list -f node,model,serial,mac|egrep 'J100GZG5|Node|----'\n  Node|      Model|     Serial|               Mac\n------|-----------|-----------|------------------\n r4u29| 7Z01CTO1WW|   J100GZG5| 3c:e1:a1:c7:ea:79\n</code></pre>"},{"location":"advanced_topics/confluenttoxcat/","title":"Using confluent discovery to feed xCAT configuration","text":"<p>While xCAT has its own discovery mechanism, in some scenarios confluent discovery may be desirable in an otherwise xCAT environment.  For example, confluent does not require a dynamic range and does not require net-snmp-perl. Additionally, confluent supports standby power discovery in a number of scenarios, enabling management and console access prior to turning on the system.</p>"},{"location":"advanced_topics/confluenttoxcat/#preparing-for-pxe-mac-collection","title":"Preparing for PXE mac collection","text":"<p>In order to direct confluent to retain PXE mac addresses, simply set the <code>net.bootable</code> attribute to 1 and ensure that <code>discovery.policy</code> includes PXE:</p> <pre><code># nodegroupattrib everything discovery.policy=permissive,pxe net.bootable=1\n</code></pre>"},{"location":"advanced_topics/confluenttoxcat/#perform-normal-confluent-discovery","title":"Perform normal confluent discovery","text":"<p>Confluent discovery may be done against the BMC device or against PXE attempts. If using the network switch as a reference for discovery, be sure to use the dedicated management port switch and port for standby power discovery, and the network boot port switch and port if doing PXE. Detailed procedures on a few strategies for discovery are:</p> <ul> <li>Discovering systems attached to ethernet switches</li> <li>Discovering systems in enclosures</li> <li>Discovering systems manually</li> </ul>"},{"location":"advanced_topics/confluenttoxcat/#populating-xcat-with-node-information","title":"Populating xCAT with node information","text":"<p>Confluent has a command called <code>confluent2xcat</code> to export confluent data to xCAT. It can generate one of two files.</p> <p>In order to generate a 'stanza' format file for mkdef (pulling in confluent group membership and other information):</p> <pre><code># confluent2xcat d1-d8 -o nodes.stanza\n</code></pre> <p>In order to generate a CSV of node and mac addresses suitable for tabrestore mac:</p> <pre><code># confluent2xcat d1-d8 -m mac.csv\n</code></pre>"},{"location":"advanced_topics/driverupdatemedia/","title":"Using driver update media for RedHat/CentOS","text":"<p>Occasionally for network deployment of a RHEL or CentOS the modules included in the install initrd for the OS aren\u2019t sufficient to work with the network device being installed over (for example, if the network device is very new and the driver support hasn\u2019t been added to the OS yet).  In that scenario a driver update media package for that network device can be used to provide support for that network device during and after the OS installation.  In order to do that, the following should be done:</p> <ol> <li>The driver update media package will typically be provided as a <code>*.iso</code> file.  This need to be wrapped into a cpio file, which may be done as follows: <pre><code>    echo `&lt;driver update media package filename&gt;`.iso | cpio -H newc -o &gt; `&lt;driver update media package filename&gt;`.cpio\n</code></pre></li> <li>Place the driver update package cpio file into the OS profile being deployed, in the <code>boot/initramfs</code> directory: <pre><code>    cp `&lt;driver update media package filename&gt;`.cpio /var/lib/confluent/public/os/`&lt;OS profile name&gt;`/boot/initramfs\n</code></pre></li> <li>In the <code>profile.yaml</code> file in the <code>var/lib/confluent/public/os/&lt;OS profile name&gt;</code> directory, add the following to the kernelargs line: <pre><code>    inst.dd=/`&lt;driver update media package filename&gt;`.iso\n</code></pre></li> <li>Update the profile (this updates the boot.ipxe and boot.img contents with the driver update media package file and kernelargs updates): <pre><code>    osdeploy updateboot `&lt;OS profile name&gt;`\n</code></pre></li> </ol> <p>Preparing for Operating System Deployment</p>"},{"location":"advanced_topics/el7rste/","title":"Directing xCAT to install to the RSTe array","text":"<p>The disk to specify would be <code>/dev/md/Volume0_0</code>.  To do this in xCAT, create a file called  /install/custom/el7rste.partitions containing the following:</p> <pre><code>ignoredisk --only-use=/dev/md/Volume0_0\npart /boot/efi --size 50 --ondisk /dev/md/Volume0_0 --fstype efi\npart /boot --size 512 --fstype xfs --ondisk /dev/md/Volume0_0\npart swap --recommended --ondisk /dev/md/Volume0_0\npart pv.01 --size 1 --grow --ondisk /dev/md/Volume0_0\nvolgroup system pv.01\nlogvol / --vgname=system --name=root --size 1 --grow --fstype xfs\nbootloader  --boot-drive=Volume0_0\n</code></pre> <p>Modify the osimage to use this file, for example:</p> <pre><code> chdef -t osimage centos7.5-x86_64-install-compute partitionfile=/install/custom/el7rste.partitions\n</code></pre> <p>Future nodeset commands will target the RSTe volume.</p>"},{"location":"advanced_topics/el7rste/#adding-support-to-74-not-needed-for-75-or-newer","title":"Adding support to 7.4 (not needed for 7.5 or newer)","text":"<p>EL 7.5 and newer include support, for 7.4 it is required to download the RSTe software from Lenovo support site</p> <p>Then, extract the archive to get the install iso:</p> <pre><code>$ tar xf intc-lnvgy_dd_iastor_rste5.3-693_linux_x86_64.tgz\n</code></pre> <p>Then extract updates.img from the iso.  You could loop mount or use isoinfo to extract:</p> <pre><code>$ isoinfo -i intc-lnvgy_dd_iastor_5.3-693_linux_x86_64/rste-5.3_rhel7.4.iso -R -x /updates.img &gt; /install/rste.img\n</code></pre> <p>Set bootparams.addkcmdline to pull in the given update:</p> <pre><code>$ nodegrpch rste bootparams.addkcmdline=\" updates=http://&lt;xcatmgt.name&gt;/install/rste.img\"\n</code></pre> <p>From this point forward, any members of the rste group will pull in the RSTe software on install.</p>"},{"location":"advanced_topics/installxcat_rhel/","title":"xCAT Installation for Red Hat Enterprise Linux 7","text":"<p>After adding the correct repository as indicated in the download page, you can install xCAT by running:</p> <pre><code>yum install xCAT\n</code></pre> <p>It is strongly recommended to also install lenovo-onecli:</p> <pre><code>yum install lenovo-onecli\n</code></pre> <p>The default assures ability to use a local SQLite database.  If you want to use PostgreSQL you will also need:</p> <pre><code>yum install perl-DBD-Pg\n</code></pre> <p>If you wish to use MySQL instead, then:</p> <pre><code>yum install perl-DBD-MySQL\n</code></pre> <p>To verify that you have installed xCAT</p> <pre><code>service xcatd status\n</code></pre> <p>At this point, source the script below for xCAT command line functionality or logout and log back in. </p> <pre><code>source /etc/profile.d/xcat.sh\n</code></pre> <p>For some notes on configuring certain Lenovo equipment in xCAT, see xCAT configuration notes</p> <p>For more information on installing xCAT, go to xCAT Install Guide</p> <p>To continue to install confluent go to install confluent</p>"},{"location":"advanced_topics/installxcat_suse/","title":"xCAT Installation for SUSE Linux Enterprise","text":"<p>Note that for SUSE Linux Enterprise 15, the HA module is required to be available for xCAT install to succeed.</p> <p>After adding the correct repository as indicated in the download page, you can install xCAT by running:</p> <pre><code>zypper install xCAT\n</code></pre> <p>It is strongly recommended to also install lenovo-onecli:</p> <pre><code>zypper install lenovo-onecli\n</code></pre> <p>The default assures ability to use a local SQLite database.  If you want to use PostgreSQL you will also need:</p> <pre><code>zypper install perl-DBD-Pg\n</code></pre> <p>If you wish to use MySQL instead, then:</p> <pre><code>zypper install perl-DBD-MySQL\n</code></pre> <p>To verify that you have installed xCAT</p> <pre><code>service xcatd status\n</code></pre> <p>At this point, source the script below for xCAT command line functionality or logout and log back in. </p> <pre><code>source /etc/profile.d/xcat.sh\n</code></pre> <p>For some notes on configuring certain Lenovo equipment in xCAT, see xCAT configuration notes</p> <p>For more information on installing xCAT, go to xCAT Install Guide</p> <p>To continue to install confluent go to install confluent</p>"},{"location":"advanced_topics/nodemedia_caveats/","title":"nodemedia caveats","text":"<p>When using the \"redfish\" hardware management method, the nodemedia attach function doesn't work with HTTPS or NFS when using the Lenovo XCC service processor.  To use these protocols with the Lenovo XCC service processor, use the IPMI hardware management method.  Alternatively, the HTTP protocol can be used with the redfish hardware management method as well.</p>"},{"location":"advanced_topics/remoteconfluent/","title":"Remote confluent","text":"<p>Note this method for xCAT usage is largely superseded by using a collective instead, and using nodeconsole rather than rcons. There remain scenarios however where remote access is expected.</p> <p>Confluent CLI access is normally local, after using SSH to access a management node. However, it also supports remote access, and this is a key functionality when used in conjunction with xCAT in a service node setup.</p> <p>First, on every confluent server you want to access, a user must be created, using the same procedure as creating a user for the Web API:</p> <pre><code>useradd demouser\npasswd demouser\nconfetty create /users/demouser role=admin\n</code></pre> <p>Additionally, a TLS certificate must be provided, with the private key in /etc/confluent/privkey.pem and the certificate in /etc/confluent/srvcert.pem.  You can generate such certificates using the collective command:</p> <pre><code>collective gencert\n</code></pre> <p>At this point, xCAT's rcons will take care of connecting to the correct server.  However, it will prompt for your confluent user and passphrase each time.  The user and password may alternatively be provided via environment variables:</p> <pre><code>CONFLUENT_USER=demouser\nCONFLUENT_PASSPHRASE=\"password\"\nexport CONFLUENT_USER CONFLUENT_PASSPHRASE\n</code></pre> <p>Additionally, while rcons automatically connects to the relevant confluent server, other confluent commands currently do not get automatically routed.  If you want to run a confluent command such as nodepower explicitly against another host, this can be done by setting the CONFLUENT_HOST variable:</p> <pre><code>CONFLUENT_HOST=10.1.0.1\nexport CONFLUENT_HOST\n</code></pre>"},{"location":"advanced_topics/rh8installib/","title":"Installing EL8 over InfiniBand","text":"<p>This covers the process of EL8 deployment on a cluster using only InfiniBand.</p>"},{"location":"advanced_topics/rh8installib/#pre-requisites-for-infiniband-install","title":"Pre-requisites for InfiniBand install","text":"<p>Confluent &gt;= 2.4.0</p> <p>xCAT &gt;= 2.14.6.lenovo3</p>"},{"location":"advanced_topics/rh8installib/#preparing-for-infiniband-install","title":"Preparing for InfiniBand install","text":"<p>It is recommended to make groups to describe the required changes.  For example, this document will assume an 'ib' group.</p>"},{"location":"advanced_topics/rh8installib/#setting-static-address-mode","title":"Setting static address mode","text":"<p>InfiniBand deployment is only supported in static mode.  Use the following command to have xCAT do static addressing:</p> <p># chtab key=managedaddressmode site.value=static</p>"},{"location":"advanced_topics/rh8installib/#put-mellanox-ofed-driver-update-media-in-place","title":"Put Mellanox OFED Driver update media in place","text":"<p>EL 8 does not include the required mlx5_ib and ib_ipoib kernel modules in the OS installation initrd.  To make these drivers available during boot obtain the Mellanox OFED Driver update media for RHEL/CentOS 8 from here:</p> <p>https://support.lenovo.com/eg/en/solutions/ht509709</p> <p>This file should be placed in the EL 8 (RHEL or CentOS) driverdisk directory, e.g.:</p> <pre><code>mn10:~ # ls -ltcr /install/driverdisk/rhels8/x86_64\ntotal 33268\n-rw-r--r-- 1 root root 34023424 Dec 15 18:56 dd-rhel8.0-mlnx-ofed-4.7-1.0.0.1-x86_64.iso\n</code></pre>"},{"location":"advanced_topics/rh8installib/#net-config-fixup-postscript","title":"Net config fixup postscript","text":"<p>InfiniBand network configuration does not work as expected out of the box.  If not installing Mellanox OFED, the following is an example of a postscript that can be added to correct that behavior:</p> <pre><code># cat /install/postscripts/fixipoib\necho 'install mlx5_core /sbin/modprobe --ignore-install mlx5_core; /sbin/modprobe mlx5_ib; /sbin/modprobe ib_ipoib' &gt;&gt; /etc/modprobe.d/mlx.conf\necho 'add_drivers+=\"mlx5_ib ib_ipoib\"' &gt; /etc/dracut.conf.d/mlx.conf\ndracut -f\nrm /etc/sysconfig/network-scripts/ifcfg-ib0\nsed -i 's/ONBOOT=no/ONBOOT=yes/' /etc/sysconfig/network-scripts/ifcfg-ib0-1\nmv /etc/sysconfig/network-scripts/ifcfg-ib0-1 /etc/sysconfig/network-scripts/ifcfg-ib0\n</code></pre>"},{"location":"advanced_topics/rh8installib/#xcat-configuration","title":"xCAT configuration","text":"<p>Define the ib group to have the required install argument changes, interface name, and to invoke the postscript shown above:</p> <pre><code># nodegrpch ib bootparams.addkcmdline=\"rd.driver.pre=mlx5_ib,ib_ipoib rd.net.timeout.carrier=80 rd.bootif=0\" noderes.primarynic=ib0 postscripts.postscripts=fixipoib\n</code></pre>"},{"location":"advanced_topics/rh8installib/#confluent-configuration","title":"confluent configuration","text":"<p>xCAT does not understand how to collect addresses for InfiniBand.  Instead, enable confluent collection of the InfinBand addresses:</p> <pre><code># nodegroupdefine ib net.ib.bootable=1 discovery.policy=permissive,pxe\n</code></pre>"},{"location":"advanced_topics/rh8installib/#gathering-infiniband-hardware-addresses-and-putting-into-xcat","title":"Gathering InfiniBand hardware addresses and putting into xCAT","text":"<p>When confluent is configured to do 'zero power' discovery, it can collect mac addresses for boot devices such as InfiniBand without having to describe the fabric topology.  This document assumes familiarity with Node discovery and autoconfiguration with confluent and that the management network discovery has been configured.</p> <p>Have the systems attempt to network boot over infiniBand.  For example:</p> <pre><code># nodeboot ib net\n</code></pre> <p>After the system attempts PXE boot, the discovery mechanism should provide attributes suitable for feeding to xCAT.  To examine addresses seen by confluent and collected into the confluent attributes, the following commands are available: <pre><code># nodediscover list -t pxe-client\n Node|      Model|   Serial|                                 UUID|       Mac Address|       Type| Current IP Addresses\n-----|-----------|---------|-------------------------------------|------------------|-----------|---------------------\n  ib1| 7X2104Z000| DVJJ1022| 58962b3d-088b-11e7-b8b8-9e59e5cf61db| 50:6b:4b:09:2a:5c| pxe-client|                     \n</code></pre></p> <pre><code># nodeattrib ib net.ib.hwaddr\nib1: net.ib.hwaddr: 50:6b:4b:09:2a:5c\n</code></pre> <p>To actually populate xCAT, you can use the confluent2xcat command.  If you have not defined nodes in xCAT at all:</p> <pre><code># confluent2xcat ib -o xcatnodes.def\n# mkdef -z &lt; xcatnodes.def\n1 object definitions have been created or modified.\n</code></pre> <p>Alternatively, if you have xCAT nodes already defined, but only want to augment the xCAT definition with the mac data:</p> <pre><code># confluent2xcat ib -m mac.csv\n# tabrestore -a mac.csv\n</code></pre> <p>Also, it is possible to use nodeinventory to collect the hardware addresses of the InfiniBand adapters.  Note that Mellanox removes the middle two bytes (03:00) of their address during netboot, so remove it here:</p> <pre><code># nodeinventory d3 mac |grep Mellanox|sed -e s/50:6b:4b:03:00/50:6b:4b/\nd3: Mellanox ConnectX-5 2x100GbE / EDR IB QSFP28 VPI Adapter MAC Address 1: 50:6b:4b:09:2a:ac\nd3: Mellanox ConnectX-5 2x100GbE / EDR IB QSFP28 VPI Adapter MAC Address 2: 50:6b:4b:09:2a:ad\n</code></pre>"},{"location":"advanced_topics/rh8installib/#performing-the-install","title":"Performing the install","text":"<p>At this point, install can proceed as any normal install:</p> <pre><code># nodeset ib1 osimage=rhels8.0.0-x86_64-install-compute\n# nodeboot ib1 net\n</code></pre>"},{"location":"advanced_topics/rh8installib/#accessing-without-fabric","title":"Accessing without fabric","text":"<p>If an issue occurs where the server is up, but the fabric is unreachable and login or scp is required, a backup path is available through the XCC:</p> <pre><code># ssh -p 3389 $(noderun -n ib1 echo {bmc})\nLast login: Wed Apr 10 14:23:19 2019 from gateway\n[root@ib1 ~]#\n</code></pre> <p>All ssh capabilities are available, including scp:</p> <pre><code># scp -P 3389 testfile $(noderun -n ib1 echo [{bmc}]):~\ntestfile                       75%   48MB   2.6MB/s   00:06 ETA\n</code></pre> <p>As well as rsync:</p> <pre><code># rsync -ave 'ssh -p 3389' testfile $(noderun -n ib1 echo [{bmc}]):/\nsending incremental file list\ntestfile\n\nsent 67,125,334 bytes  received 35 bytes  2,355,276.11 bytes/sec\ntotal size is 67,108,864  speedup is 1.00\n</code></pre>"},{"location":"advanced_topics/sharedinstallnotes/","title":"Using xCAT management nodes with an NFS-mounted install directory","text":"<p>When using an NFS-mounted install directory, installing or updating the xCAT RPMs can result in errors (e.g., lsetfilecon errors) due to some files in the xCAT RPM installing to the install directory and certain filesystem operations not supported on NFS.</p> <p>If multiple xCAT servers need to share an install directory, then it is recommended this be done with a single xCAT master and multiple xCAT service nodes, which avoids this issue, as the xCATsn RPM does not install files into the install directory.</p>"},{"location":"advanced_topics/sharedtftpnotes/","title":"Using xCAT service nodes with a shared tftpboot directory","text":"<p>When using a shared tftp directory, the Genesis image generated in an rpm update applied across master and service nodes concurrently may drive uncertainty as to which xCAT server has credentials that can connect to a node booted into genesis using ssh.</p> <p>Two strategies are suggested: * Have all management nodes have the same keys in /root/.ssh/ so that they are consistent * Run rpm updates or <code>mknb x86_64</code> on the preferred management server.</p>"},{"location":"advanced_topics/sle152ibinstall/","title":"Installing SLE 15.2 over InfiniBand","text":"<p>This covers the process of SLE 15.2 deployment on a cluster using only InfiniBand.</p>"},{"location":"advanced_topics/sle152ibinstall/#pre-requisites-for-infiniband-install","title":"Pre-requisites for InfiniBand install","text":"<p>Confluent &gt;= 2.4.0</p> <p>xCAT &gt;= 2.14.6.lenovo3</p>"},{"location":"advanced_topics/sle152ibinstall/#preparing-for-infiniband-install","title":"Preparing for InfiniBand install","text":"<p>It is recommended to make groups to describe the required changes.  For example, this document will assume an 'ib' group.</p>"},{"location":"advanced_topics/sle152ibinstall/#setting-static-address-mode","title":"Setting static address mode","text":"<p>InfiniBand deployment is only supported in static mode.  Use the following command to have xCAT do static addressing:</p> <p># chtab key=managedaddressmode site.value=static</p>"},{"location":"advanced_topics/sle152ibinstall/#net-config-fixup-postscript","title":"Net config fixup postscript","text":"<p>InfiniBand network configuration does not work as expected out of the box.  If not installing Mellanox OFED, the following is an example of a postscript that can be added to correct that behavior:</p> <pre><code># cat /install/postscripts/fixipoib\necho 'install mlx5_core /sbin/modprobe --ignore-install mlx5_core; /sbin/modprobe mlx5_ib; /sbin/modprobe ib_ipoib' &gt;&gt; /etc/modprobe.d/mlx.conf\necho 'add_drivers+=\"mlx5_ib ib_ipoib\"' &gt; /etc/dracut.conf.d/mlx.conf\ndracut -f\n</code></pre>"},{"location":"advanced_topics/sle152ibinstall/#xcat-configuration","title":"xCAT configuration","text":"<p>Define the ib group to have the required install argument changes, interface name, and to invoke the postscript shown above:</p> <pre><code># nodegrpch ib bootparams.addkcmdline=\"insmod=ib_ipoib\"\n</code></pre>"},{"location":"advanced_topics/sle152ibinstall/#confluent-configuration","title":"confluent configuration","text":"<p>xCAT does not understand how to collect addresses for InfiniBand.  Instead, enable confluent collection of the InfinBand addresses:</p> <pre><code># nodegroupdefine ib net.ib.bootable=1 discovery.policy=permissive,pxe\n</code></pre>"},{"location":"advanced_topics/sle152ibinstall/#gathering-infiniband-hardware-addresses-and-putting-into-xcat","title":"Gathering InfiniBand hardware addresses and putting into xCAT","text":"<p>When confluent is configured to do 'zero power' discovery, it can collect mac addresses for boot devices such as InfiniBand without having to describe the fabric topology. This document assumes familiarity with Node discovery and autoconfiguration with confluent and that the management network discovery has been configured.</p> <p>Have the systems attempt to network boot over infiniBand.  For example:</p> <pre><code># nodeboot ib net\n</code></pre> <p>After the system attempts PXE boot, the discovery mechanism should provide attributes suitable for feeding to xCAT.  To examine addresses seen by confluent and collected into the confluent attributes, the following commands are available: <pre><code># nodediscover list -t pxe-client\n Node|      Model|   Serial|                                 UUID|       Mac Address|       Type| Current IP Addresses\n-----|-----------|---------|-------------------------------------|------------------|-----------|---------------------\n  ib1| 7X2104Z000| DVJJ1022| 58962b3d-088b-11e7-b8b8-9e59e5cf61db| 50:6b:4b:09:2a:5c| pxe-client|                     \n</code></pre></p> <pre><code># nodeattrib ib net.ib.hwaddr\nib1: net.ib.hwaddr: 50:6b:4b:09:2a:5c\n</code></pre> <p>To actually populate xCAT, you can use the confluent2xcat command.  If you have not defined nodes in xCAT at all:</p> <pre><code># confluent2xcat ib -o xcatnodes.def\n# mkdef -z &lt; xcatnodes.def\n1 object definitions have been created or modified.\n</code></pre> <p>Alternatively, if you have xCAT nodes already defined, but only want to augment the xCAT definition with the mac data:</p> <pre><code># confluent2xcat ib -m mac.csv\n# tabrestore -a mac.csv\n</code></pre> <p>Also, it is possible to use nodeinventory to collect the hardware addresses of the InfiniBand adapters.  Note that Mellanox removes the middle two bytes (03:00) of their address during netboot, so remove it here:</p> <pre><code># nodeinventory d3 mac |grep Mellanox|sed -e s/50:6b:4b:03:00/50:6b:4b/\nd3: Mellanox ConnectX-5 2x100GbE / EDR IB QSFP28 VPI Adapter MAC Address 1: 50:6b:4b:09:2a:ac\nd3: Mellanox ConnectX-5 2x100GbE / EDR IB QSFP28 VPI Adapter MAC Address 2: 50:6b:4b:09:2a:ad\n</code></pre>"},{"location":"advanced_topics/sle152ibinstall/#performing-the-install","title":"Performing the install","text":"<p>At this point, install can proceed as any normal install:</p> <pre><code># nodeset ib1 osimage=sle15.2-x86_64-install-compute\n# nodeboot ib1 net\n</code></pre>"},{"location":"advanced_topics/sle152ibinstall/#accessing-without-fabric","title":"Accessing without fabric","text":"<p>If an issue occurs where the server is up, but the fabric is unreachable and login or scp is required, a backup path is available through the XCC:</p> <pre><code># ssh -p 3389 $(noderun -n ib1 echo {bmc})\nLast login: Wed Apr 10 14:23:19 2019 from gateway\n[root@ib1 ~]#\n</code></pre> <p>All ssh capabilities are available, including scp:</p> <pre><code># scp -P 3389 testfile $(noderun -n ib1 echo [{bmc}]):~\ntestfile                       75%   48MB   2.6MB/s   00:06 ETA\n</code></pre> <p>As well as rsync:</p> <pre><code># rsync -ave 'ssh -p 3389' testfile $(noderun -n ib1 echo [{bmc}]):/\nsending incremental file list\ntestfile\n\nsent 67,125,334 bytes  received 35 bytes  2,355,276.11 bytes/sec\ntotal size is 67,108,864  speedup is 1.00\n</code></pre>"},{"location":"advanced_topics/sles12rste/","title":"Using xCAT to install SLES12 on Intel RSTe","text":"<p>xCAT does not currently consider the RSTe array as a default install target.  To override the behavior and direct the OS to be installed to RSTe, first create a file called /install/custom/sles12rste.partitions containing the following:</p> <pre><code>&lt;drive&gt;\n &lt;device&gt;/dev/md/Volume0&lt;/device&gt;\n &lt;partitions config:type=\"list\"&gt;\n     &lt;partition&gt;\n         &lt;filesystem config:type=\"symbol\"&gt;vfat&lt;/filesystem&gt;\n          &lt;mount&gt;/boot/efi&lt;/mount&gt;&lt;size&gt;128mb&lt;/size&gt;\n      &lt;/partition&gt;\n      &lt;partition&gt;\n          &lt;mount&gt;swap&lt;/mount&gt;\n          &lt;size&gt;auto&lt;/size&gt;\n      &lt;/partition&gt;\n          &lt;partition&gt;\n           &lt;mount&gt;/&lt;/mount&gt;\n           &lt;size&gt;auto&lt;/size&gt;\n      &lt;/partition&gt;\n &lt;/partitions&gt;\n &lt;initialize config:type=\"boolean\"&gt;true&lt;/initialize&gt;\n&lt;/drive&gt;\n</code></pre> <p>With this in place, modify the osimage to use this partition plan:</p> <pre><code>chdef -t osimage sles12.3-x86_64-install-compute partitionfile=/install/custom/sles12rste.partitions\n</code></pre> <p>From that point forward invocations of the nodeset command will target the RSTe volume.</p>"},{"location":"advanced_topics/xcataddingsnmp/","title":"Adding snmp support to xCAT","text":"<p>Due to changes in RedHat/CentOS 8, net-snmp-perl is no longer provided in either the vendor repository nor the lenovo repository. As such, xCAT support for SNMP is now considered optional.</p> <p>It is recommended to either use confluent to do PXE discovery and feed the data into xCAT or use confluent for the OS deployment. However, if wanting to use xCAT discovery with SNMP support, builds of the net-snmp rpms are available.</p> <p>Installing net-snmp-perl will add SNMP support to xCAT. Note that every rpm beginning with net-snmp must be exactly the same version, so it may be required to upgrade multiple rpms.</p> <p>If the most recent download is still old enough to create issues trying to apply updates from RedHat or CentOS, you may build your own packages instead of using packages from an archive:</p> <pre><code>$ git clone https://git.centos.org/rpms/net-snmp.git\n$ cd net-snmp\n$ git checkout c8\n$ cp SOURCES/* ~/rpmbuild/SOURCES\n$ rpmbuild -ba SPECS/net-snmp.spec --define 'netsnmp_check 0'  --undefine '_disable_source_fetch'\n</code></pre>"},{"location":"advanced_topics/xcatconfignotes/","title":"xCAT configuration notes","text":"<ul> <li>Installing EL7 with RSTe support</li> <li>Installing SLES12 with RSTe support</li> </ul> <p>If using xCAT's bmcsetup to manage the service processor port on Lenovo systems, that is, whether the dedicated management port will be used or the service processor management traffic will be carried over the same port as what is used for \"normal\" network traffic (shared mode), this can be set by the <code>bmcport</code> attribute in <code>chdef</code> or <code>ipmi.bmcport</code> in <code>nodech</code>.</p> <p>Generally speaking, a value of <code>1</code> will refer to the dedicated port on Lenovo equipment, and <code>0</code> will refer to shared, with some exceptions:   * For SD650 systems, the shared on-board port is designated by <code>0 2</code>   * If using an ML2 adapter, the shared port is <code>2 0</code>   * For SR645 systems, the shared OCP port (port 1) is designated by <code>2 0</code></p>"},{"location":"advanced_topics/xcatconfluentsetup/","title":"Confluent setup in existing xCAT configuration","text":"<p>In order to opt into using confluent as your console service, set the site table value for consoleservice:</p> <pre><code># chtab key=consoleservice site.value=confluent\n</code></pre> <p>Current xCAT versions include a command called <code>makeconfluentcfg</code>.  This command can be used without arguments to try to define or update all node configuration in confluent based on xCAT configuration.</p> <pre><code># makeconfluentcfg\n</code></pre> <p>To create or update only a subset:</p> <pre><code># makeconfluentcfg rack1\n</code></pre> <p>Note that the confluent network model does not currently map directly to the xCAT model.  Notably, if wanting to indicate a static gateway for the sake of autodiscovery, you would want to set the <code>net.ipv4_gateway</code> attribute on a confluent group or confluent nodes.  For example:</p> <pre><code># nodegroupattrib everything net.mgt.ipv4_gateway=172.20.0.1\n</code></pre> <p>The <code>mgt</code> value in the above example can be any name.  It is used to group distinct network settings together if multiple network interfaces are specified.  It's also possible to omit the name if there is only a single interface to configure.</p>"},{"location":"advanced_topics/xcatramrootibboot/","title":"Booting xCAT ramroot over InfiniBand","text":"<p>In the case of xCAT stateless images which network boot from infiniband, the ordering of the interfaces (ib0, ib1, etc) may change during the booting of the ramroot image. The lower order port (typically comparing MAC address) would normally be assigned the interface name ib0. This example assumes that a static DHCP lease was created for the lower order port.</p> <p>If the image is configured to boot from the lower order port, the port may instead be assigned the interface name ib1, causing the boot to fail. </p> <p>If this happens, the solution is to make an addition to the image kernel command line by modifying the bootparams.addkcmdline for the node to include \"ip=ib1:dhcp\".</p>"},{"location":"advanced_topics/xcatstatelessimagesles152/","title":"xCAT stateless image creation under SLES 15.2 fails","text":"<p>During the process of creating an <code>xCAT stateless image</code> under <code>SLES 15.2</code>, the xCAT genimage command may fail due to failure to locate the software packages in the distribution, even though the software repositories appear to be set up correctly.</p> <p>Repetitive output such as the following would be seen:</p> <pre><code>Loading repository data...\nReading installed packages...\n'aaa_base' not found in package names. Trying capabilities.\nNo provider of 'aaa_base' found.\n</code></pre> <p>In the example where the SLES 15.2 distribution has been extracted (<code>via the xCAT copycds utility</code>) onto an xCAT management node in the <code>/install/sle15.2/x86_64</code> directory, <code>the workaround</code> for the above problem would be to <code>rename the file</code> <code>/install/sle15.2/x86_64/1/repodata</code>, such as to <code>/install/sle15.2/x86_64/1/repodata-ignore</code>.</p> <p>At this point, the genimage command can be rerun and should succeed.</p>"},{"location":"advanced_topics/xcatstatelessimagesles152/#note","title":"Note:","text":"<p>Once the stateless image creation process is completed, the above file to be restored to its original name.</p>"},{"location":"developer/api/","title":"Confluent API Documentation","text":"<p>Confluent models functionality in a hierarchical structure.  It is a RESTful or filesystem-like structure, depending on how you want to think of it.  With respect to REST there are a couple of exceptional resources that are not strictly RESTful, which shall be explained.</p> <p>This document will review the available resources as they are structured. It is suggested to browse the API using confetty (without arguments) or using a web browser pointed at http://[mgt]:4005/ (once remote HTTP usage has been   enabled)</p>"},{"location":"developer/api/#enabling-remote-usage-over-http","title":"Enabling remote usage over HTTP","text":"<p>By default, confluent API is only accessible locally over a unix domain socket. To enable a remote user for HTTP access, the quickest method is to use confetty to create a local account:</p> <pre><code># useradd apiuser\n# passwd apiuser\n# confetty create /users/apiuser role=Administrator\n</code></pre> <p>With the above example, using 'apiuser' and the entered password in the user/password prompt will provide access when accessing the management server by http://servername:14005/.</p>"},{"location":"developer/api/#using-python-to-access-the-api","title":"Using python to access the API","text":"<p>All of the confluent command lines are implemented in python.  They serve as a good reference to review accessing the API.  For example, reviewing the source code of 'nodepower' can be very informative.  In general, a python developer will want to start by importing the client library:</p> <pre><code>import confluent.client as client\n</code></pre> <p>Next, you'll want to create a client session:</p> <pre><code>session = client.Command()\n</code></pre> <p>By default, this will reach out to the local instance.  If you want to reach out to a remote server, you may pass that as a string to the <code>Command()</code> call, as in <code>Command('172.20.0.1')</code>. Also you would have to enable remote native confluent protocol, as described in remote confluent.</p> <p>For many common interactions, there is a convenient method on the session object called 'simple_noderange_command()'. To accomodate more complex scenarios and map more directly to the underlying REST structure, the functions <code>create()</code>, <code>read()</code>, <code>update()</code>, and <code>delete()</code> are provided. See the client.py python API documentaion for more details.</p>"},{"location":"developer/api/#api-structure","title":"API Structure","text":"<p>The Confluent API structure is set up like a psuedo file system. Reading these paths will list the respective data. To update, the same path is given, along with the data to be used in the update, such as {'state' : [newstate]}. </p>"},{"location":"developer/api/#accessing-nodes-nodes-and-noderange","title":"Accessing Nodes: /nodes/ and /noderange/","text":""},{"location":"developer/api/#nodes","title":"/nodes/","text":"<p>The /nodes/ collection lists all defined nodes in confluent.  Every operation that can be done against a node is represented in the /nodes/ collection. Functionality is further subdivided into categories under the top level /nodes/ location for a given node. The operations for a specific node are  accessed with /nodes/[nodename]/</p>"},{"location":"developer/api/#noderangenoderange","title":"/noderange/[noderange]/","text":"<p>The /noderange/ top level structure appears empty.  However, if the client requests a subcollection, [noderange]/, it will try to auto-create a matching  collection based on the confluent noderange syntax.  Strictly speaking, this is  not RESTful, but consider it as an auto-mounting filesystem.  For a given           collection, the same structure produced by '/nodes/[nodename]/' is reproduced,  but the operations are considered to apply to all nodes matching the noderange  rather than just one node. Additionally, a noderange has a 'nodes/' subcollection to allow client software to list the nodes that match the noderange, but this does not allow operations on the individual nodes.</p> <p>In the following examples, /nodes/[nodename]/ can be replaced by  /noderange/[noderange]/ to execute the operations on multiple nodes.</p>"},{"location":"developer/api/#querying-or-setting-power-state-nodesnodenamepowerstate","title":"Querying or setting power state: /nodes/[nodename]/power/state","text":"<p>This resource allows query and setting of the power state.  Reading this value provides the current state, and sending {'state': [newstate]} will request a state change.  </p> <p>The recognized states are:</p> <ul> <li>on - Request system to be powered on.  Has no effect if system is already on.</li> <li>off - Request system to be powered off, without waiting for OS to shutdown.         This is an immediate power down.  Has no effect if system is already off.</li> <li>boot - Request system to take appropriate action to immediately start booting.          If a system is on, this is effectively 'reset'.  If a system is off, it          has the same effect as 'on'</li> <li>reset - Request a running system to immediately start booting without regard           for current OS.  This has no effect with the system off.</li> <li>shutdown - Send a request to the running OS to gracefully shutdown.  This             returns asynchronously to notify that the request has been relayed,             but has no guarantee that the OS will react or that the OS will             react as desired (e.g. an OS could present a shutdown dialog on             console, or ignore such requests completely)</li> </ul>"},{"location":"developer/api/#reseat-node-nodesnodenamepowerreseat","title":"Reseat node: /nodes/[nodename]/power/reseat","text":"<p>Reseating is equivalent to unplugging the node and plugging it back in. Removes standby power and reapplies it.</p>"},{"location":"developer/api/#setting-next-boot-device-nodesnodenamebootnextdevice","title":"Setting next boot device: /nodes/[nodename]/boot/nextdevice","text":"<p>Check and modify boot device override for next boot.  Frequently used for an OS deployment or diagnostic boot to prepare for an exceptional boot case where the default OS boot is not desired, but only for one boot.  Parameters are:</p> <ul> <li>bootmode - Allows requesting the firmware personality.  Recognized values are</li> <li>bios - Force a BIOS style boot in the style that x86 systems have            historically booted from their initial release</li> <li>uefi - Force the boot to be UEFI style</li> <li>unspecified - Allow platform to choose</li> <li>persistent - True/False indication of whether to request the platform leave                the override in place.  For example, a request to network boot                with persistent set to True should reboot from network from that                point on, rather than reverting to default boot order after next                boot</li> <li>nextdevice - The device/psuedo device to use in the next boot attempt.  This                is a single device and not an order of devices.  The recognized                devices are:</li> <li>default - Use the usual boot sequence behavior without any overrides</li> <li>setup - Boot the system into a configuration menu provided by firmware.             Generally the same menu that results from pressing a special key             during boot like 'F1'.  If this is active, no keypress during boot             should be required.</li> <li>network - Boot the system using a network protocol, generally PXE</li> <li>hd - Attempt to boot straight to a hard disk in a system</li> <li>cd - Boot from a CD/DVD/BD device.  In practice, this is frequently a          virtual instance of a CD provided by remote media capability of a          server.</li> </ul>"},{"location":"developer/api/#identifying-a-node-nodesnodenameidentify","title":"Identifying a node: /nodes/[nodename]/identify","text":"<p>This controls the behavior of the server to provide a means of making its physical location known.  Generally, this is an LED that illuminates on request. Sending {'identify': [newstate]} requests activation/deactivation of the LED. It is common for this data not to be readable, so querying the value is not generally promised to produce useful information (the server would return an empty value in such a case).</p> <p>The recognized states are:</p> <ul> <li>on - The LED will be illuminated (in some implementations, it will blink)</li> <li>off -The LED will be deactivated</li> </ul>"},{"location":"developer/api/#monitoring-hardware-nodesnodenamesensorshardwarecategory","title":"Monitoring hardware: /nodes/[nodename]/sensors/hardware/[category]/","text":"<p>This presents a collection of 'sensors' relevant to a node.  These are current point-in-time indications of both numeric values (e.g. wattage, fanspeed, temperature) and discrete states (missing hard drive, failed DIMM).  </p> <p>Supported categories include:</p> <ul> <li>all - Returns all sensors present on the node</li> <li>temperature - Temperature sensors can include CPU temps, ambient temperatures,                    DIMM temperatures, etc. </li> <li>power - Power sensors can include AC Power and DC Power, and any other measurements               of power</li> <li>energy - Energy sensors can include AC Energy and DC Energy, and any other               measurements of energy</li> <li>leds - LED sensors return the state of LEDs on the node, including the identify LED,             error LEDs, etc.</li> <li>fans - Fan sensors return the speed of fans such as PSU or CPU fans. This may also             return discrete sensors such as a fault.</li> </ul> <p>Each sensor may return the following fields:</p> <ul> <li>health - An assessment of whether the state of the component should             be considered normal or a concern.            The following states are declared:</li> <li>ok - Sensor indicates no problem</li> <li>warning - Sensor indicates an abnormal condition exists, but not              one that is currently impacting workload.  For example,              excess correctable memory errors.</li> <li>critical - Sensor indicates a severe problem exists that is               impacting workload or presents an imminent risk               of catastrophic data loss.  For example, a degraded               RAID array.</li> <li>failed - Indicates a severe problem that has caused disruption of             resources or data loss.  For example, a fatal memory error             resulting in a reboot, or loss of non-redundant storage.</li> <li>name - A string identifying the sensors</li> <li>state_ids - Numeric values representing the observed states.  Generally               this field can be ignored.</li> <li>states - A list of textual descriptions of currently active states.  Examples            include Present, Failed, Non-Redundant, and are intended to be            self-explanatory and can be presented directly to an administrator            without processing.  Programatic understanding of the severity is            acheived through examining the 'health' field above.</li> <li>units -  Optional indicator of the units to use when evaluating 'value' field</li> <li>value - A numeric value representing the current reading of the sensors.  It           is null when the sensor is a non-numeric sensor.</li> </ul>"},{"location":"developer/api/#configuring-a-node-nodesnodenameconfiguration","title":"Configuring a node: /nodes/[nodename]/configuration/","text":"<p>This is where one can view and manipulate various configurations active on the node.  This is distinguished from 'attributes' which are values stored about the node by confluent, but are not directly active on the system.  </p>"},{"location":"developer/api/#managing-system-defined-configuration-nodesnodenameconfigurationsystemall","title":"Managing system-defined configuration: /nodes/[nodename]/configuration/system/all","text":"<p>This is where one can read or edit system-defined configuration like BIOS or UEFI settings.  </p>"},{"location":"developer/api/#resetting-the-management-controller-nodesnodenameconfigurationmanagement_controllerreset","title":"Resetting the management controller: /nodes/[nodename]/configuration/management_controller/reset","text":"<p>This can be used to request that the management controller for the node be reset. PUT {'state': 'reset'} in order to initiate a restart of the management controller</p>"},{"location":"developer/api/#viewing-user-accounts-on-the-management-controller-nodesnodenameconfigurationmanagement_controllerusers","title":"Viewing user accounts on the management controller: /nodes/[nodename]/configuration/management_controller/users/","text":"<p>This is a list of accounts considered local to the management controller.  This excludes accounts provided by a central authentication provider, such as LDAP. It is indexed by an arbitrary index value that might not correlate to user names. For IPMI systems, it represents the 'user slot' of the user account.  Each account provides the following fields:</p> <ul> <li>username - The username associated with this account</li> <li>privilege_level - The level of access afforded to the account. Levels are:</li> <li>user - Able to read most sensor data</li> <li>operator - Able to manipulate the running system, reboot, and access console</li> <li>administrator - Able to change the configuration of the management controller,                     including authentication data, ip addresses, alert destinations,                     and so forth</li> </ul>"},{"location":"developer/api/#configuring-ntp-nodesnodenameconfigurationmanagement_controllerntpargument","title":"Configuring NTP: /nodes/[nodename]/configuration/management_controller/ntp/[argument]/","text":"<p>Configure and control the NTP functionality of supported management controllers. For management controllers implementing NTP in a manner supported by confluent, this provides the following mechanisms:</p> <ul> <li>enabled - Enable or disable NTP</li> <li>servers - Collection of servers currently configured. Can create new or update existing</li> </ul> <p>Note that in confluent, efforts are made to correct timestamps with detectable systematic errors, so local time on the management controller may not necessarily impact accuracy of data such as event log timestamps.</p>"},{"location":"developer/api/#managing-alert-destinations-nodesnodenameconfigurationmanagement_controlleralertsdestinations","title":"Managing alert destinations: /nodes/[nodename]/configuration/management_controller/alerts/destinations/","text":"<p>Manage the list of destinations that the management controller will directly send alerts to.  Alert information may be in turn propogated by the respective destination to more destinations and formats.  Each item contains  the following fields:</p> <ul> <li>ip - The ip address to transmit to</li> <li>retries - If acknowledge is enabled, the number of attempts to perform before             giving up</li> <li>acknowledge_timeout - When waiting for an acknowledgement from the target,                         how long to wait before evaluating the need to retrytime</li> <li>acknowledge - Whether to expect an explicit acknowledgement.  For example, SNMP                   traps do not have an SNMP mechanism to acknowledge receipt, so                 this would be disabled for normal SNMP traps.  However, IPMI                 PET alerts are SNMP traps, but provide a mechanism a receiver                 can use to confirm receipt.  If uncertain, this should be false                 unless otherwise indicated by the alert destination software.</li> </ul>"},{"location":"developer/api/#viewing-host-name-used-by-management-controller-nodesnodenameconfigurationmanagement_controlleridentifier","title":"Viewing host name used by management controller: /nodes/[nodename]/configuration/management_controller/identifier","text":"<p>Returns the host name that the management controller uses for DHCP requests.</p>"},{"location":"developer/api/#manage-bmc-domain-name-nodesnodenameconfigurationmanagement_controllerdomain_name","title":"Manage BMC domain name: /nodes/[nodename]/configuration/management_controller/domain_name/","text":"<p>Set/view the domain name of the BMC.</p>"},{"location":"developer/api/#managing-ip-configuration-nodesnodenameconfigurationmanagement_controllernet_interfacesmanagement","title":"Managing IP configuration: /nodes/[nodename]/configuration/management_controller/net_interfaces/management","text":"<p>IP configuration data for the management controller.  Note that changing this value without coordinating changes in the associated hardwaremanagement.manager attribute may cause disruption.  The fields available:</p> <ul> <li>ipv4_address - The ipv4 address and netmask length in CIDR notation.  This                  should provide the current value regardless of whether it is                  DHCP or static, but should not be PUT if the ipv4_configuration                  is not Static.</li> <li>ipv4_configuration - The method to use to assign the IPv4 address, either                        'Static' or 'DHCP'</li> <li>ipv4_gateway - The gateway to use for non-local traffic.  As in ipv4_address,                  PUT is only supported for this field if 'Static'</li> <li>hw_addr - The ethernet mac address of the interface</li> </ul>"},{"location":"developer/api/#running-a-shell-session-nodesnodenameshellsessions","title":"Running a shell session: /nodes/[nodename]/shell/sessions/","text":"<p>This is a non-RESTful resource, used to create a stateful ssh session suitable for use in a web browser.  See the source of consolewindow.js for an example of how to interact.  RESTful style interaction allows listing currently active shell sessions, but the primary role of translating HTTP to SSH is not something that fits the RESTful models</p>"},{"location":"developer/api/#running-a-console-session-nodesnodenameconsolesession","title":"Running a console session: /nodes/[nodename]/console/session","text":"<p>This is a non-RESTful interface.  It provides a mechanism for javascript code in a browser to present a terminal-in-a-browser proxying an HTTP based protocol to the appropriate console protocol for the node.  The console is the single, authoritatitve text based console of the node.  A node's console is active independent of having any clients connected, and multiple clients connecting always share a single view and input.  Upon open, a console session may stream older data from log to client to help recreate the console.</p>"},{"location":"developer/api/#viewing-availability-of-licensed-functionality-nodesnodenameconsolelicense","title":"Viewing availability of licensed functionality: /nodes/[nodename]/console/license","text":"<p>Describes the availability of potentially licensed functionality pertaining to remote console; for example, remote graphics console is frequently a premium feature provided at additional cost.</p>"},{"location":"developer/api/#viewing-and-setting-node-attributes-nodesnodenameattributesgroup","title":"Viewing and setting node attributes: /nodes/[nodename]/attributes/[group]/","text":"<p>Lists attributes in confluent's datastore pertaining to nodes.  This may contain information that confluent needs to function (e.g. address of management controllers), helpful metadata about a node (node location, admin notes), or cached data for performance enhancement or post-mortem (last health state, serial numbers, et al).</p> <p>Attributes can be accessed via the following groups:</p> <ul> <li>all - Provides all possible attributes as well as current values</li> <li>current - Provides only those attributes that have been given values</li> </ul> <p>When doing UPDATE, 'all' and 'current' will behave identically. The fields are     defined in the [attributes] document.  Each attribute has:</p> <ul> <li>value - The current value of the attribute, after any potential expressions and           inheritance have been performed.</li> <li>inheritedfrom - Present and set if the current value is derived from a group                   level attribute rather than directly set on the node.</li> <li>expression - Present and set if the current value is calculated from an expression</li> </ul>"},{"location":"developer/api/#viewing-hardware-health-nodesnodenamehealthhardware","title":"Viewing hardware health: /nodes/[nodename]/health/hardware","text":"<p>An overall assessment of the health of the hardware associated with a node. It provides a 'health' field summarizing the most severe detected state, as well as a 'sensors' list of relevant readings to explain the reason for the health assessment.  The content of the sensors is identical to the items in '/sensors'</p>"},{"location":"developer/api/#viewing-hardware-information-nodesnodenameinventoryhardwarecategory","title":"Viewing hardware information: /nodes/[nodename]/inventory/hardware/[category]/","text":"<p>A list of hardware devices that are possible, their presence, and associated data. </p> <p>Categories currently supported are:</p> <ul> <li>all - This is currently the only supported category, listing all hardware             inventories. More categories may be added in the future.</li> </ul> <p>The hardware inventory data is a list of objects with the following fields:    </p> <ul> <li>name - A human friendly name describing the item</li> <li>information - A set of free-form key-value structured information about                 the inventory item.  Though free-form, similar devices should                 resemble each other to the extent feasible.</li> <li>present - A true/false value indicated whether the specified device actually             is populated in this specific node.</li> </ul>"},{"location":"developer/api/#viewing-firmware-information-nodesnodenameinventoryfirmwarecategory","title":"Viewing firmware information: /nodes/[nodename]/inventory/firmware/[category]/","text":"<p>Items containing firmware, and the current version information. </p> <p>Categories currently supported are:</p> <ul> <li>all - Lists all firmware items and their current version information.</li> <li>updates/active - A collection of firmware updates currently in progress.                       Will hold this information after update completion until removed.</li> </ul> <p>The firmware data may contain: </p> <ul> <li>date - The date that the firmware was created by the vendor</li> <li>version - The version designation as indicated by the vendor</li> <li>build - A freeform build identification string vendors may use to more           fully describe firmware.  For example, 1.2 may mean different things           on different products, but a vendor may elect to have unique build ids           to embed the product family into a single value, without worrying           about making clear what version is newer than another, as is the case           with version</li> </ul>"},{"location":"developer/api/#viewing-log-of-hardware-events-nodesnodenameeventshardwarelog","title":"Viewing log of hardware events: /nodes/[nodename]/events/hardware/log","text":"<p>An enumeration of events and timestamps that have happened to the indicated node. Each event has:</p> <ul> <li>component - A textual description of a physical or logical entity related to               the event. For example, \"Progress\", \"Host Power\", \"Non Auth DIMMs\"</li> <li>component_type - A description of what type of entity the component is.                       Examples are: \"System Firmware\", \"Power Unit\" and \"Memory\"</li> <li>event - A text description of the event that occured</li> <li>id - A numerical value representing the id, useful for looking up the id        against a database</li> <li>record_id - An identifier associated with the event by the providing device </li> <li>severity - An assessment of any health state changes that would be caused by              this event.  The values are the same as the 'health' values.</li> <li>timestamp - When available, ISO-8601 timestamp of when the event happened,               in local time relative to the confluent server.</li> </ul>"},{"location":"developer/api/#decoding-alert-data-nodesnodenameeventshardwaredecode","title":"Decoding alert data: /nodes/[nodename]/events/hardware/decode","text":"<p>This provides a facility for decoding and enriching alert data from a target. For example, an SNMP trap handler can use this to decode a PET alert from an    IPMI source.  TODO: Document this further                  </p>"},{"location":"developer/api/#managing-physical-and-virtual-media-nodesnodenamemediaargument","title":"Managing physical and virtual media: /nodes/[nodename]/media/[argument]","text":"<p>Manage physical and virtual media, such as a USB, CD, or iso image.</p> <p>Arguments include:</p> <ul> <li>current - A collection of all uploaded and attached media</li> <li>uploads - Manages process of uploading media to management controller for use in OS.                 Will list current and completed uploads, until told to delete.</li> <li>attach - Requests that BMC connect to another server and associate that URL with a media device,                    instructing BMC to use the file at the URL</li> <li>detach - Detaches attached media or deletes an uploaded image or file</li> </ul>"},{"location":"getting_started/configureconfluent/","title":"Configuring confluent","text":""},{"location":"getting_started/configureconfluent/#when-used-in-conjunction-with-xcat","title":"When used in conjunction with xCAT","text":"<p>If you wish to use xCAT to create the confluent configuration, see Configuring confluent from xCAT The remainder of this document is mostly applicable to users working with confluent standalone directly rather than using xCAT to configure.</p>"},{"location":"getting_started/configureconfluent/#using-confluent-without-xcat","title":"Using Confluent without xCAT","text":"<p>In confluent, configuration is organized as attributes on nodes.  The  attributes may be directly configured on a node or inherited from a group. Values may be a straightforward string or an expression as documented in  the attribute expressions documentation.</p> <p>To get started, it is suggested to use the <code>everything</code> group to set universal attributes. The <code>everything</code> group automatically exists and all defined nodes are automatically placed into it, in addition to manually specified and created groups Usually a cluster uses the same username/password across the XCCs (xClarity Controllers).  In such a case, it is suggested to set this data as attributes on the <code>everything</code> group:</p> <pre><code>nodegroupattrib everything console.method=ipmi\nnodegroupattrib everything -p bmcuser bmcpass\n</code></pre> <p>The <code>nodeattrib</code> and <code>nodegroupattrib</code> commands can either accept <code>key=value</code> or <code>-p key1 key2</code>. The former allows fully non-interactive use, while the latter prompts interactively to prevent the username and password from being inadvertently on screen or stored in your shell history.</p> <p>From there, adding a specific node using values from the group <code>everything</code> combined with node specific attributes could involve the following:</p> <pre><code>nodedefine n3 bmc=n3-xcc\n</code></pre> <p>Another common task is to create a custom group, with particular meaning to a specific environment.  For example, here is creating a custom group called <code>rack1</code> and using the expression syntax to append '-xcc' to the end of the nodename to use as the XCC address:</p> <pre><code>nodegroupdefine rack1 location.rack=1\nnodegroupdefine compute bmc={nodename}-xcc\n</code></pre> <p>These groups, like the <code>everything</code> group can hold any attribute, and may also use expressions or normal values.  The process to create a node can include these groups:</p> <pre><code>nodedefine n1 groups=rack1,compute\n</code></pre> <p>At which point, <code>n1</code> has location and XCC address configured just by virtue of the nodes it was assigned to.  Note that membership in the <code>everything</code> group is automatic, even if not listed in the groups for a node to be in, it will nevertheless be considered a member of that group.</p> <p>At this point, there are a few alternative paths to proceed:</p> <ul> <li>Set up confluent to be able to deploy operating systems (recommended prior to auto-configuration if planning for OS deployment using confluent): Preparing for Operating System Deployment</li> <li>Discovery is intended to help when IP addresses, usernames, and/or passwords are not configured yet. If these activities are otherwise handled in the environment, it is suggested to skip discovery and read: Managing hardware using confluent</li> <li>If the IP addresses, usernames, and/or passwords need to be configured and it is desired to use physical location of equipment as the key, see: Using switch based discovery for rackmount servers or Using enclosure based discovery for dense platforms</li> <li>If the IP addresses, usernames, and/or passwords need to be configured and it is desired to either use serial numbers, mac addresses, or otherwise manually review the available data to proceed, see: Using nodediscover assign</li> </ul>"},{"location":"getting_started/confluentgroups/","title":"Confluent Groups","text":"<p>In confluent, there is a concept of node groups to provide convenient shorthand for noderanges as well as  a way to group attributes together.  This may be ignored and everything be individually managed directly, but the groups may provide for easier configuration management at larger scale of components.</p>"},{"location":"getting_started/confluentgroups/#use-in-noderanges","title":"Use in noderanges","text":"<p>Node groups can be used the same as nodes in noderange syntax.  </p> <p>Additionally, a group can be used to be shorthand for a noderange.  For example, to make a group <code>all</code> to represent every node excluding <code>switches</code> and <code>pdus</code>, without having to continually update the <code>all</code> group as nodes are added or removed:</p> <pre><code>nodegroupdefine all noderange=everything,-switches,-pdus\n</code></pre> <p>Note that <code>noderange</code> groups do not contribute to providing attributes to the node attributes.</p>"},{"location":"getting_started/confluentgroups/#attribute-inheritence","title":"Attribute inheritence","text":"<p>Attributes on a group will flow into specific node attributes.  A node may inherit attributes from multiple groups at the same time.  If a node is in multiple groups, and more than one group offers an attribute value, the highest priority group overrides the lower priority group.  Priority proceeds from the first listed group to last group for highest to lower priority when looking at the <code>groups</code> attribute on a node.  Attributes defined on a node specifically will always supersede anything from groups.  A large number of attributes require individual values, but proceed in a predictable fashion.  These may be defined on a group level, leveraging attribute expressions to individualize the group setting accordingly.</p>"},{"location":"getting_started/confluentgroups/#using-nodeattrib-versus-nodegroupattrib","title":"Using <code>nodeattrib</code> versus <code>nodegroupattrib</code>","text":"<p>A point of confusion is using <code>nodeattrib [group] [attribute]=[value]</code> versus <code>nodegroupattrib [group] [attribute]=[value]</code>. The <code>nodeattrib [group]</code> command sets attributes individually on every current member of [group].  This means that the attribute will override anything from groups, even if there's a higher priority group.  It means that the attribute will not be set on future members of the group, as it wasn't targeted by nodeattrib.  The <code>nodegroupattrib</code> command specifically ensures the attribute is set on the group.  It will avoid overriding higher priority groups and it will be inherited as appropriate on any future nodes added to the group going forward.</p>"},{"location":"getting_started/confluentgroups/#the-everything-group","title":"The <code>everything</code> group","text":"<p>There is an implicit group called <code>everything</code>, intended to provide a shorthand in lieu of global settings.  Anything set on a node can be set on <code>everything</code>, and attributes set on <code>everything</code> will be inherited by all nodes, unless the specific attribute is superseded by a higher priority group or the node itself.</p>"},{"location":"getting_started/confluentgroups/#bringing-it-together","title":"Bringing it together","text":"<p>Now a sample will be presented leveraging groups to define a representative configuration.</p> <p>First will set the 'global' username and password that is preferred in this site.  This will use the interactive prompt to keep the values out of the shell history and ps output for other users.</p> <pre><code># nodegroupattrib everything -p secret.hardwaremanagementuser secret.hardwaremanagementpassword\nEnter value for secret.hardwaremanagementuser:\nConfirm value for secret.hardwaremanagementuser:\nEnter value for secret.hardwaremanagementpassword:\nConfirm value for secret.hardwaremanagementpassword:\neverything: secret.hardwaremanagementpassword: ********\neverything: secret.hardwaremanagementuser: ********\n</code></pre> <p>A group will be created to explain the configurations naming scheme and how it influences network connectivity:</p> <pre><code># nodegroupdefine rackmount location.rack={n1} location.u={n2} \\\n  net.switch=r{location.rack}eth net.switchport=swp{location.u} \\\n  discovery.nodeconfig=bmc.ipv4_address=172.30.{location.rack}.{location.u} \\\n  discovery.policy=permissive \\\n  power.outlet='{(n2-1)%12+1}' power.pdu=r{n1}pdu'{(n2-1)/12+1}'\n</code></pre> <p>A group will be created to declare the method to manage how to manage pdus:</p> <pre><code># nodegroupdefine pdus hardwaremanagement.method=geist\n</code></pre> <p>A group to explain method to manage ethernet switches:</p> <pre><code># nodegroupdefine switches hardwaremanagement.method=affluent\n</code></pre> <p>A group to have a shorthand for all server devices excluding infrastructure equipment when using noderanges:</p> <pre><code># nodegroupdefine all noderange=everything,-pdus,-switches\n</code></pre> <p>Then define nodes according to what is expected for an eight rack configuration with 42 1U servers each:</p> <pre><code># nodedefine r[1:8]eth groups=switches\n# nodedefine r[1:8]pdu[1:4] groups=pdus\n# nodedefine r[1:8]u[1:42] groups=rackmount\n</code></pre> <p>With this in place, <code>nodeattrib --blame</code> can be used to see the results of the sequence of commands:</p> <pre><code># nodeattrib r3u32 --blame\nr3u32: discovery.nodeconfig: bmc.ipv4_address=172.30.3.32 (inherited from group rackmount, derived from expression \"bmc.ipv4_address=172.30.{location.rack}.{location.u}\")\nr3u32: discovery.policy: permissive (inherited from group rackmount)\nr3u32: groups: rackmount,everything\nr3u32: location.rack: 3 (inherited from group rackmount, derived from expression \"{n1}\")\nr3u32: location.u: 32 (inherited from group rackmount, derived from expression \"{n2}\")\nr3u32: net.switch: r3eth (inherited from group rackmount, derived from expression \"r{location.rack}eth\")\nr3u32: net.switchport: swp32 (inherited from group rackmount, derived from expression \"swp{location.u}\")\nr3u32: power.outlet: 8 (inherited from group rackmount, derived from expression \"{(n2-1)%12+1}\")\nr3u32: power.pdu: r3pdu3 (inherited from group rackmount, derived from expression \"r{n1}pdu{(n2-1)/12+1}\")\nr3u32: secret.hardwaremanagementpassword: ******** (inherited from group everything)\nr3u32: secret.hardwaremanagementuser: ******** (inherited from group everything)\n</code></pre>"},{"location":"getting_started/confluentquickstart_el8/","title":"Confluent quickstart","text":"<p>This document provides one example flow from installation to capable cluster. Confluent is very flexible and there are multiple ways to do things. For example, this document is going to skip configuring automatic IP addresses, working with an external DHCP server, automatic configuration based on physical location, and other topics. See the more detailed documentation for more detail and alternative strategies for particular areas.</p>"},{"location":"getting_started/confluentquickstart_el8/#installing-confluent","title":"Installing confluent","text":"<p>To install confluent as well as optional requirements, after adding a yum repository according to downloads page:</p> <pre><code># yum install lenovo-confluent confluent_osdeploy-x86_64 tftp-server\n# systemctl enable confluent --now\n# systemctl enable httpd --now # if wanting to deploy operating systems and/or the web gui\n# systemctl enable tftp.socket --now  # If wanting to support PXE install\n</code></pre> <p>More details, including firewall rules and enabling GUI login may be found in the dedicated install page.</p>"},{"location":"getting_started/confluentquickstart_el8/#specifying-some-global-behavior","title":"Specifying some global behavior","text":"<p>In confluent, most all configuration is node oriented and can be derived from a group. A default group called 'everything` is automatically added to every node. It provides a method to indicate global settings.</p> <p>Attributes may all be specified on the command line, and an example set could be:</p> <pre><code># nodegroupattrib everything deployment.useinsecureprotocols=firmware console.method=ipmi dns.servers=172.30.0.254 dns.domain=mydomain.example net.ipv4_gateway=172.30.0.254\n</code></pre> <p>The deployment.useinsecureprotocols=firmware enables PXE support (HTTPS only mode is by default the only allowed mode), console.method=ipmi may be skipped but if specified instructs confluennt to use IPMI to access the text console to enable the <code>nodeconsole</code> command.</p> <p>While passwords and similar may be specified the same way, it is recommended to use the '-p' argument to prompt for values, to keep them out of your command history. Note that if unspecified, default root password behavior is to disable password based login and for grub omitting the password will allow console to edit grub at boot without a password:</p> <pre><code># nodegroupattrib everything -p bmcuser bmcpass crypted.rootpassword crypted.grubpassword\nEnter value for bmcuser: \nConfirm value for bmcuser: \nEnter value for bmcpass: \nConfirm value for bmcpass: \nEnter value for crypted.rootpassword: \nConfirm value for crypted.rootpassword: \nEnter value for crypted.grubpassword: \nConfirm value for crypted.grubpassword: \neverything: crypted.grubpassword: ********\neverything: crypted.rootpassword: ********\neverything: secret.hardwaremanagementpassword: ********\neverything: secret.hardwaremanagementuser: ********\n</code></pre>"},{"location":"getting_started/confluentquickstart_el8/#leave-ipv6-enabled","title":"Leave IPv6 enabled","text":"<p>Even if you are not using it explicitly, IPv6 needs to be enabled on interfaces. Generally this is default, but if you have disabled IPv6 on an interface, then re-enable it. No address needs to be assigned explicitly, no DHCPv6 server is needed.  The only thing required is that deployment interfaces have an automatic IPv6 address beginning with fe80::</p>"},{"location":"getting_started/confluentquickstart_el8/#defining-nodes","title":"Defining nodes","text":"<p>Nodes may contain any number of attributes. In this document, everything is defined at the group level, so we only need define the names. Here we will use a simple n[number] scheme, though any scheme may be used.</p> <pre><code># nodedefine n1-n4\n</code></pre>"},{"location":"getting_started/confluentquickstart_el8/#establishing-hardware-management-through-confluent-discovery","title":"Establishing hardware management through confluent discovery","text":"<p>It is possible to skip discovery and manually configure the xClarity Controllers and define them to confluent. On the other extreme, it is possible to configure fully automatic discovery based on physical location.</p> <p>For this guide we will use the manual confluent discovery process, which works with xClarity controllers without having an ip address or username/password configured in advance.</p> <p>A command to examine what was detected:</p> <pre><code># nodediscover rescan\nRescan complete\n# nodediscover list -t lenovo-xcc -f node,model,serial,mac -o model \n Node|      Model|   Serial|               Mac\n-----|-----------|---------|------------------\n     | 7D2VCTO1WW| J301VETT| 08:94:ef:aa:93:b7\n     | 7X21CTO1WW| J100M79E| 08:94:ef:41:01:b5\n     | 7X21CTO1WW| J1001PNE| 08:94:ef:50:1c:6b\n     | 7X21CTO1WW| J1001PNG| 08:94:ef:50:9b:3b\n     | 7X2104Z000| DVJJ1042| 08:94:ef:3f:e0:af\n     | 7X2104Z000| DVJJ1003| 08:94:ef:40:89:31\n     | 7X2104Z023| DVJJ9986| 08:94:ef:2f:2b:c7\n     | 7X2106Z009| DVJJ1086| 08:94:ef:2f:2e:9d\n     | 7Y02RCZ000| DVJJ8699| 08:94:ef:49:c3:55\n</code></pre> <p>This can be used to create a .csv file for manual discovery input:</p> <pre><code># nodediscover list -t lenovo-xcc -f node,serial -c -o model &gt; input.csv\n</code></pre> <p>After manually editing in the desired names and deleting rows not of interest, input.csv looks like:</p> <pre><code># cat input.csv\nNode,Serial\nn1,J100M79E\nn2,J301VETT\nn3,J1001PNE\nn4,J1001PNG\n</code></pre> <p>Which can then be passed to nodediscover assign:</p> <pre><code># nodediscover assign -i input.csv \nDefined n1\nDiscovered n1\nDefined n2\nDiscovered n2\nDefined n3\nDiscovered n3\nDefined n4\nDiscovered n4\n</code></pre> <p>At which point we can demonstrate power control through the everything group:</p> <pre><code># nodepower everything\nn1: on\nn2: on\nn3: on\nn4: off\n</code></pre>"},{"location":"getting_started/confluentquickstart_el8/#preparing-for-os-deployment","title":"Preparing for OS deployment","text":"<p>If desiring only to prepare for hardware management, then the guide has completed. However, confluent also optionally supports OS deployment.</p>"},{"location":"getting_started/confluentquickstart_el8/#preparing-name-resolution","title":"Preparing name resolution","text":"<p>Note that no particular name resolution solution is required, but this document suggests a basic strategy if no strategy is already in place.</p> <p>We start by building /etc/hosts. This may be done manually, or noderun can be used to quickly generate lines for /etc/hosts. First a dry run to make sure it looks correct:</p> <pre><code># noderun -n n1-n4 echo 172.30.0.{n1} {node} {node}.{dns.domain}\n172.30.0.1 n1 n1.mydomain.example\n172.30.0.2 n2 n2.mydomain.example\n172.30.0.3 n3 n3.mydomain.example\n172.30.0.4 n4 n4.mydomain.example\n</code></pre> <p>And then append to /etc/hosts when it looks correct:</p> <pre><code># noderun -n n1-n4 echo 172.30.0.{n1} {node} {node}.{dns.domain} &gt;&gt; /etc/hosts\n</code></pre> <p>Finally, to quickly have a dns server, installing and starting dnsmasq can make /etc/hosts available through dns:</p> <pre><code># yum install dnsmasq\n# systemctl enable dnsmasq --now\n</code></pre> <p>Any time /etc/hosts is updated, restart dnsmasq to have it pick up changes.</p>"},{"location":"getting_started/confluentquickstart_el8/#initializing-confluent-os-deployment","title":"Initializing confluent OS deployment.","text":"<p>The osdeploy command has an initialize subcommand to help set up requirements for OS deployment. Here the <code>-i</code> flag is used to interactively prompt on the options that are available: <pre><code># osdeploy initialize -i\nAdd root user key to be authorized to log into nodes (-u)? (y/n): y\nInitialize a profile to boot Genesis on target systems (a small Linux environment for rescue and staging use)? (y/n): y\nSet up an SSH authority to help manage known_hosts and node to node ssh for all users (-s)? (y/n): y\nUpdate global known hosts on this server to trust local CA certificates (-k)? (y/n): y\nAllow managed nodes to ssh to this management node without a password (-l)? (y/n): y\nUpdate tftp directory with binaries to support PXE (-p) (y/n): y\nGenerate new TLS certificates for HTTP, replacing any existing certificate (-t)? (y/n): y\nHTTP server has been restarted if it was running\nGenerating public/private ed25519 key pair.\nYour identification has been saved in /etc/confluent/ssh/ca.\nYour public key has been saved in /etc/confluent/ssh/ca.pub.\nThe key fingerprint is:\nSHA256:hnSBJPUL2tET7Djkdd3jP9zabTdGiefjuWnaNTvajec mgt3 SSH CA\nThe key's randomart image is:\n+--[ED25519 256]--+\n|    .oooo  . .   |\n|     .oooo. . o  |\n|     o++=.   . . |\n|     ++=.o    .  |\n|    . o.S     o.o|\n|       .     . *o|\n|              +++|\n|              +O&amp;|\n|             oB%E|\n+----[SHA256]-----+\nTFTP service is enabled and running\nSigned host key /tmp/tmpnc184l43/hostkey-cert.pub: id \"mgt3\" serial 0 for mgt3,mgt3.mycluster.example valid forever\nSigned host key /tmp/tmp0y1oyp46/hostkey-cert.pub: id \"mgt3\" serial 0 for mgt3,mgt3.mycluster.example valid forever\nSigned host key /tmp/tmp2i8lgmu_/hostkey-cert.pub: id \"mgt3\" serial 0 for mgt3,mgt3.mycluster.example valid forever\n10 blocks\nUpdated: genesis-x86_64\nSite initramfs content packed successfully\n</code></pre></p>"},{"location":"getting_started/confluentquickstart_el8/#importing-install-media","title":"Importing Install media","text":"<p>The iso of a supported OS may be imported by using the <code>osdeploy import</code> command, for example:</p> <pre><code># osdeploy import RHEL-8.2.0-20200404.0-x86_64-dvd1.iso \nImporting from /root/RHEL-8.2.0-20200404.0-x86_64-dvd1.iso to /var/lib/confluent/distributions/rhel-8.2-x86_64\ncomplete: 100.00%    \nDeployment profile created: rhel-8.2-x86_64-default\n</code></pre> <p>Note that a new directory exists in /var/lib/confluent/public/os/rhel-8.2-x86_64-default. This is intended to be freely editable for customization as desired.</p>"},{"location":"getting_started/confluentquickstart_el8/#deploying-a-node","title":"Deploying a node","text":"<p>To initiate network deployment of the profile above, the nodedeploy command may be used (TIP: the profile name like many other things may be tab completed when used interactively):</p> <pre><code># nodedeploy n1-n2 -n rhel-8.2-x86_64-default \nn1: network\nn2: network\nn1: reset\nn2: reset\n</code></pre> <p>At this point, the boot and install progress may be watched interactively through the video console or by the text console available via nodeconsole:</p> <pre><code># nodeconsole n1\n</code></pre> <p>Also <code>nodedeploy</code> may be used to check the current status of a deployment:</p> <pre><code># nodedeploy n1-n2\nn1: pending: centos-8.2-x86_64-default (node authentication armed)\nn2: pending: centos-8.2-x86_64-default (node authentication armed)\n</code></pre> <p>When install is complete:</p> <pre><code>[root@mgt1 ~]# nodedeploy d3,d4\nn1: completed: centos-8.2-x86_64-default\nn2: completed: centos-8.2-x86_64-default\n</code></pre> <p>Additionally, ssh to nodes will work:</p> <pre><code># nodeshell n1,n2 echo test\nn1: test\nn2: test\n</code></pre> <p>As will ssh between nodes:</p> <pre><code># ssh n1 ssh n2 echo test\ntest\n</code></pre>"},{"location":"getting_started/ibinstallconfluentrhel8/","title":"InfiniBand install with confluent on RHEL 8","text":"<p>Please refer to the following link for the confluent OS deployment process:</p> <p>Preparing for Operating System Deployment</p> <p>The confluent deployment process for installing over InfiniBand requires the following modifications:</p> <p>Using driver update media for RedHat/CentOS</p> <p>Occasionally for network deployment of a RHEL or CentOS the modules included in the install initrd for the OS aren\u2019t sufficient to work with the network device being installed over (for example, if the network device is very new and the driver support hasn\u2019t been added to the OS yet).  In that scenario a driver update media package for that network device can be used to provide support for that network device during and after the OS installation. In order to do that, the following should be done:</p> <ol> <li> <p>The driver update media package will typically be provided as a <code>*.iso</code> file.  This need to be wrapped into a cpio file, which may be done as follows:</p> <p><code>echo &lt;driver update media package filename&gt;.iso | cpio -H newc -o &gt; &lt;driver update media package filename&gt;.cpio</code></p> </li> <li> <p>Place the driver update package cpio file into the OS profile being deployed, in the <code>boot/initramfs</code> directory:</p> <p><code>cp &lt;driver update media package filename&gt;.cpio /var/lib/confluent/public/os/&lt;OS profile name&gt;/boot/initramfs</code></p> </li> <li> <p>In the <code>profile.yaml</code> file in the <code>var/lib/confluent/public/os/&lt;OS profile name&gt;</code> directory, add the following to the kernelargs line:</p> <p><code>dd=/&lt;driver update media package filename&gt;.iso</code></p> </li> <li> <p>Update the profile (this updates the boot.ipxe and boot.img contents with the driver update media package file and kernelargs updates):</p> <p><code>osdeploy updateboot &lt;OS profile name&gt;</code></p> </li> </ol> <p>Net config fixup postscript</p> <p>InfiniBand network configuration does not work as expected out of the box.  If not installing Mellanox OFED, the following is an example of a postscript that can be added to correct that behavior:</p> <pre><code># cat /var/lib/confluent/public/os/your-profile-here/scripts/pod.d/fixipoib\necho 'install mlx5_core /sbin/modprobe --ignore-install mlx5_core; /sbin/modprobe mlx5_ib; /sbin/modprobe ib_ipoib' &gt;&gt; /etc/modprobe.d/mlx.conf\necho 'add_drivers+=\"mlx5_ib ib_ipoib\"' &gt; /etc/dracut.conf.d/mlx.conf\ndracut -f\n</code></pre> <p>Kernel command line configuration</p> <p>Change the profile.yaml file in the the OS profile to be deployed to add:</p> <pre><code># rd.driver.pre=\"mlx5_ib,ib_ipoib\"\n</code></pre> <p>on the kernel.args line</p> <p>Then run</p> <pre><code># osdeploy updateboot &lt;OS profile name&gt;\n</code></pre>"},{"location":"getting_started/ibinstallconfluentsle152/","title":"InfiniBand install with confluent on SLE 15.2","text":"<p>Please refer to the following link for the confluent OS deployment process:</p> <p>Preparing for Operating System Deployment</p> <p>The confluent deployment process for installing over InfiniBand requires the following modifications:</p> <p>Net config fixup postscript</p> <p>InfiniBand network configuration does not work as expected out of the box.  If not installing Mellanox OFED, the following is an example of a postscript that can be added to correct that behavior:</p> <pre><code># cat /install/postscripts/fixipoib\necho 'install mlx5_core /sbin/modprobe --ignore-install mlx5_core; /sbin/modprobe mlx5_ib; /sbin/modprobe ib_ipoib' &gt;&gt; /&lt;profile dir&gt;/scripts/post.d/mlx.conf\necho 'add_drivers+=\"mlx5_ib ib_ipoib\"' &gt; /&lt;profile dir&gt;/scripts/post.d/mlx.conf\ndracut -f\n</code></pre> <p>Kernel command line configuration</p> <p>Change the profile.yaml file in the the OS profile to be deployed to add:</p> <pre><code># insmod=\"ib_ipoib\"\n</code></pre> <p>and run</p> <pre><code># osdeploy updateboot &lt;OS profile name&gt;\n</code></pre>"},{"location":"getting_started/installconfluent_rhel/","title":"Confluent Installation for Red Hat Enterprise Linux","text":"<p>Enterprise Linux 8.6 or 9.0 and higher is required for installation.</p> <p>First add the Lenovo HPC yum repository appropriate to your environment according to the procedure on the  download page.  It is suggested to then make sure there are no updates in the repository for your existing software:</p> <pre><code>yum --disablerepo=* --enablerepo=lenovo-hpc update\n</code></pre> <p>At this point, the package may be installed:</p> <pre><code>yum install lenovo-confluent\n</code></pre> <p>Next, enable it and start the confluent service:</p> <pre><code>systemctl enable confluent --now\n</code></pre> <p>At this point, source the script below for confluent command line functionality or logout and log back in. </p> <pre><code>source /etc/profile.d/confluent_env.sh\n</code></pre>"},{"location":"getting_started/installconfluent_rhel/#enabling-http-connectivity-for-os-deployment-rest-api-usage-and-the-web-ui","title":"Enabling http connectivity for OS Deployment, REST API usage, and the Web UI","text":"<p>If you have SELinux enforcing, you need to allow httpd to make network connections:</p> <pre><code>setsebool -P httpd_can_network_connect=on\n</code></pre> <p>Note that a default install also will have firewall restrictions preventing https use.  You may remedy this by doing the following:</p> <pre><code>firewall-cmd --zone=public --add-service=https --permanent\nfirewall-cmd --zone=public --add-service=https\n</code></pre> <p>Further, OS deployment uses some more ports, depending on scenario.  </p> <p>If doing any sort of network based boot (PXE/HTTP) without using an 'identity image' mounted over virtual USB, then the following is required to facilitate the API arming mechanism, as well as the SSDP port (udp port 1900) to allow deploying systems to scan for confluent servers:</p> <pre><code>firewall-cmd --permanent --zone=public --add-port=13001/tcp\nfirewall-cmd --permanent --zone=public --add-port=1900/udp\n</code></pre> <p>If doing HTTP boot with `deployment.useinsecureprotocols' set to firmware, you will need plain http (port 80):</p> <pre><code>firewall-cmd --permanent --zone=public --add-service=http --permanent\nfirewall-cmd --permanent --zone=public --add-service=http\n</code></pre> <p>If doing PXE boot, then you will need PXE and TFTP opened:</p> <pre><code>firewall-cmd --permanent --zone=public --add-port=67/udp\nfirewall-cmd --permanent --zone=public --add-port=69/udp\nfirewall-cmd --permanent --zone=public --add-port=4011/udp\n</code></pre> <p>Further, if doing network boot over IPv6:</p> <pre><code>firewall-cmd --permanent --zone=public --add-port=547/udp\n</code></pre> <p>If the web server is not already started, enable the web server:</p> <pre><code>systemctl enable httpd --now\n</code></pre>"},{"location":"getting_started/installconfluent_rhel/#web-ui-forwarding-feature","title":"Web UI Forwarding feature","text":"<p>The WebUI offers dynamic port forwarding.  To enable this feature, ensure TCP ports starting from port 3900 through however many ports you anticipate concurrently using. Otherwise, you may opt to disable the firewall:</p> <pre><code>systemctl stop firewalld\nsystemctl disable firewalld\n</code></pre>"},{"location":"getting_started/installconfluent_rhel/#web-ui-login","title":"Web UI Login","text":"<p>In terms of confluent itself, it is by default set up without any user access.  To enable a user that can ssh into your server to access the web interface:</p> <pre><code>confetty create /users/demouser role=admin\n</code></pre> <p>The user 'demouser' may now use his login password to access the confluent web interface as an administrator.  The available roles are:</p> <ul> <li>Administrator: Full access apart from reading 'secret.' attributes for all data and operations</li> <li>Operator: Removes the ability to change or add usernames or passwords in various contexts</li> <li>Monitor: Suitable for health check programs, unable to do anything to effect operation of systems, but can get power state, health, and sensor data.</li> </ul> <p>After these steps, the GUI should be available at:</p> <pre><code>https://[server]/lenovo-confluent/\n</code></pre>"},{"location":"getting_started/installconfluent_rhel/#preparing-for-discovery-if-firewall-enabled","title":"Preparing for discovery if firewall enabled","text":"<p>If wanting to use the confluent discovery capabilities and you have a firewall enabled, further firewall configuration is required. First, check /etc/firewalld/firewalld.conf and ensure that the FirewallBackend is set to iptables, as the multicast reply rules require it.  With that configured, here are example commands to allow discovery to work when managed by firewalld:</p> <pre><code>firewall-cmd --permanent --new-ipset=confluentv4 --type=hash:ip,port --option timeout=3\nfirewall-cmd --permanent --new-ipset=confluentv6 --type=hash:ip,port --option timeout=3 --family inet6\nfirewall-cmd --reload\nfirewall-cmd --permanent --direct --add-rule ipv6 filter OUTPUT 1 -p udp -m udp --dport 427 -j SET --add-set confluentv6 src,src --exist\nfirewall-cmd --permanent --direct --add-rule ipv4 filter OUTPUT 1 -p udp -m udp --dport 427 -j SET --add-set confluentv4 src,src --exist\nfirewall-cmd --permanent --direct --add-rule ipv6 filter OUTPUT 1 -p udp -m udp --dport 1900 -j SET --add-set confluentv6 src,src --exist\nfirewall-cmd --permanent --direct --add-rule ipv4 filter OUTPUT 1 -p udp -m udp --dport 1900 -j SET --add-set confluentv4 src,src --exist\nfirewall-cmd --permanent --direct --add-rule ipv4 filter INPUT 1 -p udp -m set --match-set confluentv4 dst,dst -j ACCEPT\nfirewall-cmd --permanent --direct --add-rule ipv6 filter INPUT 1 -p udp -m set --match-set confluentv6 dst,dst -j ACCEPT\nfirewall-cmd --zone=public --add-port=427/udp --permanent\nfirewall-cmd --zone=public --add-port=1900/udp --permanent\nfirewall-cmd --zone=public --add-service=dhcp --permanent\nfirewall-cmd --reload\n</code></pre>"},{"location":"getting_started/installconfluent_rhel/#getting-ready-to-use-confluent","title":"Getting ready to use confluent","text":"<p>Proceed to configuring confluent for information on adding groups and nodes.</p>"},{"location":"getting_started/installconfluent_suse/","title":"Confluent Installation for SUSE Linux Enterprise","text":"<p>SuSE Linux Enterprise 15 SP4 or higher is currently required for installation.</p> <p>After adding the correct repository as indicated in the download page, you can install confluent by doing:</p> <pre><code>zypper install lenovo-confluent\n</code></pre> <p>At which point go ahead and enable it and start it.</p> <pre><code>systemctl enable confluent --now\n</code></pre> <p>At this point, source the script below for confluent command line functionality or logout and log back in. </p> <pre><code>source /etc/profile.d/confluent_env.sh\n</code></pre>"},{"location":"getting_started/installconfluent_suse/#enabling-the-web-ui","title":"Enabling the Web UI","text":""},{"location":"getting_started/installconfluent_suse/#enable-secure-webserver-with-ssl","title":"Enable Secure WebServer with SSL","text":"<p>If not otherwise enabling and configuring TLS, then the following will activate a TLS configuration:    </p> <pre><code>cd /etc/apache2/vhosts.d/\ncp vhost-ssl.template mySSL.conf\n</code></pre> <p>Use osdeploy to create TLS certificate:</p> <pre><code>osdeploy initialize -t\n</code></pre> <p>Enable SSL on Apache</p> <pre><code>a2enmod rewrite\na2enflag SSL\nsystemctl enable apache2 --now\n</code></pre> <p>In terms of confluent itself, it is by default set up without any user access.  To enable a user that can ssh into your server to access the web interface:</p> <pre><code>confetty create /users/demouser role=admin\n</code></pre> <p>The user 'demouser' may now use his login password to access the confluent web interface as an administrator.  The available roles are:</p> <ul> <li>Administrator: Full access apart from reading 'secret.' attributes for all data and operations</li> <li>Operator: Removes the ability to change or add usernames or passwords in various contexts</li> <li>Monitor: Suitable for health check programs, unable to do anything to effect operation of systems, but can get power state, health, and sensor data.</li> </ul> <p>After these steps, the GUI should be available at:</p> <pre><code>https://[server]/lenovo-confluent/\n</code></pre>"},{"location":"getting_started/installconfluent_suse/#getting-ready-to-use-confluent","title":"Getting ready to use confluent","text":"<p>Proceed to configuring confluent  for information on adding groups and nodes.</p>"},{"location":"getting_started/installconfluent_ubuntu/","title":"Confluent Installation for Ubuntu","text":"<p>Ubuntu Linux 22.04 or 24.04 is supported for installation.</p> <p>After adding the correct repository as indicated in the download page, you can install confluent by doing:</p> <pre><code>apt install lenovo-confluent\n</code></pre> <p>At which point go ahead and enable it and start it.</p> <pre><code>systemctl enable confluent --now\n</code></pre> <p>At this point, source the script below for confluent command line functionality or logout and log back in. </p> <pre><code>source /etc/profile.d/confluent_env.sh\n</code></pre>"},{"location":"getting_started/installconfluent_ubuntu/#enabling-support-for-pxe","title":"Enabling support for PXE","text":"<p>Prior to running osdeploy, it is suggested to install a tftp server.  The following will install a tftp server with socket activation, which is generally adequate:</p> <pre><code>apt install tftpd-hpa\n</code></pre>"},{"location":"getting_started/installconfluent_ubuntu/#enabling-the-web-ui-or-deployment-api","title":"Enabling the Web UI or Deployment API","text":""},{"location":"getting_started/installconfluent_ubuntu/#enable-secure-webserver-with-ssl","title":"Enable Secure WebServer with SSL","text":"<p>If not otherwise enabling and configuring TLS, then the following will activate a TLS configuration:    </p> <pre><code>a2enmod ssl\na2ensite default-ssl.conf\n</code></pre> <p>Also, enable the confluent web configuration:</p> <pre><code>a2enconf confluent\n</code></pre> <p>Use osdeploy to create TLS certificate:</p> <pre><code>osdeploy initialize -t\n</code></pre> <p>In terms of confluent itself, it is by default set up without any user access.  To enable a user that can ssh into your server to access the web interface:</p> <pre><code>confetty create /users/demouser role=admin\n</code></pre> <p>The user 'demouser' may now use his login password to access the confluent web interface as an administrator.  The available roles are:</p> <ul> <li>Administrator: Full access apart from reading 'secret.' attributes for all data and operations</li> <li>Operator: Removes the ability to change or add usernames or passwords in various contexts</li> <li>Monitor: Suitable for health check programs, unable to do anything to effect operation of systems, but can get power state, health, and sensor data.</li> </ul> <p>After these steps, the GUI should be available at:</p> <pre><code>https://[server]/lenovo-confluent/\n</code></pre>"},{"location":"getting_started/installconfluent_ubuntu/#getting-ready-to-use-confluent","title":"Getting ready to use confluent","text":"<p>Proceed to configuring confluent  for information on adding groups and nodes.</p>"},{"location":"manuals/","title":"Confluent command man pages","text":"<ul> <li>collate</li> <li>collective</li> <li>confetty</li> <li>confluent</li> <li>confluent2hosts</li> <li>confluentdbutil</li> <li>nodeapply</li> <li>nodeattrib</li> <li>nodeattribexpressions</li> <li>nodebmcpassword</li> <li>nodebmcreset</li> <li>nodeboot</li> <li>nodeconfig</li> <li>nodeconsole</li> <li>nodedefine</li> <li>nodedeploy</li> <li>nodediscover</li> <li>nodeeventlog</li> <li>nodefirmware</li> <li>nodegroupattrib</li> <li>nodegroupdefine</li> <li>nodegrouplist</li> <li>nodegroupremove</li> <li>nodehealth</li> <li>nodeidentify</li> <li>nodeinventory</li> <li>nodel2traceroute</li> <li>nodelicense</li> <li>nodelist</li> <li>nodemedia</li> <li>nodeping</li> <li>nodepower</li> <li>noderange</li> <li>noderemove</li> <li>nodereseat</li> <li>nodersync</li> <li>noderun</li> <li>nodesensors</li> <li>nodesetboot</li> <li>nodeshell</li> <li>nodestorage</li> <li>nodesupport</li> <li>osdeploy</li> <li>stats</li> </ul>"},{"location":"manuals/collate/","title":"collate(1) -- Organize text input by node","text":""},{"location":"manuals/collate/#synopsis","title":"SYNOPSIS","text":"<p><code>&lt;var&gt;other command&lt;/var&gt; | collate [-a] [-b] [-d] [-w] [-g] [-s] [-c] [-r] [-l lognametemplate]</code></p>"},{"location":"manuals/collate/#description","title":"DESCRIPTION","text":"<p>collate takes input in the form of nodename: data and groups the output for each nodename together, and checks for identical data to further group nodes together. Output groups are sorted in descending size such that the topmost group is the largest, and the last output group is the smallest.  In the event of equally sized output groups, the groups are sorted alphanumerically by their header, and each header has node and group names sorted alphanumerically.</p>"},{"location":"manuals/collate/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-a</code>, <code>--abbreviate</code>:    Use confluent to attempt to shorten the noderange.  This can help identify    when output differs along a telling group boundary.  For example, if    output suggests a large number of nodes are unreachable, abbreviate    showing 'rack1' as being unreachable may make more obvious a possible cause.</p> </li> <li> <p><code>-b BASE</code>, <code>--base=BASE</code>:    Use given node as reference for comparison when using    -d, instead of using the most common result      </p> </li> <li> <p><code>-d</code>, <code>--diff</code>:    Express all but the most common result group in terms of diff from    the most common result group</p> </li> <li> <p><code>-w</code>, <code>--watch</code>:    Update results dynamically as data becomes available, rather than    waiting    for the command to fully complete.</p> </li> <li> <p><code>-g</code>, <code>--groupcount</code>:    Show count of output groups rather than the actual    output</p> </li> <li> <p><code>-s</code>, <code>--skipcommon</code>:    Suppress printing of the most common result text group.  This is used to    focus on stray output against a well known and expected result.</p> </li> <li> <p><code>-c</code>, <code>--count</code>:    Print a count of the number of nodes in an output group under the     noderange.</p> </li> <li> <p><code>-r</code>, <code>--reverse</code>:    Rather than starting with most common to least common, start with    the least common and print the most common last.</p> </li> <li> <p><code>-l LOG</code>, <code>--log=LOG</code>:    Save output per node to individual log files, replacing {node} in the name    with the nodename of each</p> </li> <li> <p><code>-h</code>, <code>--help</code>:    Show help message and exit   </p> </li> </ul>"},{"location":"manuals/collate/#examples","title":"EXAMPLES","text":"<ul> <li> <p>Organizing power state of multiple nodes: <code># nodepower n1-n12 | collate</code> <code>====================================</code> <code>n1,n2,n3,n4,n7,n8,n9,n10,n11,n12</code> <code>====================================</code> <code>on</code> <code></code> <code>====================================</code> <code>n5,n6</code> <code>====================================</code> <code>off</code> </p> </li> <li> <p>Using diff to detect distinct UEFI configuration</p> </li> </ul> <p><code># pasu n1-n4 show Processors|collate -d -s</code> <code>====================================</code> <code>n3</code> <code>====================================</code> <code>@@</code> <code>Processors.ProcessorPerformanceStates=Enable</code> <code>Processors.C-States=Enable</code> <code>Processors.PackageACPIC-StateLimit=ACPI C3</code> <code>- Processors.C1EnhancedMode=Enable</code> <code>+ Processors.C1EnhancedMode=Disable</code> <code>- Processors.Hyper-Threading=Enable</code> <code>+ Processors.Hyper-Threading=Disable</code> <code>Processors.ExecuteDisableBit=Enable</code> <code>Processors.IntelVirtualizationTechnology=Enable</code> <code></code> <code>====================================</code> <code>n1</code> <code>====================================</code> <code>@@</code> <code>Processors.ProcessorPerformanceStates=Enable</code> <code>Processors.C-States=Enable</code> <code>Processors.PackageACPIC-StateLimit=ACPI C3</code> <code>- Processors.C1EnhancedMode=Enable</code> <code>+ Processors.C1EnhancedMode=Disable</code> <code>Processors.Hyper-Threading=Enable</code> <code>Processors.ExecuteDisableBit=Enable</code> </p>"},{"location":"manuals/collective/","title":"collective(1) -- Check and manage a confluent collective","text":""},{"location":"manuals/collective/#synopsis","title":"SYNOPSIS","text":"<p><code>collective invite &lt;var&gt;server&lt;/var&gt;</code> <code>collective join &lt;var&gt;server&lt;/var&gt; [-i TOKEN]</code> <code>collective show</code> <code>collective gencert</code> <code>collective delete</code> </p>"},{"location":"manuals/collective/#description","title":"DESCRIPTION","text":"<p>collective helps manage the collective mode of confluent, where multiple confluent servers are linked together to act as one.  For example, the procedure to set up a collective to run on three servers called mgt1, mgt2, and mgt3, first install and start confluent as usual on the three servers.  On mgt1, run <code>collective invite mgt2</code> and an invitation token will be output.  On mgt2, either run <code>collective join mgt1</code> to paste the token interactively, or <code>collective join mgt1 -i &lt;var&gt;token&lt;/var&gt;</code>.  At this point, either mgt1 or mgt2 can bring in mgt3.  For example on mgt2 run <code>collective invite mgt3</code> and on mgt3 run <code>collective join mgt2 -i &lt;var&gt;token&lt;/var&gt;</code></p> <p>This can be linked together in the following manner with ssh: on mgt1:   <code># ssh mgt2 collective join mgt1 -i $(collective invite mgt2)</code></p> <p>Note that a collective is only redundant with 3 or more members.  The collective will function so long as more than half of the members are online.  A collective of two members is supported, but without redundancy.</p> <p>Also note that the collective leader role is dynamic, but has no impact on interacting with confluent.  It is merely an internal role that can dynamically change depending on circumstances.</p>"},{"location":"manuals/collective/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-i</code>:     Provide the token as an argument rather than interactively.</p> </li> <li> <p><code>-h</code>, <code>--help</code>:   Show help message and exit    </p> </li> </ul>"},{"location":"manuals/collective/#examples","title":"EXAMPLES","text":"<ul> <li> <p>Inviting a server called mgt2:   <code># collective invite mgt2</code> <code>bWd0MkA+BNQ6XAxMXlqJJa+EQRlihL/k9xCXnasgSQXZr989Pa1/ln7G3e1Ncxx6BMzMqqreHJVkPr2FrzjNit/UgHlg</code> </p> </li> <li> <p>On mgt2, joining mgt1:   <code># collective join mgt1 -i bWd0MkA+BNQ6XAxMXlqJJa+EQRlihL/k9xCXnasgSQXZr989Pa1/ln7G3e1Ncxx6BMzMqqreHJVkPr2FrzjNit/UgHlg</code> <code>Success</code> </p> </li> <li> <p>Showing the collective state:   <code># collective show</code> <code>Quorum: True</code> <code>Leader: mgt1</code> <code>Active collective members:</code> <code>mgt2</code> </p> </li> </ul>"},{"location":"manuals/confetty/","title":"confetty(8) --- Interactive confluent client","text":""},{"location":"manuals/confetty/#synopsis","title":"SYNOPSIS","text":"<p><code>confetty</code> <code>confetty &lt;var&gt;confetty command line&lt;/var&gt;</code></p>"},{"location":"manuals/confetty/#description","title":"DESCRIPTION","text":"<p>confetty launches an interactive CLI session to the confluent service.  It provides a filesystem-like view of the confluent interface.  It is intended to be mostly an aid for developing client software, with day to day administration generally being easier with the various function specific commands.</p>"},{"location":"manuals/confetty/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-s SERVER:PORT</code>, <code>--server=SERVER:PORT</code>:   Confluent instance to connect to</p> </li> <li> <p><code>-c PATH</code>, <code>--control=PATH</code>:   Path to offer terminal control</p> </li> <li> <p><code>-m MINTIME</code>, <code>--mintime=MINTIME</code>:   Minimum time to run or else pause for input (used to   keep a terminal from closing quickly on error)</p> </li> <li> <p><code>-h</code>, <code>--help</code>:   Show help message and exit  </p> </li> </ul>"},{"location":"manuals/confetty/#commands","title":"COMMANDS","text":"<p>The CLI may be navigated by shell commands and some other commands.</p> <ul> <li><code>cd</code>:   Change the location within the tree</li> <li><code>ls</code>:   List the elements within the current directory/tree</li> <li><code>show</code> ELEMENT, <code>cat</code> ELEMENT:   Display the result of reading a specific element (by full or relative path)</li> <li><code>unset</code> ELEMENT ATTRIBUTE   For an element with attributes, request to clear the value of the attribue</li> <li><code>set</code> ELEMENT ATTRIBUTE=VALUE   Set the specified attribute to the given value</li> <li><code>start</code> ELEMENT   Start a console session indicated by ELEMENT (e.g. /nodes/n1/console/session)</li> <li><code>rm</code> ELEMENT   Request removal of an element.  (e.g. rm events/hardware/log clears log from a node)</li> </ul>"},{"location":"manuals/confluent/","title":"confluent(8) -- Start the confluent server","text":""},{"location":"manuals/confluent/#synopsis","title":"SYNOPSIS","text":"<p><code>confluent</code></p>"},{"location":"manuals/confluent/#description","title":"DESCRIPTION","text":"<p>confluent is the name of the server daemon.  It is normally run through the init subsystem rather than executed directly.  All confluent commands connect to confluent daemon.  It provides the web interface, debug, and unix socket connectivity.</p>"},{"location":"manuals/confluent2hosts/","title":"confluent2hosts(8) -- Generate /etc/hosts entries for nodes","text":""},{"location":"manuals/confluent2hosts/#synopsis","title":"SYNOPSIS","text":"<p><code>confluent2hosts -i &lt;var&gt;ip expression&lt;/var&gt; -n &lt;var&gt;name expression&lt;/var&gt; &lt;var&gt;noderange&lt;/var&gt;</code> <code>confluent2hosts -a &lt;var&gt;noderange&lt;/var&gt;</code> </p>"},{"location":"manuals/confluent2hosts/#description","title":"DESCRIPTION","text":"<p><code>confluent2hosts</code> can be used to help generate /etc/hosts entries for a  noderange.  There are two general approaches.</p> <p>It can be used ad-hoc, using -i and -n to specify the address and name portions respectively.  This accepts the standard confluent expression syntax, allowing for things like 172.30.1.{n1} or {node}.{dns.domain} or {bmc}.</p> <p>It can also read from the confluent db, using <code>-a</code>.  In this mode, each net.value.attribute group is pulled together into hosts lines.  ipv4_address and ipv6_address fields are associated with the corresponding hostname attributes. You can use <code>-f</code> to put the FQDN first.</p>"},{"location":"manuals/confluent2hosts/#examples","title":"EXAMPLES","text":"<ul> <li> <p>Generate /etc/hosts entries ad-hoc using default name:   <code># confluent2hosts -i 10.2.3.{n1} d9-d12</code> </p> </li> <li> <p>Generate /etc/hosts entries ad-hoc using alternative name:   <code># confluent2hosts -i 10.2.3.{n1} -n \"{node}-alt {node}-alt.{dns.domain}\" d9-d12</code> </p> </li> <li> <p>Generate /etc/hosts entries using the confluent DB as a reference:   <code># confluent2hosts -a d9-d12</code> </p> </li> </ul>"},{"location":"manuals/confluentdbutil/","title":"confluentdbutil(8) -- Backup or restore confluent database","text":""},{"location":"manuals/confluentdbutil/#synopsis","title":"SYNOPSIS","text":"<p><code>confluentdbutil [options] [dump|restore] &lt;var&gt;path&lt;/var&gt;</code></p>"},{"location":"manuals/confluentdbutil/#description","title":"DESCRIPTION","text":"<p>confluentdbutil is a utility to export/import the confluent attributes to/from json files.  The path is a directory that holds the json version. In order to perform restore, the confluent service must not be running.  It is required to indicate how to treat the usernames/passwords are treated in the json files (password protected, removed from the files, or unprotected).</p>"},{"location":"manuals/confluentdbutil/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-p PASSWORD</code>, <code>--password=PASSWORD</code>:   If specified, information such as usernames and passwords will be encrypted   using the given password.</p> </li> <li> <p><code>-i</code>, <code>--interactivepassword</code>:   Prompt for password.  </p> </li> <li> <p><code>-r</code>, <code>--redact</code>:   Indicates to replace usernames and passwords with a dummy string rather   than included.</p> </li> <li> <p><code>-u</code>, <code>--unprotected</code>:   The keys.json file will include the encryption keys without any protection.</p> </li> <li> <p><code>-s</code>, <code>--skipkeys</code>:   This specifies to dump the encrypted data without   dumping the keys needed to decrypt it.  This is   suitable for an automated incremental backup, where an   earlier password protected dump has a protected   keys.json file, and only the protected data is needed.   keys do not change and as such they do not require   incremental backup.</p> </li> <li> <p><code>-y</code>, `--yaml   Use YAML instead of JSON as file format</p> </li> <li> <p><code>-h</code>, <code>--help</code>:   Show help message and exit</p> </li> </ul>"},{"location":"manuals/nodeapply/","title":"nodeapply(8) -- Execute command on many nodes in a noderange through ssh","text":""},{"location":"manuals/nodeapply/#synopsis","title":"SYNOPSIS","text":"<p><code>nodeapply [options] &lt;var&gt;noderange&lt;/var&gt;</code></p>"},{"location":"manuals/nodeapply/#description","title":"DESCRIPTION","text":"<p>Provides shortcut access to a number of common operations against deployed nodes.  These operations include refreshing ssh certificates and configuration, rerunning syncflies, and executing specified postscripts.</p>"},{"location":"manuals/nodeapply/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-k</code>, <code>--security</code>   Refresh SSH configuration (hosts.equiv and node SSH certificates)</p> </li> <li> <p><code>-F</code>, <code>--sync</code>   Rerun syncfiles from deployed profile</p> </li> <li> <p><code>-P SCRIPTS</code>, <code>--scripts=SCRIPTS</code>   Re-run specified scripts, with full path under scripts specified, e.g. post.d/scriptname,firstboot.d/otherscriptname</p> </li> <li> <p><code>-c COUNT</code>, <code>-f COUNT</code>, <code>--count=COUNT</code>   Specify the maximum number of instances to run concurrently</p> </li> <li> <p><code>-m MAXNODES</code>, <code>--maxnodes=MAXNODES</code>   Specify a maximum number of nodes to run remote ssh command to, prompting   if over the threshold</p> </li> </ul>"},{"location":"manuals/nodeattrib/","title":"nodeattrib(8) -- List or change confluent nodes attributes","text":""},{"location":"manuals/nodeattrib/#synopsis","title":"SYNOPSIS","text":"<p><code>nodeattrib [-b] &lt;var&gt;noderange&lt;/var&gt; [all|&lt;var&gt;nodeattribute&lt;/var&gt;...]</code> <code>nodeattrib &lt;var&gt;noderange&lt;/var&gt; [&lt;var&gt;nodeattribute1=value1&lt;/var&gt; &lt;var&gt;nodeattribute2=value2&lt;/var&gt; ...]</code> <code>nodeattrib -c &lt;var&gt;noderange&lt;/var&gt; &lt;var&gt;nodeattribute1&lt;/var&gt; &lt;var&gt;nodeattribute2&lt;/var&gt; ...</code> <code>nodeattrib -e &lt;var&gt;noderange&lt;/var&gt; &lt;var&gt;nodeattribute1&lt;/var&gt; &lt;var&gt;nodeattribute2&lt;/var&gt; ...</code> <code>nodeattrib -p &lt;var&gt;noderange&lt;/var&gt; &lt;var&gt;nodeattribute1&lt;/var&gt; &lt;var&gt;nodeattribute2&lt;/var&gt; ...</code> <code>nodeattrib &lt;var&gt;noderange&lt;/var&gt; -s &lt;attributes.batch&gt; ...</code> </p>"},{"location":"manuals/nodeattrib/#description","title":"DESCRIPTION","text":"<p>nodeattrib manages the attributes of confluent nodes.  In the simplest form, it simply takes the given noderange(5) and lists the matching nodes, one line at a time.</p> <p>If a list of node attribute names are given, the value of those are also displayed.  If <code>-b</code> is specified, it will also display information on how inherited and expression based attributes are defined.  Attributes can be straightforward values, or an expression as documented in nodeattribexpressions(5). For a full list of attributes, run <code>nodeattrib &lt;var&gt;node&lt;/var&gt; all</code> against a node. If <code>-c</code> is specified, this will set the nodeattribute to a null value. This is different from setting the value to an empty string.</p> <p>Attributes may be specified by wildcard, for example <code>net.*switch</code> will report all attributes that begin with <code>net.</code> and end with <code>switch</code>.</p> <p>If the word all is specified, then all available attributes are given. Omitting any attribute name or the word 'all' will display only attributes that are currently set.</p> <p>For the <code>groups</code> attribute, it is possible to add a group by doing <code>groups,=&lt;var&gt;newgroup&lt;/var&gt;</code> and to remove by doing <code>groups^=&lt;var&gt;oldgroup&lt;/var&gt;</code></p> <p>Note that <code>nodeattrib &lt;var&gt;group&lt;/var&gt;</code> will likely not provide the expected behavior. See nodegroupattrib(8) command on how to manage attributes on a group level.  Running nodeattrib on a group will simply set node-specific attributes on each individual member of the group.</p> <p>Additionally, if wanting to change from a node level attribute value to inherit from a member group, it is required to use '-c' to clear the attribute.  Conversely, assigning to a blank value will allow masking a group defined attribute with an empty value.</p>"},{"location":"manuals/nodeattrib/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-b</code>, <code>--blame</code>:   Annotate inherited and expression based attributes to show their base value.</p> </li> <li> <p><code>-c</code>, <code>--clear</code>:   Clear specified nodeattributes.</p> </li> <li> <p><code>-e</code>, <code>--environment</code>:   Set specified attributes based on exported environment variable of matching name.    Environment variable names may be lower case or all upper case.    Replace . with _ as needed (e.g. info.note may be specified as either $info_note or $INFO_NOTE)</p> </li> <li> <p><code>-p</code>, <code>--prompt</code>:   Request interactive prompting to provide values rather than the command line   or environment variables.</p> </li> <li> <p><code>-s</code>, <code>--set</code>:   Set attributes using a batch file rather than the command line. The attributes in the batch file    can be specified as one line of key=value pairs simmilar to command line or each attribute can   be in its own line. Lines that start with # sign will be read as a comment. See EXAMPLES for batch   file syntax.   </p> </li> <li> <p><code>-m MAXNODES</code>, <code>--maxnodes=MAXNODES</code>:   Prompt if trying to set attributes on more than   specified number of nodes.</p> </li> <li> <p><code>-h</code>, <code>--help</code>:   Show help message and exit</p> </li> </ul>"},{"location":"manuals/nodeattrib/#examples","title":"EXAMPLES","text":"<ul> <li> <p>Listing matching nodes of a simple noderange:     <code># nodeattrib n1-n2</code> <code>n1: console.method: ipmi</code> <code>n1: hardwaremanagement.manager: 172.30.3.1</code> <code>n2: console.method: ipmi</code> <code>n2: hardwaremanagement.manager: 172.30.3.2</code> </p> </li> <li> <p>Getting an attribute of nodes matching a noderange:     <code># nodeattrib n1,n2 hardwaremanagement.manager</code> <code>n1: hardwaremanagement.manager: 172.30.3.1</code> <code>n2: hardwaremanagement.manager: 172.30.3.2</code> </p> </li> <li> <p>Getting a group of attributes while determining what group defines them:     <code># nodeattrib n1,n2 hardwaremanagement --blame</code> <code>n1: hardwaremanagement.manager: 172.30.3.1</code> <code>n1: hardwaremanagement.method: ipmi (inherited from group everything)</code> <code>n1: net.switch: r8e1</code> <code>n1: net.switchport: 14</code> <code>n2: hardwaremanagement.manager: 172.30.3.2</code> <code>n2: hardwaremanagement.method: ipmi (inherited from group everything)</code> <code>n2: net.switch: r8e1</code> <code>n2: net.switchport: 2</code> </p> </li> <li> <p>Listing matching nodes of a simple noderange that are set:     <code># nodeattrib n1-n2 current</code> <code>n1: console.method: ipmi</code> <code>n1: hardwaremanagement.manager: 172.30.3.1</code> <code>n2: console.method: ipmi</code> <code>n2: hardwaremanagement.manager: 172.30.3.2</code> </p> </li> <li> <p>Change attribute on nodes of a simple noderange:     <code># nodeattrib n1-n2 console.method=serial</code> <code>n1: console.method: serial</code> <code>n1: hardwaremanagement.manager: 172.30.3.1</code> <code>n2: console.method: serial</code> <code>n2: hardwaremanagement.manager: 172.30.3.2</code> </p> </li> <li> <p>Clear attribute on nodes of a simple noderange, if you want to retain the variable set the attribute to \"\":     <code># nodeattrib n1-n2 -c console.method</code> <code># nodeattrib n1-n2 console.method</code> <code>n1: console.method:</code> <code>n2: console.method:</code> </p> </li> <li> <p>List all switches that a node is described as connected to:     <code># nodeattrib d1 net.*switch</code> <code>d1: net.mgt.switch: mgtswitch1</code> <code>d1: net.pxe.switch: pxeswitch1</code> <code>d1: net.switch:</code> </p> </li> <li> <p>Setting attributes using a batch file with syntax similar to command line:     <code># cat nodeattributes.batch</code> <code># power</code> <code>power.psu1.outlet=3 power.psu1.pdu=pdu2</code> <code># nodeattrib n41 -s nodeattributes.batch</code> <code>n41: 3</code> <code>n41: pdu2</code></p> </li> <li> <p>Setting attributes using a batch file with syntax where each attribute is in its own line:     <code># cat nodeattributes.batch</code> <code># management</code> <code>custom.mgt.switch=switch_main</code> <code>custom.mgt.switch.port=swp4</code> <code># nodeattrib n41 -s nodeattributes.batch</code> <code>n41: switch_main</code> <code>n41: swp4</code></p> </li> </ul>"},{"location":"manuals/nodeattrib/#see-also","title":"SEE ALSO","text":"<p>nodegroupattrib(8), nodeattribexpressions(5)</p>"},{"location":"manuals/nodeattrib/#attributes","title":"ATTRIBUTES","text":"<ul> <li> <p><code>collective.manager</code>:   When in collective mode, the member of the collective currently considered to be responsible for this node.  At a future date, this may be modified automatically if another attribute indicates candidate managers, either for high availability or load balancing purposes.</p> </li> <li> <p><code>collective.managercandidates</code>:   A noderange of nodes permitted to be a manager for the node. This controls failover and deployment.  If not defined, all managers may deploy and no automatic failover will be performed. Using this requires that collective members be defined as nodes for noderange expansion</p> </li> <li> <p><code>console.logging</code>:   Indicate logging level to apply to console. Defaults to \"full\".</p> <p>Valid values: 'full', 'memory', 'interactive', 'none'</p> </li> <li> <p><code>console.method</code>:   Indicate the method used to access the console of the managed node.  If not specified, then console is disabled.  \"ipmi\" should be specified for most systems if console is desired.</p> <p>Valid values: 'ssh', 'ipmi', 'openbmc', 'tsmsol', 'vcenter'</p> </li> <li> <p><code>crypted.grubpassword</code>:   Password required to modify grub behavior at boot</p> </li> <li> <p><code>crypted.rootpassword</code>:   The password of the local root password. This is stored as a non-recoverable hash. If unspecified and confluent is used to deploy, then login at console using password will be impossible and only key based login can work for root.</p> </li> <li> <p><code>crypted.selfapikey</code>:   Crypt of api key for self api requests by node</p> </li> <li> <p><code>deployment.apiarmed</code>:   Indicates whether the node authentication token interface is armed.  If set to once, it will grant only the next request. If set to continuous, will allow many requests, which greatly reduces security, particularly when connected to untrusted networks. Should not be set unless an OS deployment is pending on the node. Generally this is not directly modified, but is modified by the \"nodedeploy\" command</p> <p>Valid values: 'once', 'continuous', ''</p> </li> <li> <p><code>deployment.encryptboot</code>:   Specify a strategy for encrypting the volume. Support for this setting is currently only enabled for RedHat 8 and CentOS 8 profiles. If blank or unset, no encryption is done. If set to \"tpm2\" then the OS will freely decrypt so long as the same Trusted Platform Module is available to decrypt the volume. Note that versions earlier than 8.2 may malfunction at boot time if this feature is attempted, depending on configuration.</p> <p>Valid values: 'tpm2', 'none', ''</p> </li> <li> <p><code>deployment.lock</code>:   Indicates whether deployment actions should be impeded. If locked, it indicates that a pending profile should not be applied. If \"autolock\", then locked will be set when current pending deployment completes. </p> <p>Valid values: 'autolock', 'locked'</p> </li> <li> <p><code>deployment.pendingprofile</code>:   An OS profile that is pending deployment.  This indicates to the network boot subsystem what should be offered when a potential network boot request comes in</p> </li> <li> <p><code>deployment.profile</code>:   The profile that has most recently reported completion of deployment. Note that an image may opt to leave itself both current and pending, for example a stateless profile would be both after first boot.</p> </li> <li> <p><code>deployment.sealedapikey</code>:   This attribute is used by some images to save a sealed version of a node apikey, so that a subsequent run with same TPM2 will use the TPM2 to protect the API key rather than local network verification. If this is set, then an api key request will receive this if the api key grant is not armed</p> </li> <li> <p><code>deployment.stagedprofile</code>:   A profile that has been staged, but is awaiting final boot to be activated. This allows an OS profile to remove itself from netboot without indicating completion to any watcher.</p> </li> <li> <p><code>deployment.state</code>:   Profiles may push more specific state, for example, it may set the state to \"failed\" or \"succeded\"</p> </li> <li> <p><code>deployment.state_detail</code>:   Detailed state information as reported by an OS profile, when available</p> </li> <li> <p><code>deployment.useinsecureprotocols</code>:   What phase(s) of boot are permitted to use insecure protocols (TFTP and HTTP without TLS.  By default, only HTTPS is used.  However this is not compatible with most firmware in most scenarios.  Using \"firmware\" as the setting will still use HTTPS after the initial download, though be aware that a successful attack during the firmware phase will negate future TLS protections.  The value \"always\" will result in tftp/http being used for most of the deployment.  The value \"never\" will allow HTTPS only. Note that Ubuntu will still use HTTP without TLS for a phase of the installation process.</p> <p>Valid values: 'always', 'firmware', 'never'</p> </li> <li> <p><code>discovery.nodeconfig</code>:   Set of nodeconfig arguments to apply after automatic discovery</p> </li> <li> <p><code>discovery.passwordrules</code>:   Any specified rules shall be configured on the BMC upon discovery.  \"expiration=no,loginfailures=no,complexity=no,reuse=no\" would disable password expiration, login failures triggering a lockout, password complexity requirements,and any restrictions around reusing an old password.</p> <p>Valid values: 'expiration', 'loginfailures', 'complexity', 'reuse'</p> </li> <li> <p><code>discovery.policy</code>:   Policy to use for auto-configuration of discovered and identified nodes. \"manual\" means nodes are detected, but not autoconfigured until a user approves. \"permissive\" indicates to allow discovery, so long as the node has no existing public key. \"open\" allows discovery even if a known public key is already stored</p> <p>Valid values: 'manual', 'permissive', 'pxe', 'open', 'verified'</p> </li> <li> <p><code>dns.domain</code>:   DNS Domain searched by default by the system</p> </li> <li> <p><code>dns.servers</code>:   DNS Server or servers to provide to node</p> </li> <li> <p><code>enclosure.bay</code>:   The bay in the enclosure, if any</p> </li> <li> <p><code>enclosure.extends</code>:   When using an extendable enclosure, this is the node representing the manager that is one closer to the uplink.</p> </li> <li> <p><code>enclosure.manager</code>:   The management device for this node's chassis</p> </li> <li> <p><code>groups</code>:   List of static groups for which this node is considered a member</p> </li> <li> <p><code>hardwaremanagement.manager</code>:   The management address dedicated to this node.  This is the address of, for example, the Lenovo XCC.  It may optionally include /prefixlen CIDR suffix to indicate subnet length, which is autodetected by default where possible.</p> </li> <li> <p><code>hardwaremanagement.method</code>:   The method used to perform operations such as power control, get sensor data, get inventory, and so on. ipmi is used if not specified.</p> </li> <li> <p><code>hardwaremanagement.port</code>:   The port the BMC should be configured to connect to network.  This only has effect during deployment and does not apply to out of band discovery. Example values include \"ocp\", \"ml2\", \"lom\" (for on board port shared with operating system), or \"dedicated\"</p> </li> <li> <p><code>hardwaremanagement.vlan</code>:   The vlan that a BMC should be configured to tag traffic. This only has effect during OS deployment and does not apply to out of band discovery.</p> </li> <li> <p><code>id.model</code>:   The model number of a node.  In scenarios where there is both a name and a model number, it is generally expected that this would be the generally more specific model number.</p> </li> <li> <p><code>id.serial</code>:   The manufacturer serial number of node</p> </li> <li> <p><code>id.uuid</code>:   The UUID of the node as presented in DMI.</p> </li> <li> <p><code>info.note</code>:   A field used for administrators to make arbitrary notations about nodes. This is meant entirely for human use and not programmatic use, so it can be freeform text data without concern for issues in how the server will process it.</p> </li> <li> <p><code>location.height</code>:   Height in RU of the system (defaults to query the systems)</p> </li> <li> <p><code>location.rack</code>:   Rack number of the rack the node is in</p> </li> <li> <p><code>location.room</code>:   Room description for the node</p> </li> <li> <p><code>location.row</code>:   Row description for the rack the node is in</p> </li> <li> <p><code>location.u</code>:   Position in the rack of the node</p> </li> <li> <p><code>net.bootable</code>:   Whether or not the indicated network interface is to be used for booting.  This is used by the discovery process to decide where to place the mac address of a detected PXE nic.</p> </li> <li> <p><code>net.connection_name</code>:   Name to use when specifiying a name for connection and/or interface name for a team.  This may be the name of a team interface, the connection name in network manager for the interface, or may be installed as an altname as supported by the respective OS deployment profiles.  Default is to accept default name for a team consistent with the respective OS, or to use the matching original port name as connection name.</p> </li> <li> <p><code>net.hostname</code>:   Used to specify hostnames per interface. Can be a comma delimited list to indicate aliases</p> </li> <li> <p><code>net.hwaddr</code>:   The hardware address, aka MAC address of the interface indicated, generally populated by the PXE discovery mechanism</p> </li> <li> <p><code>net.interface_names</code>:   Interface name or comma delimited list of names to match for this interface. It is generally recommended to leave this blank unless needing to set up interfaces that are not on a common subnet with a confluent server, as confluent servers provide autodetection for matching the correct network definition to an interface. This would be the default name per the deployed OS and can be a comma delimited list to denote members of a team or a single interface for VLAN/PKEY connections.</p> </li> <li> <p><code>net.ipv4_address</code>:   When configuring static, use this address.  If unspecified, it will check if the node name resolves to an IP address.  Additionally, the subnet prefix may be specified with a suffix, e.g. \"/16\".  If not specified, it will attempt to autodetect based on current network configuration.</p> </li> <li> <p><code>net.ipv4_gateway</code>:   The IPv4 gateway to use if applicable.  As is the case for other net attributes, net.eth0.ipv4_gateway and similar is accepted.</p> </li> <li> <p><code>net.ipv4_method</code>:   Whether to use static or dhcp when configuring this interface for IPv4. \"firmwaredhcp\" means to defer to external DHCP server during firmware execution, but use static for OS. \"firmwarenone\" means to suppress even the no-IP dhcp offers, to fully delegate to an external dhcp/pxe configuration, even for confluent deployment.</p> <p>Valid values: 'dhcp', 'static', 'firmwaredhcp', 'firmwarenone', 'none'</p> </li> <li> <p><code>net.ipv6_address</code>:   When configuring static, use this address.  If unspecified, it will check if the node name resolves to an IP address.  Additionally, the subnet prefix may be specified with a suffix, e.g. \"/64\".  If not specified, it will attempt to autodetect based on current network configuration.</p> </li> <li> <p><code>net.ipv6_gateway</code>:   The IPv6 gateway to use if applicable.  As is the case for other net attributes, net.eth0.ipv6_gateway and similar is accepted.</p> </li> <li> <p><code>net.ipv6_method</code>:   Whether to use static or dhcp when configuring this interface for IPv6. \"firmwaredhcp\" means to defer to external DHCP server during firmware execution, but use static for OS. \"firmwarenone\" means to suppress even the no-IP dhcp offers, to fully delegate to an external dhcp/pxe configuration, even for confluent deployment</p> <p>Valid values: 'dhcp', 'static', 'firmwaredhcp', 'firmwarenone', 'none'</p> </li> <li> <p><code>net.switch</code>:   An ethernet switch the node is connected to.  Note that net.* attributes may be indexed by interface. For example instead of using net.switch, it is possible to use net.eth0.switch and net.eth1.switch or net.0.switch and net.1.switch to define multiple sets of net connectivity associated with each other.</p> </li> <li> <p><code>net.switchport</code>:   The port on the switch that corresponds to this node. See information on net.switch for more on the flexibility of net.* attributes.</p> </li> <li> <p><code>net.team_mode</code>:   Indicates that this interface should be a team and what mode or runner to use when teamed. If this covers a deployment interface, one of the member interfaces may be brought up as a standalone interface until deployment is complete, as supported by the OS deployment profile. To support this scenario, the switch should be set up to allow independent operation of member ports (e.g. lacp bypass mode or fallback mode).</p> <p>Valid values: 'lacp', 'loadbalance', 'roundrobin', 'activebackup', 'none'</p> </li> <li> <p><code>net.vlan_id</code>:   Ethernet VLAN or InfiniBand PKEY to use for this connection. Specify the parent device using net.interface_names.</p> </li> <li> <p><code>ntp.servers</code>:   NTP server or servers to provide to node during deployment. An OS profile may default to internet NTP, depending on default configuration of the respective operating system</p> </li> <li> <p><code>power.outlet</code>:   Species the outlet identifier on the PDU associoted with a power input on the node</p> </li> <li> <p><code>power.pdu</code>:   Specifies the managed PDU associated with a power input on the node</p> </li> <li> <p><code>pubkeys.addpolicy</code>:   Policy to use when encountering unknown public keys.  Choices are \"automatic\" to accept and store new key if no key known and \"manual\" to always reject a new key, even if no key knownNote that if the trusted CA verifies the certificate, that is accepted ignoring this policy.  Default policy is \"automatic\"</p> <p>Valid values: 'automatic', 'manual'</p> </li> <li> <p><code>pubkeys.ssh</code>:   Fingerprint of the SSH key of the OS running on the system.</p> </li> <li> <p><code>pubkeys.tls</code>:   Fingerprint of the TLS certificate for service running on host.</p> </li> <li> <p><code>pubkeys.tls_hardwaremanager</code>:   Fingerprint of the TLS certificate recognized asbelonging to the hardware manager of the server</p> </li> <li> <p><code>secret.hardwaremanagementpassword</code>:   Password to use when connecting to the hardware manager.  Aliases for this attribute include bmcpass and switchpass</p> </li> <li> <p><code>secret.hardwaremanagementuser</code>:   The username to use when connecting to the hardware manager. Aliases for this attribute include bmcuser and switchuser</p> </li> <li> <p><code>secret.ipmikg</code>:   Optional Integrity key for IPMI communication.  This should generally be ignored, as mutual authentication is normally done with the password alone (which is a shared secret in IPMI)</p> </li> <li> <p><code>secret.selfapiarmtoken</code>:   A one-time use shared secret to authenticate a node api token</p> </li> <li> <p><code>secret.snmpcommunity</code>:   SNMPv1 community string, it is highly recommended tostep up to SNMPv3</p> </li> <li> <p><code>ssh.trustnodes</code>:   Nodes that are allowed to ssh into the node, expressed in noderange syntax.  This is used during deployment if the confluent SSH certificate authority is configured.  Default behavior is for all nodes to trust each other.</p> </li> <li> <p><code>trusted.subnets</code>:   Remote subnets in CIDR notation that should be considered as trusted as local networks</p> </li> <li> <p><code>type</code>:   The type of node.  This may be switch, server, rackmount, dense, enclosure or not set to be generic.</p> <p>Valid values: 'switch', 'server', 'rackmount', 'dense', 'enclosure', ''</p> </li> </ul>"},{"location":"manuals/nodeattribexpressions/","title":"nodeattribexpressions(5) -- Confluent attribute expression syntax","text":""},{"location":"manuals/nodeattribexpressions/#description","title":"DESCRIPTION","text":"<p>In confluent, any attribute may either be a straightforward value, or an expression to generate the value.</p> <p>An expression will contain some directives wrapped in <code>{}</code> characters. Within <code>{}</code> are a number of potential substitute values and operations.</p> <p>Note that syntax of expressions can have overlap with the shell syntax. For example:</p> <p><code>$ echo (n2)</code> <code>-bash: syntax error near unexpected token</code>n2'`  </p> <p>In such a case, it helps to quote the expression to allow it to be passed:</p> <p><code>$ echo '(n2)'</code> <code>(n2)</code> </p> <p>The most common operation is to extract a number from the nodename. These  values are available as n1, n2, etc. So for example attributes for a node named  b1o2r3u4 would have {n1} as 1, {n2} as 2, {n3} as 3, and {n4} as 4.  Additionally, {n0} is special as representing the last number in a name, so in the b1o2r3u4 example, {n0} would be 4.</p> <p>Frequently a value derives from a number in the node name, but must undergo a transform to be useful. As an example, if we have a scheme where nodes are numbered n1-n512, and they are arranged 1-42 in rack1, 43-84 in rack2, and so forth, it is convenient to perform arithmetic on the extracted number. Here is an example of codifying the above scheme, and setting the u to the remainder:</p> <p><code>location.rack=rack{(n1-1)/42+1}</code> <code>location.u={(n1-1)%42+1}</code> </p> <p>Note how text may be mixed into expressions, only data within {} will receive special treatment. Here we also had to adjust by subtracting 1 and adding it back to make the math work as expected.</p> <p>It is sometimes the case that the number must be formatted a different way, either specifying 0 padding or converting to hexadecimal. This can be done by a number of operators at the end to indicate formatting changes.</p> <p><code>{n1:02x} - Zero pad to two decimal places, and convert to hexadecimal, as mightbe used for generating MAC addresses</code> <code>{n1:x} - Hexadecimal without padding, as may be used in a generated IPv6 address</code> <code>{n1:X} - Uppercase hexadecimal</code> <code>{n1:02d} - Zero pad a normal numeric representation of the number.</code> </p> <p>Another common element to pull into an expression is the node name in whole:</p> <p><code>hardwaremanagement.manager={node}-imm</code></p> <p>Additionally other attributes may be pulled in:</p> <p><code>hardwaremanagement.switchport={location.u}</code> </p> <p>Multiple expressions are permissible within a single attribute:</p> <p><code>hardwaremanagement.manager={node}-{hardwaremanagement.method}</code></p> <p>A note to developers: in general the API layer will automatically recognize a generic set attribute to string with expression syntax and import it as an expression. For example, submitting the following JSON:</p> <p><code>{ 'location.rack': '{n1}' }</code></p> <p>Will auto-detect {n1} as an expression and assign it normally. If wanting to set that value verbatim, it can either be escaped by doubling the {} or by explicitly declaring it as a value:</p> <p><code>{ 'location.rack': '{{n1}}' }</code> </p> <p><code>{ 'location.rack': { 'value': '{n1}' } }</code></p>"},{"location":"manuals/nodebmcpassword/","title":"nodebmcpassword(8) -- Change management controller password for a specified user","text":""},{"location":"manuals/nodebmcpassword/#synopsis","title":"SYNOPSIS","text":"<p><code>nodebmcpassword &lt;var&gt;noderange&lt;/var&gt; &lt;var&gt;username&lt;/var&gt; &lt;var&gt;new_password&lt;/var&gt;</code> </p>"},{"location":"manuals/nodebmcpassword/#description","title":"DESCRIPTION","text":"<p><code>nodebmcpassword</code> allows you to change the management controller password for a user on a specified noderange</p>"},{"location":"manuals/nodebmcpassword/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-m MAXNODES</code>, <code>--maxnodes=MAXNODES</code>:   Number of nodes to affect before prompting for   confirmation</p> </li> <li> <p><code>-h</code>, <code>--help</code>:   Show help message and exit  </p> </li> </ul>"},{"location":"manuals/nodebmcpassword/#examples","title":"EXAMPLES:","text":"<ul> <li>Reset the management controller for nodes n1 through n4:   <code># nodebmcreset n1-n4</code> <code>n1: Password Change Successful</code> <code>n2: Password Change Successful</code> <code>n3: Password Change Successful</code> <code>n4: Password Change Successful</code> </li> </ul>"},{"location":"manuals/nodebmcreset/","title":"nodebmcreset(8) -- Reset management controller","text":""},{"location":"manuals/nodebmcreset/#synopsis","title":"SYNOPSIS","text":"<p><code>nodebmcreset &lt;var&gt;noderange&lt;/var&gt;</code> </p>"},{"location":"manuals/nodebmcreset/#description","title":"DESCRIPTION","text":"<p><code>nodebmcreset</code> allows you to reset the management controller of the specified noderange</p>"},{"location":"manuals/nodebmcreset/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-m MAXNODES</code>, <code>--maxnodes=MAXNODES</code>:   Number of nodes to affect before prompting for   confirmation</p> </li> <li> <p><code>-h</code>, <code>--help</code>:   Show help message and exit  </p> </li> </ul>"},{"location":"manuals/nodebmcreset/#examples","title":"EXAMPLES:","text":"<ul> <li>Reset the management controller for nodes n1 through n4:   <code># nodebmcreset n1-n4</code> <code>n1: BMC Reset Successful</code> <code>n2: BMC Reset Successful</code> <code>n3: BMC Reset Successful</code> <code>n4: BMC Reset Successful</code> </li> </ul>"},{"location":"manuals/nodeboot/","title":"nodeboot(8) -- Reboot a confluent node to a specific device","text":""},{"location":"manuals/nodeboot/#synopsis","title":"SYNOPSIS","text":"<p><code>nodeboot [options] &lt;var&gt;noderange&lt;/var&gt; [default|cd|network|setup|hd]</code> </p>"},{"location":"manuals/nodeboot/#description","title":"DESCRIPTION","text":"<p>nodeboot reboots nodes in a noderange.  If an additional argument is given, it sets the node to specifically boot to that as the next boot.  This  performs an immediate reboot without waiting for the OS.  To set the boot device without inducing a reboot, see the <code>nodesetboot</code> command.</p>"},{"location":"manuals/nodeboot/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-b</code>, <code>--bios</code>:   For a system that supports both BIOS and UEFI style boot, request BIOS style   boot if supported (some platforms will UEFI boot with this flag anyway).</p> </li> <li> <p><code>-u</code>, <code>--uefi</code>:   This flag does nothing, it is for command compatibility with xCAT's rsetboot</p> </li> <li> <p><code>-p</code>, <code>--persist</code>:   For a system that supports it, mark the boot override to persist rather than   be a one time change.  Many systems do not support this functionality.</p> </li> <li> <p><code>-m MAXNODES</code>, <code>--maxnodes=MAXNODES</code>:   Specify a maximum number of nodes to boot, prompting   if over the threshold</p> </li> <li> <p><code>-h</code>, <code>--help</code>:   Show help message and exit  </p> </li> <li> <p><code>default</code>:   Request a normal default boot with no particular device override</p> </li> <li> <p><code>cd</code>:   Request boot from media.  Note that this can include physical CD,   remote media mounted as CD/DVD, and detachable hard disks drives such as usb   key devices.</p> </li> <li> <p><code>network</code>:   Request boot to network</p> </li> <li> <p><code>setup</code>:   Request to enter the firmware configuration menu (e.g. F1 setup) on next boot.</p> </li> <li> <p><code>hd</code>:   Boot straight to hard disk drive</p> </li> </ul>"},{"location":"manuals/nodeboot/#examples","title":"EXAMPLES","text":"<ul> <li> <p>Booting n3 and n4 to the default boot behavior:   <code># nodeboot n3-n4</code> <code>n3: default</code> <code>n4: default</code> <code>n3: on-&gt;reset</code> <code>n4: on-&gt;reset</code> </p> </li> <li> <p>Booting n1 and n2 to setup menu:   <code># nodeboot n1-n2 setup</code> <code>n2: setup</code> <code>n1: setup</code> <code>n2: on-&gt;reset</code> <code>n1: on-&gt;reset</code> </p> </li> <li> <p>Booting n3 and n4 to network:   <code># nodeboot n3-n4 net</code> <code>n3: network</code> <code>n4: network</code> <code>n4: on-&gt;reset</code> <code>n3: off-&gt;on</code> </p> </li> </ul>"},{"location":"manuals/nodeconfig/","title":"nodeconfig(8) -- Show or change node configuration","text":""},{"location":"manuals/nodeconfig/#synopsis","title":"SYNOPSIS","text":"<p><code>nodeconfig [options] &lt;var&gt;noderange&lt;/var&gt; [setting|setting=value]</code></p>"},{"location":"manuals/nodeconfig/#description","title":"DESCRIPTION","text":"<p>nodeconfig manages the configuration of nodes managed by confluent. Rather than manipulating the confluent database, this actually modifies the running configuration on the node firmware.  Calling without '=' will show the current value, and '=' will change the value.  Network information can be given as a node expression, as documented in the man page for nodeattribexpressions(5).</p> <p>Note that when using nodeconfig to submit changes, it will exit when the change is accepted, but the endpoint may not have fully processed it. Doing a show immediately after doing a set may reflect older information. Also, if changing BIOS/UEFI settings, the change may appear in output, but generally won't actually be in effect until a reboot.</p>"},{"location":"manuals/nodeconfig/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-c</code>, <code>--comparedefault</code>:   Take the given settings and compare against default value, if available.  If   no configuration values are specified, it will show only those that differ.   If combined with <code>-x</code>, will show all differing values except those indicated   by <code>-x</code></p> </li> <li> <p><code>-b settings.batch</code>, <code>--batch=settings.batch</code>:    Provide arguments as lines of a file, rather than the command line.  </p> </li> <li> <p><code>-d</code>, <code>--detail</code>:   Provide detailed data as available.  This can include help text and valid   values for a setting.   </p> </li> <li> <p><code>-e</code>, <code>--extra</code>:    Read settings that are generally not needed, but may be slow to retrieve.    Notably this includes the IMM category of Lenovo systems.  The most popular    IMM settings are available through faster 'bmc' attributes.</p> </li> <li> <p><code>-x</code>, <code>--exclude</code>:   Rather than listing only the specified configuration parameters, list all   attributes except for the specified ones</p> </li> <li> <p><code>-a</code>, <code>--advanced</code>:   Include advanced settings, which are normally not intended to be used   without direction from the relevant server vendor.</p> </li> <li> <p><code>-r COMPONENT</code>, <code>--restoredefault=COMPONENT</code>:   Request that the specified component of the targeted nodes will have its   configuration reset to default.  Currently the only component implemented   is uefi.</p> </li> <li> <p><code>-m MAXNODES</code>, <code>--maxnodes=MAXNODES</code>:   Specify a maximum number of nodes to configure, prompting if over    the threshold  </p> </li> <li> <p><code>-h</code>, <code>--help</code>:   Show help message and exit  </p> </li> </ul>"},{"location":"manuals/nodeconfig/#examples","title":"EXAMPLES","text":"<ul> <li> <p>Showing the current IP configuration of noderange BMC/IMM/XCC:     <code># nodeconfig s3,s4 bmc</code> <code>s3: bmc.ipv4_address: 172.30.254.193/16</code> <code>s3: bmc.ipv4_method: DHCP</code> <code>s3: bmc.ipv4_gateway: 172.30.0.6</code> <code>s4: bmc.ipv4_address: 172.30.254.192/16</code> <code>s4: bmc.ipv4_method: DHCP</code> <code>s4: bmc.ipv4_gateway: 172.30.0.6</code> </p> </li> <li> <p>Changing nodes <code>s3</code> and <code>s4</code> to have the ip addressess 10.1.2.3 and 10.1.2.4 with a 16 bit subnet mask:     <code># nodeconfig s3,s4 bmc.ipv4_address=10.1.2.{n1}/16</code> </p> </li> </ul>"},{"location":"manuals/nodeconfig/#see-also","title":"SEE ALSO","text":"<p>nodeattribexpressions(5)</p>"},{"location":"manuals/nodeconsole/","title":"nodeconsole(8) -- Open a console to a confluent node","text":""},{"location":"manuals/nodeconsole/#synopsis","title":"SYNOPSIS","text":"<p><code>nodeconsole [options] &lt;var&gt;noderange&lt;/var&gt; [kill][-- [passthroughoptions]]</code></p>"},{"location":"manuals/nodeconsole/#description","title":"DESCRIPTION","text":"<p>nodeconsole opens an interactive console session to a given node.  This is the text or serial console of a system.  Exiting is done by hitting <code>Ctrl-e</code>, then <code>c</code>,  then <code>.</code>.  Note that console output by default is additionally logged to <code>/var/log/confluent/consoles/</code>NODENAME.</p> <p>When the console connection to the target is broken, then confluent on backend will initiate an automatic retry interval that is randomized between 2 and 4 minutes. The reopen escape sequence below requests an immediate retry, as does connecting a new session.</p> <p>When a windowed console is open the <code>nodeconsole &lt;var&gt;noderange&lt;/var&gt; kill</code> command will kill the console process which will result in the console window closing. </p>"},{"location":"manuals/nodeconsole/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-i N</code>, <code>--interval</code>:   For screenshot mode, fetch new screenshots and overwrite old screenshots every N seconds.   For example, <code>nodeconsole r3u[21:24] -tsi 3</code> will tile screenshots of r3u21 through r3u24 and   refresh them every 3 seconds.</p> </li> <li> <p><code>-t</code>, <code>--tile</code>:   For text consoles, use tmux to arrange consoles of the given noderange into a tiled layout on   the terminal screen.  If using 'screenshot' mode, divide the terminal and display the images   in a grid. </p> </li> <li> <p><code>-l</code>, <code>--log</code>:   Perform a log reply on the current, local log in /var/log/confluent/consoles.   If in collective mode, this only makes sense to use on the current collective   manager at this time.</p> </li> <li> <p><code>-T</code>, <code>--Timestamp</code>:  Dump the log with Timpstamps on the current, local log in /var/log/confluent/consoles.   If in collective mode, this only makes sense to use on the current collective   manager at this time.</p> </li> <li> <p><code>-s</code>, <code>--screenshot</code>:   Attempt to grab screenshot(s) and render using a terminal   image protocol. The image protocol defaults to kitty, and   can be selected by CONFLUENT_IMAGE_PROTOCOL environment variable.   Supported protocols are kitty, iterm, and, sixel (sixel only   if PySixel is installed).  This only presents screenshots, there   is no input supported to graphical consoles from a terminal.</p> </li> <li> <p><code>-w</code>, <code>--windowed</code>:   Open terminal windows for each node.  The   environment variable NODECONSOLE_WINDOWED_COMMAND   should be set, which should be a text string corresponding   to a command that can be used to open a windowed console,   omitting the <code>nodeconsole &lt;var&gt;noderange&lt;/var&gt;</code> part of the   command, for example, to open a set of consoles for a   range of nodes in separate xterm windows, set   NODECONSOLE_WINDOWED_COMMAND to <code>xterm -e</code>.  To open a   set of consoles for a range of nodes in separate   GNOME Terminal windows with a size of 100 columns and   31 rows, set NODECONSOLE_WINDOWED_COMMAND   to <code>gnome-terminal --geometry 100x31 --</code> or in a WSL   environment, to open a set of consoles for a range of   nodes in separate Windows Terminal windows, with the   title set for each node, set NODECONSOLE_WINDOWED_COMMAND   to `wt.exe wsl.exe -d AlmaLinux-8 --shell-type login.  If the   NODECONSOLE_WINDOWED_COMMAND environment variable isn't set,   xterm will be used bydefault.</p> </li> </ul>"},{"location":"manuals/nodeconsole/#escape-sequence-commands","title":"ESCAPE SEQUENCE COMMANDS","text":"<p>While connected to a console, a number of commands may be performed through escape sequences.  To begin an command escape sequence, hit <code>Ctrl-e</code>, then <code>c</code>.  The next keystroke will be interpreted as a command.  The following commands are available.</p> <ul> <li><code>.</code>:   Exit the session and return to the command prompt</li> <li><code>b</code>:   [send Break]   Send a break to the remote console when possible (some console plugins may not support this)</li> <li><code>o</code>:   [reOpen]   Request confluent to disconnect and reconnect to console.  For example if there is suspicion   that the console has gone inoperable, but would work if reconnected.</li> <li><code>po</code>:   [Power Off]   Power off server immediately, without waiting for OS to shutdown</li> <li><code>ps</code>:   [Power Shutdown]   Request OS shut down gracefully, and then power off</li> <li><code>pb&lt;var&gt;ent&lt;/var&gt;</code>:   [Power Boot]   Cause system to immediately boot, resetting or turning on as appropriate.   Hitting enter is required to execute the reboot rather than another pb sequence</li> <li><code>pbs</code>:   [Power Boot Setup]   Request immediate boot ultimately landing in interactive firmware setup</li> <li><code>pbn</code>:   [Power Boot Network]   Request immediate boot to network</li> <li><code>r</code>:   [send Resize]   This queries the current terminal and sends stty commands to advertise the user termineal   size to the remote console</li> <li><code>?</code>:   Get a list of supported commands</li> <li><code>&lt;var&gt;ent&lt;/var&gt;</code>:   Hit enter to skip entering a command at the escape prompt.</li> </ul>"},{"location":"manuals/nodeconsole/#passthrough-options","title":"PASSTHROUGH OPTIONS","text":"<p>While opening a windowed console with xterm or any other console of choice. The  nodeconsole command gives capality to specify passthrough options targeted at  the console. All options after the -- will be parsed the console program. For  example, opening a windowed console using xterm with a black background.  <code>nodeconconsole -w n1 -- -bg black</code> </p>"},{"location":"manuals/nodedefine/","title":"nodedefine(8) -- Define new confluent nodes","text":""},{"location":"manuals/nodedefine/#synopsis","title":"SYNOPSIS","text":"<p><code>nodedefine &lt;var&gt;noderange&lt;/var&gt; [nodeattribute1=value1&gt; &lt;var&gt;nodeattribute2=value2&lt;/var&gt; ...]</code> </p>"},{"location":"manuals/nodedefine/#description","title":"DESCRIPTION","text":"<p><code>nodedefine</code> allows the definition of new nodes for the confluent management system.  It has the same syntax as <code>nodeattrib(8)</code>, and the commands differ in that <code>nodeattrib(8)</code> will error if a node does not exist.</p>"},{"location":"manuals/nodedefine/#examples","title":"EXAMPLES","text":"<ul> <li>Define two racks of nodes, named r{rack}u{u}:     <code># nodedefine r1u1-r2u4</code> <code>r1u4: created</code> <code>r1u1: created</code> <code>r1u2: created</code> <code>r1u3: created</code> <code>r2u4: created</code> <code>r2u3: created</code> <code>r2u2: created</code> <code>r2u1: created</code> </li> </ul>"},{"location":"manuals/nodedefine/#see-also","title":"SEE ALSO","text":"<p>noderange(5), nodeattribexpressions(8)</p>"},{"location":"manuals/nodedeploy/","title":"nodedeploy(8) -- Request preparation and/or initiating a node deployment","text":""},{"location":"manuals/nodedeploy/#synopsis","title":"SYNOPSIS","text":"<p><code>nodedeploy [-h] [-c] [-n] [-p] [-m MAXNODES] &lt;var&gt;noderange&lt;/var&gt; [profile]</code> </p>"},{"location":"manuals/nodedeploy/#description","title":"DESCRIPTION","text":"<p>nodedeploy configures attributes and interacts with BMC devices as appropriate to change the operating system on the noderange to that indicated by <code>profile</code>. Tab completion is supported under bash to help list and select a profile name. <code>-n</code> indicates that it will be a network based deployment (either HTTP or PXE) and <code>-p</code> suppresses any activity that requires the BMC (e.g. setting the next boot device and rebooting the system). Currently nodedeploy only supports <code>-n</code> style deployment flows. Without options it shows the current deployment status.</p>"},{"location":"manuals/nodedeploy/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-c</code>, <code>--clear</code>:   Remove any pending deployment action</p> </li> <li> <p><code>-n</code>, <code>--network</code>:   Prepare for either an HTTP or PXE based deployment, setting boot device to network and rebooting unless <code>-p</code> is specified.</p> </li> <li> <p><code>-p</code>, <code>--prepareonly</code>:   Prepare the network services for deployment, but do not interact with BMCs. This is intended for scenarios where   the boot device control and server restart will be handled outside of confluent.</p> </li> <li> <p><code>-m MAXNODES</code>, <code>--maxnodes=MAXNODES</code>:    Specifiy a maximum nodes to be deployed.</p> </li> <li> <p><code>-h</code>, <code>--help</code>:   Show help message and exit  </p> </li> </ul>"},{"location":"manuals/nodedeploy/#examples","title":"EXAMPLES","text":"<ul> <li> <p>Begin the instalalation of a profile of CentOS 8.2: <code># nodedeploy d4 -n centos-8.2-x86_64-default</code> <code>d4: network</code> <code>d4: reset</code> </p> </li> <li> <p>Check current deployment state of nodes:   <code># nodedeploy d4</code> <code>d4: pending: centos-8.2-x86_64-default (node authentication armed)</code> </p> </li> </ul>"},{"location":"manuals/nodediscover/","title":"nodediscover(8)  -- List or manage confluent node discovery","text":""},{"location":"manuals/nodediscover/#synopsis","title":"SYNOPSIS","text":"<p><code>nodediscover rescan</code> <code>nodediscover [options] list</code> <code>nodediscover [options] assign</code> <code>nodediscover [options] rescan</code> <code>nodediscover [options] clear</code> <code>nodediscover [options] subscribe [switch]</code> <code>nodediscover [options] unsubscribe [switch]</code> <code>nodediscover [options] register [Addresses, e.g. 192.168.1.2 or 192.168.1.0/24 or 192.168.1.1-192.168.1.28]</code> </p>"},{"location":"manuals/nodediscover/#description","title":"DESCRIPTION","text":"<p>nodediscover provides streamlined access to the confluent discovery data and assignment.  Nodes are detected through either an active scan (as occurs at service startup and on request by nodediscover rescan) or through passive detection (as a target comes online, it may attempt to register with the network).</p> <p>nodediscover list provides the currently known data in tabular format.  The data may be filtered by various parameters, as denoted in the options below.</p> <p>nodediscover assign performs manual discovery, assigning an entry to a node identity or, using <code>-i</code>, using a csv file to assign nodes all at once.  For example, a spreadsheet of serial numbers to desired node names could be used. Note that if you see that the host is unreachable, it may be due to the IP address on the endpoint having changed since last detected. In such a case, it may help to clear and try assign again.</p> <p>nodediscover rescan requests the server to do an active sweep for new devices.  Generally every effort is made to passively detect devices as they become available (as they boot or are plugged in), however sometimes an active scan is the best approach to catch something that appears to be missing.</p> <p>nodedsicover clear requests the server forget about a selection of detected device.  It takes the same arguments as nodediscover list.</p> <p>nodediscover subscribe and unsubscribe instructs confluent to subscribe to or unsubscribe from the designated switch running affluent with system discovery support.</p> <p>nodediscover register instructs confluent to perform a remote probe of an address, subnet, or range of IP addresses.</p>"},{"location":"manuals/nodediscover/#csv-format","title":"CSV FORMAT","text":"<p>The CSV format used by nodediscover consists of one header describing the columns followed by the data.  The available columns are:</p> <ul> <li>node: The name desired for the node in confluent</li> <li>groups: A comma delimited list of groups to put the node into (using normal CSV escape rules for the commas)</li> <li>mac: The mac address of the node</li> <li>serial: The serial number of the node</li> <li>uuid: The uuid of the node</li> <li>bmc: The name or ip address that should be assigned to the BMC, regardless of current address</li> <li>bmc_gateway: IP address of gateway, if desired</li> <li>bmcuser: The desired username for the BMC to have as administrator</li> <li>bmcpass: The desired password for the BMC to require</li> </ul> <p>Note that node is the only mandatory field.  To identify the systems, one of mac, serial, or uuid should be specified, it is pointless to provide more than one of these columns.  Other attributes if not provided may be defined through nodeattrib or group inherited.  It is possible to define nodes without ever providing a BMC ip, in which case IPv6 will be used automatically if possible.</p> <p>One example of a valid CSV file would be: node,serial,bmc,bmcuser,bmcpass n1,06DPMDF,172.30.204.1,admin,Passw0rd12 n2,J30002HG,172.30.204.2,admin,Passw0rd12</p> <p>Which would use the serial number to assign the name and other three values to the nodes.</p>"},{"location":"manuals/nodediscover/#options","title":"OPTIONS","text":"<ul> <li><code>-m MODEL</code>, <code>--model=MODEL</code>:   Operate with nodes matching the specified model number</li> <li><code>-s SERIAL</code>, <code>--serial=SERIAL</code>:   Operate against the system matching the specified   serial number</li> <li><code>-u UUID</code>, <code>--uuid=UUID</code>:   Operate against the system matching the specified UUID</li> <li><code>-n NODE</code>, <code>--node=NODE</code>:   Operate with the given nodename</li> <li><code>-e MAC</code>, <code>--ethaddr=MAC</code>:   Operate against the system with the specified MAC   address</li> <li><code>-f FIELDS</code>, <code>--fields=FIELDS</code>:   Request a custom set of fields.  The available fields are:   Node: The node name if a correlation has been identified   Model: The model number   Serial: The serial number   UUID: The UUID as it should appear in DMI   Type: Device type (e.g. lenovo-xcc, pxe-client, etc)   IP: The confirmed working IP addresses associated with the record   Mac: Mac address of the relevant network interface   Switch: The nearest detected switch to the entry   Port: Port of the switch that most closely connects to the network interface   Advertised IP: IP addresses that may not have been confirmed, but are advertised  </li> <li><code>-o ORDER</code>, <code>--order=ORDER</code>:   Order output by given field.  Field names are the same as documented in the -f argument.</li> <li><code>-t TYPE</code>, <code>--type=TYPE</code>:   Operate against the system of the specified type</li> <li><code>-c</code>, <code>--csv</code>:   Use CSV formatted output</li> <li><code>-i IMPORT.CSV</code>, <code>--import=IMPORT.CSV</code>:   Import bulk assignment data from given CSV file</li> <li><code>-d STATE</code>, <code>--discoverystate=STATE</code>:   Indicate devices with a particular state.  The states are listed below</li> <li>discovered: The device has been identified and has also had discovery               activities performed, including any relevant certificate               exchanges and deploying user and network configuration.</li> <li>identified:  The device has been identified as to what node it is                supposed to be, however no active changes to the attributes                or device configuration has been performed.  This is                generally discovery awaiting approval due to                discovery.policy specifying a strict security model.</li> <li>unidentified:  A device has been sensed, but no node identity has been                  established at all.  It provides data that can be used                  for nodediscover assign, as well as current IP addresses                  that can be used for manual efforts as possible.</li> </ul>"},{"location":"manuals/nodediscover/#examples","title":"EXAMPLES","text":"<ul> <li> <p>Listing all detected Lenovo IMMv2 systems on a local network:   <code># nodediscover list -t lenovo-imm2</code> <code>Node|          Model|         Serial|                                UUID|      Mac Address|        Type|                            Current IP Addresses</code> <code>---------------|---------------|---------------|------------------------------------|-----------------|------------|------------------------------------------------</code> <code>r2|        5463AC1|        06DPMDF|5f7133b8-c8cb-11e4-99a9-40f2e9b91018|40:f2:e9:b9:10:1d| lenovo-imm2|     172.30.204.1,fe80::42f2:e9ff:feb9:101d%eth1</code> <code>|        7906AC1|        06PBX15|e98d483d-2759-11e1-8ffd-5cf3fc11249c|5c:f3:fc:11:24:9f| lenovo-imm2|      172.30.3.12,fe80::5ef3:fcff:fe11:249f%eth1</code> <code>n1|        8737AC1|        23XXH41|14dd3ba6-5c38-11e1-931a-5cf3fc6e4680|5c:f3:fc:6e:13:e1| lenovo-imm2|       172.30.3.1,fe80::5ef3:fcff:fe6e:13e1%eth1</code> <code>n7|        8737AC1|        23XXH32|79d2ce28-5cd5-11e1-8c86-5cf3fc6e46b0|5c:f3:fc:6e:13:f9| lenovo-imm2|       172.30.3.7,fe80::5ef3:fcff:fe6e:13f9%eth1</code> <code>n8|        8737AC1|        23XXH49|551a8438-5cd5-11e1-8d6c-5cf3fc6e4708|5c:f3:fc:6e:14:25| lenovo-imm2|       172.30.3.8,fe80::5ef3:fcff:fe6e:1425%eth1</code> <code>n3|        8737AC1|        23XXH30|1dd7f7b3-5da5-11e1-baf0-5cf3fc6e4738|5c:f3:fc:6e:14:3d| lenovo-imm2|       172.30.3.3,fe80::5ef3:fcff:fe6e:143d%eth1</code> <code>n4|        8737AC1|        23XXH35|45b81dae-5d9b-11e1-8337-5cf3fc6e4858|5c:f3:fc:6e:14:cd| lenovo-imm2|       172.30.3.4,fe80::5ef3:fcff:fe6e:14cd%eth1</code> <code>n11|        8737AC1|        23XXH12|31d90128-5c37-11e1-bdb7-5cf3fc6e4920|5c:f3:fc:6e:15:31| lenovo-imm2|      172.30.3.11,fe80::5ef3:fcff:fe6e:1531%eth1</code> <code>n13|        8737AC1|        23XXH44|e23a138a-5cd3-11e1-8f3d-5cf3fc6e4950|5c:f3:fc:6e:15:49| lenovo-imm2|      172.30.3.13,fe80::5ef3:fcff:fe6e:1549%eth1</code> <code>|        8737AC1|        23XXH29|5cd1216b-5c37-11e1-ba0c-5cf3fc6e49c8|5c:f3:fc:6e:15:85| lenovo-imm2|       172.30.3.9,fe80::5ef3:fcff:fe6e:1585%eth1</code> <code>|        8737AC1|        23ZYT44|f4bf48ca-71f0-11e1-b274-5cf3fc6e4f10|5c:f3:fc:6e:18:29| lenovo-imm2|      172.30.3.10,fe80::5ef3:fcff:fe6e:1829%eth1</code> <code>hpcedr|        7915AC1|        06DRHL5|a64e3014-d7e3-11e1-8d21-6cae8b1dff32|6c:ae:8b:1d:ff:36| lenovo-imm2|   172.30.254.250,fe80::6eae:8bff:fe1d:ff36%eth1</code> <code>|        8737AC1|        06YRWC3|3af85a51-7efd-11e3-8599-000af7482e00|6c:ae:8b:32:cb:c5| lenovo-imm2|       172.30.3.6,fe80::6eae:8bff:fe32:cbc5%eth1</code> <code>|        8737AC1|        06YRWB7|b230f62e-7efd-11e3-9773-000af7482980|6c:ae:8b:32:cd:01| lenovo-imm2|       172.30.3.5,fe80::6eae:8bff:fe32:cd01%eth1</code> <code>|        8737AC1|        06YRWC7|09586005-7efe-11e3-9f03-000af7482df0|6c:ae:8b:32:cd:a5| lenovo-imm2|       172.30.3.2,fe80::6eae:8bff:fe32:cda5%eth1</code> </p> </li> <li> <p>Manually assign a single node according to serial number:   <code>[root@odin ~]# nodediscover assign -s 06PBX15 -n n12</code> <code>Assigned: n12</code> </p> </li> <li> <p>Bulk execute discovery based on spreadsheet:   <code>[root@odin ~]# nodediscover assign -i import.csv</code> <code>Defined r2</code> <code>Discovered r2</code> <code>Defined c1</code> <code>Discovered c1</code> </p> </li> </ul>"},{"location":"manuals/nodeeventlog/","title":"nodeeventlog(8) -- Pull eventlog from confluent nodes","text":""},{"location":"manuals/nodeeventlog/#synopsis","title":"SYNOPSIS","text":"<p><code>nodeeventlog [options] &lt;var&gt;noderange&lt;/var&gt; [clear]</code> </p>"},{"location":"manuals/nodeeventlog/#description","title":"DESCRIPTION","text":"<p><code>nodeeventlog</code> pulls and optionally clears the event log from the requested noderange.</p>"},{"location":"manuals/nodeeventlog/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-m MAXNODES</code>, <code>--maxnodes=MAXNODES</code>:   Specify a maximum number of nodes to clear if clearing log, prompting if    over the threshold </p> </li> <li> <p><code>-l LINES</code>, <code>--lines=LINES</code>:     return the last n entries for each node in the eventlog. </p> </li> <li> <p><code>-t TIMEFRAME</code>, <code>--timeframe=TIMEFRAME</code>:    return entries within a specified timeframe for each node's event log.     This will return entries from the last n hours or days. 1h would be     entries from with the last one hour. </p> </li> <li> <p><code>-h</code>, <code>--help</code>:   Show help message and exit  </p> </li> </ul>"},{"location":"manuals/nodeeventlog/#examples","title":"EXAMPLES","text":"<ul> <li> <p>Pull the event log from n2 and n3:   <code># nodeeventlog n2,n3</code> <code>n2: 05/03/2017 11:44:25 Event Log Disabled - SEL Fullness - Log clear</code> <code>n2: 05/03/2017 11:44:56 System Firmware - Progress - Unspecified</code> <code>n3: 05/03/2017 11:44:39 Event Log Disabled - SEL Fullness - Log clear</code> <code>n3: 05/03/2017 11:45:00 System Firmware - Progress - Unspecified</code> <code>n3: 05/03/2017 11:47:22 System Firmware - Progress - Starting OS boot</code> </p> </li> <li> <p>Pull and clear the event log from n2 and n3: <code># nodeeventlog n2,n3 clear</code> <code>n2: 05/03/2017 11:44:25 Event Log Disabled - SEL Fullness - Log clear</code> <code>n2: 05/03/2017 11:44:56 System Firmware - Progress - Unspecified</code> <code>n2: 05/03/2017 11:48:29 System Firmware - Progress - Starting OS boot</code> <code>n3: 05/03/2017 11:44:39 Event Log Disabled - SEL Fullness - Log clear</code> <code>n3: 05/03/2017 11:45:00 System Firmware - Progress - Unspecified</code> <code>n3: 05/03/2017 11:47:22 System Firmware - Progress - Starting OS boot</code> <code># nodeeventlog n2,n3</code> <code>n2: 05/03/2017 11:48:48 Event Log Disabled - SEL Fullness - Log clear</code> <code>n3: 05/03/2017 11:48:52 Event Log Disabled - SEL Fullness - Log clear</code> </p> </li> </ul>"},{"location":"manuals/nodefirmware/","title":"nodefirmware(8) -- Report firmware information on confluent nodes","text":""},{"location":"manuals/nodefirmware/#synopsis","title":"SYNOPSIS","text":"<p><code>nodefirmware &lt;var&gt;noderange&lt;/var&gt; [list][updatestatus][update [--backup &lt;var&gt;file&lt;/var&gt;]]|[&lt;var&gt;components&lt;/var&gt;]</code></p>"},{"location":"manuals/nodefirmware/#description","title":"DESCRIPTION","text":"<p><code>nodefirmware</code> reports and updates various firmware on nodes.  By default it will retrieve all firmware, but can be directed to fetch specific firmware by calling out the name of the firmware (e.g. uefi or xcc) or request reading only core firmware firmware by using the word 'core', which is generally a quicker operation.  Different hardwaremanagement.method indicated plugins may have different capabilities available.  For example, the 'core' distinction may not be relevant to redfish.  Additionally, the Lenovo XCC makes certain information available over IPMI that is not otherwise available (for example the FPGA version where applicable).</p> <p>The updatestatus argument will describe the state of firmware updates on the nodes.</p> <p>In the update form, it accepts a single file and attempts to update it using the out of band facilities.  Firmware updates can end in one of three states:</p> <ul> <li><code>error</code>: The attempted update encountered an error that prevented successful install.  Nodes experiencing this state will be reported at the end and more detail on the error will be given</li> <li><code>pending</code>:  The firmware update process has completed, but the firmware will not be active until the relevant component next resets.  Generally speaking, for UEFI update the system will need a reboot, and for BMC updates, the <code>nodebmcreset</code> command will begin the process to activate the firmware.</li> <li><code>complete</code>:  The firmware update process has completed and activation has proceeded.  Note that while the activation process has commenced, the component may still be in the process of rebooting when nodefirmware exits.</li> </ul>"},{"location":"manuals/nodefirmware/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-b</code>, <code>--backup</code>:   Target a backup bank rather than primary</p> </li> <li> <p><code>-m MAXNODES</code>, <code>--maxnodes=MAXNODES</code>:   When updating, prompt if more than the specified number of servers will    be affected  </p> </li> <li> <p><code>-h</code>, <code>--help</code>:   Show help message and exit    </p> </li> </ul>"},{"location":"manuals/nodefirmware/#examples","title":"EXAMPLES","text":"<ul> <li>Pull firmware from a node: <code># nodefirmware r1</code> <code>r1: IMM: 3.70 (TCOO26H 2016-11-29T05:09:51)</code> <code>r1: IMM Backup: 1.71 (TCOO10D 2015-04-17T00:00:00)</code> <code>r1: IMM Trusted Image: TCOO26H</code> <code>r1: UEFI: 2.31 (TCE128I 2016-12-13T00:00:00)</code> <code>r1: UEFI Backup: 2.20 (TCE126O)</code> <code>r1: FPGA: 3.2.0</code> <code>r1: Broadcom NetXtreme Gigabit Ethernet Controller Bootcode: 1.38</code> <code>r1: Broadcom NetXtreme Gigabit Ethernet Controller MBA: 16.8.0</code> <code>r1: Broadcom NetXtreme Gigabit Ethernet Controller Firmware Package: 0.0.0a</code> <code>r1: ServeRAID M1215 MegaRAID Controller Firmware: 24.12.0-0038 (2016-10-20T00:00:00)</code> <code>r1: ServeRAID M1215 Disk 28 MBF2600RC: SB2C</code> <code>r1: ServeRAID M1215 Disk 29 MBF2600RC: SB2C</code> <code>r1: ServeRAID M5210 Disk 0 MBF2600RC: SB2C</code> <code>r1: ServeRAID M5210 Disk 1 MBF2600RC: SB2C</code> <code>r1: ServeRAID M5210 Disk 2 MBF2600RC: SB2C</code> </li> </ul>"},{"location":"manuals/nodegroupattrib/","title":"nodegroupattrib(8) -- List or change confluent nodegroup attributes","text":""},{"location":"manuals/nodegroupattrib/#synopsis","title":"SYNOPSIS","text":"<p><code>nodegroupattrib &lt;var&gt;group&lt;/var&gt; [ current | all ]</code> <code>nodegroupattrib &lt;var&gt;group&lt;/var&gt; [&lt;var&gt;nodeattribute&lt;/var&gt;...]</code> <code>nodegroupattrib &lt;var&gt;group&lt;/var&gt; [&lt;var&gt;nodeattribute1=value1&lt;/var&gt; &lt;var&gt;nodeattribute2=value2&lt;/var&gt; ...]</code> <code>nodegroupattrib &lt;var&gt;group&lt;/var&gt; [-c] [&lt;var&gt;nodeattribute1&lt;/var&gt; &lt;var&gt;nodeattribute2=value2&lt;/var&gt; ...]</code> <code>nodeattrib -p &lt;var&gt;noderange&lt;/var&gt; &lt;var&gt;nodeattribute1&lt;/var&gt; &lt;var&gt;nodeattribute2&lt;/var&gt; ...</code> </p>"},{"location":"manuals/nodegroupattrib/#description","title":"DESCRIPTION","text":"<p><code>nodegroupattrip</code> queries the confluent server to get information about nodes. In the simplest form, it simply takes the given group and lists the attributes of that group.</p> <p>Contrasted with nodeattrib(8), settings managed by nodegroupattrib will be added and removed from a node as it is added or removed from a group.  If an attribute is set using nodeattrib(8) against a noderange(5) that happens to be a group name, nodeattrib(8) individually sets attributes directly on each individual node that is currently a member of that group.  Removing group membership or adding a new node after using the nodeattrib(8) command will not have attributes change automatically. It's easiest to see by using the <code>nodeattrib &lt;var&gt;noderange&lt;/var&gt; -b</code> to understand how the attributes are set on the node versus a group to which a node belongs.</p>"},{"location":"manuals/nodegroupattrib/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-b</code>, <code>--blame</code>:   Show information about how attributes inherited</p> </li> <li> <p><code>-e</code>, <code>--environment</code>:   Set attributes, but from environment variable of same name</p> </li> <li> <p><code>-c</code>, <code>--clear</code>:   Clear specified nodeattributes.</p> </li> <li> <p><code>-p</code>, <code>--prompt</code>:   Prompt for attribute values interactively</p> </li> <li> <p><code>-h</code>, <code>--help</code>:   Show help message and exit  </p> </li> </ul>"},{"location":"manuals/nodegroupattrib/#examples","title":"EXAMPLES","text":"<ul> <li> <p>Show attributes of a group called <code>demogrp</code>:   <code># nodegroupattrib demogrp</code> <code>demogrp: hardwaremanagement.manager:  (will derive from expression 10.30.{n0/255}.{n0%255})</code> <code>demogrp: nodes: n12,n13,n10,n11,n9,n1,n2,n3,n4</code> </p> </li> <li> <p>Set location.u to be the remainder of first number in node name when divided by 42: <code># nodegroupattrib demogrp location.u={n1%42}</code> </p> </li> </ul>"},{"location":"manuals/nodegroupattrib/#see-also","title":"SEE ALSO","text":"<p>nodeattrib(8), nodeattribexpressions(5)</p>"},{"location":"manuals/nodegroupattrib/#attributes","title":"ATTRIBUTES","text":"<ul> <li> <p><code>collective.manager</code>:   When in collective mode, the member of the collective currently considered to be responsible for this node.  At a future date, this may be modified automatically if another attribute indicates candidate managers, either for high availability or load balancing purposes.</p> </li> <li> <p><code>collective.managercandidates</code>:   A noderange of nodes permitted to be a manager for the node. This controls failover and deployment.  If not defined, all managers may deploy and no automatic failover will be performed. Using this requires that collective members be defined as nodes for noderange expansion</p> </li> <li> <p><code>console.logging</code>:   Indicate logging level to apply to console. Defaults to \"full\".</p> <p>Valid values: 'full', 'memory', 'interactive', 'none'</p> </li> <li> <p><code>console.method</code>:   Indicate the method used to access the console of the managed node.  If not specified, then console is disabled.  \"ipmi\" should be specified for most systems if console is desired.</p> <p>Valid values: 'ssh', 'ipmi', 'openbmc', 'tsmsol', 'vcenter'</p> </li> <li> <p><code>crypted.grubpassword</code>:   Password required to modify grub behavior at boot</p> </li> <li> <p><code>crypted.rootpassword</code>:   The password of the local root password. This is stored as a non-recoverable hash. If unspecified and confluent is used to deploy, then login at console using password will be impossible and only key based login can work for root.</p> </li> <li> <p><code>crypted.selfapikey</code>:   Crypt of api key for self api requests by node</p> </li> <li> <p><code>deployment.apiarmed</code>:   Indicates whether the node authentication token interface is armed.  If set to once, it will grant only the next request. If set to continuous, will allow many requests, which greatly reduces security, particularly when connected to untrusted networks. Should not be set unless an OS deployment is pending on the node. Generally this is not directly modified, but is modified by the \"nodedeploy\" command</p> <p>Valid values: 'once', 'continuous', ''</p> </li> <li> <p><code>deployment.encryptboot</code>:   Specify a strategy for encrypting the volume. Support for this setting is currently only enabled for RedHat 8 and CentOS 8 profiles. If blank or unset, no encryption is done. If set to \"tpm2\" then the OS will freely decrypt so long as the same Trusted Platform Module is available to decrypt the volume. Note that versions earlier than 8.2 may malfunction at boot time if this feature is attempted, depending on configuration.</p> <p>Valid values: 'tpm2', 'none', ''</p> </li> <li> <p><code>deployment.lock</code>:   Indicates whether deployment actions should be impeded. If locked, it indicates that a pending profile should not be applied. If \"autolock\", then locked will be set when current pending deployment completes. </p> <p>Valid values: 'autolock', 'locked'</p> </li> <li> <p><code>deployment.pendingprofile</code>:   An OS profile that is pending deployment.  This indicates to the network boot subsystem what should be offered when a potential network boot request comes in</p> </li> <li> <p><code>deployment.profile</code>:   The profile that has most recently reported completion of deployment. Note that an image may opt to leave itself both current and pending, for example a stateless profile would be both after first boot.</p> </li> <li> <p><code>deployment.sealedapikey</code>:   This attribute is used by some images to save a sealed version of a node apikey, so that a subsequent run with same TPM2 will use the TPM2 to protect the API key rather than local network verification. If this is set, then an api key request will receive this if the api key grant is not armed</p> </li> <li> <p><code>deployment.stagedprofile</code>:   A profile that has been staged, but is awaiting final boot to be activated. This allows an OS profile to remove itself from netboot without indicating completion to any watcher.</p> </li> <li> <p><code>deployment.state</code>:   Profiles may push more specific state, for example, it may set the state to \"failed\" or \"succeded\"</p> </li> <li> <p><code>deployment.state_detail</code>:   Detailed state information as reported by an OS profile, when available</p> </li> <li> <p><code>deployment.useinsecureprotocols</code>:   What phase(s) of boot are permitted to use insecure protocols (TFTP and HTTP without TLS.  By default, only HTTPS is used.  However this is not compatible with most firmware in most scenarios.  Using \"firmware\" as the setting will still use HTTPS after the initial download, though be aware that a successful attack during the firmware phase will negate future TLS protections.  The value \"always\" will result in tftp/http being used for most of the deployment.  The value \"never\" will allow HTTPS only. Note that Ubuntu will still use HTTP without TLS for a phase of the installation process.</p> <p>Valid values: 'always', 'firmware', 'never'</p> </li> <li> <p><code>discovery.nodeconfig</code>:   Set of nodeconfig arguments to apply after automatic discovery</p> </li> <li> <p><code>discovery.passwordrules</code>:   Any specified rules shall be configured on the BMC upon discovery.  \"expiration=no,loginfailures=no,complexity=no,reuse=no\" would disable password expiration, login failures triggering a lockout, password complexity requirements,and any restrictions around reusing an old password.</p> <p>Valid values: 'expiration', 'loginfailures', 'complexity', 'reuse'</p> </li> <li> <p><code>discovery.policy</code>:   Policy to use for auto-configuration of discovered and identified nodes. \"manual\" means nodes are detected, but not autoconfigured until a user approves. \"permissive\" indicates to allow discovery, so long as the node has no existing public key. \"open\" allows discovery even if a known public key is already stored</p> <p>Valid values: 'manual', 'permissive', 'pxe', 'open', 'verified'</p> </li> <li> <p><code>dns.domain</code>:   DNS Domain searched by default by the system</p> </li> <li> <p><code>dns.servers</code>:   DNS Server or servers to provide to node</p> </li> <li> <p><code>enclosure.bay</code>:   The bay in the enclosure, if any</p> </li> <li> <p><code>enclosure.extends</code>:   When using an extendable enclosure, this is the node representing the manager that is one closer to the uplink.</p> </li> <li> <p><code>enclosure.manager</code>:   The management device for this node's chassis</p> </li> <li> <p><code>groups</code>:   List of static groups for which this node is considered a member</p> </li> <li> <p><code>hardwaremanagement.manager</code>:   The management address dedicated to this node.  This is the address of, for example, the Lenovo XCC.  It may optionally include /prefixlen CIDR suffix to indicate subnet length, which is autodetected by default where possible.</p> </li> <li> <p><code>hardwaremanagement.method</code>:   The method used to perform operations such as power control, get sensor data, get inventory, and so on. ipmi is used if not specified.</p> </li> <li> <p><code>hardwaremanagement.port</code>:   The port the BMC should be configured to connect to network.  This only has effect during deployment and does not apply to out of band discovery. Example values include \"ocp\", \"ml2\", \"lom\" (for on board port shared with operating system), or \"dedicated\"</p> </li> <li> <p><code>hardwaremanagement.vlan</code>:   The vlan that a BMC should be configured to tag traffic. This only has effect during OS deployment and does not apply to out of band discovery.</p> </li> <li> <p><code>id.model</code>:   The model number of a node.  In scenarios where there is both a name and a model number, it is generally expected that this would be the generally more specific model number.</p> </li> <li> <p><code>id.serial</code>:   The manufacturer serial number of node</p> </li> <li> <p><code>id.uuid</code>:   The UUID of the node as presented in DMI.</p> </li> <li> <p><code>info.note</code>:   A field used for administrators to make arbitrary notations about nodes. This is meant entirely for human use and not programmatic use, so it can be freeform text data without concern for issues in how the server will process it.</p> </li> <li> <p><code>location.height</code>:   Height in RU of the system (defaults to query the systems)</p> </li> <li> <p><code>location.rack</code>:   Rack number of the rack the node is in</p> </li> <li> <p><code>location.room</code>:   Room description for the node</p> </li> <li> <p><code>location.row</code>:   Row description for the rack the node is in</p> </li> <li> <p><code>location.u</code>:   Position in the rack of the node</p> </li> <li> <p><code>net.bootable</code>:   Whether or not the indicated network interface is to be used for booting.  This is used by the discovery process to decide where to place the mac address of a detected PXE nic.</p> </li> <li> <p><code>net.connection_name</code>:   Name to use when specifiying a name for connection and/or interface name for a team.  This may be the name of a team interface, the connection name in network manager for the interface, or may be installed as an altname as supported by the respective OS deployment profiles.  Default is to accept default name for a team consistent with the respective OS, or to use the matching original port name as connection name.</p> </li> <li> <p><code>net.hostname</code>:   Used to specify hostnames per interface. Can be a comma delimited list to indicate aliases</p> </li> <li> <p><code>net.hwaddr</code>:   The hardware address, aka MAC address of the interface indicated, generally populated by the PXE discovery mechanism</p> </li> <li> <p><code>net.interface_names</code>:   Interface name or comma delimited list of names to match for this interface. It is generally recommended to leave this blank unless needing to set up interfaces that are not on a common subnet with a confluent server, as confluent servers provide autodetection for matching the correct network definition to an interface. This would be the default name per the deployed OS and can be a comma delimited list to denote members of a team or a single interface for VLAN/PKEY connections.</p> </li> <li> <p><code>net.ipv4_address</code>:   When configuring static, use this address.  If unspecified, it will check if the node name resolves to an IP address.  Additionally, the subnet prefix may be specified with a suffix, e.g. \"/16\".  If not specified, it will attempt to autodetect based on current network configuration.</p> </li> <li> <p><code>net.ipv4_gateway</code>:   The IPv4 gateway to use if applicable.  As is the case for other net attributes, net.eth0.ipv4_gateway and similar is accepted.</p> </li> <li> <p><code>net.ipv4_method</code>:   Whether to use static or dhcp when configuring this interface for IPv4. \"firmwaredhcp\" means to defer to external DHCP server during firmware execution, but use static for OS. \"firmwarenone\" means to suppress even the no-IP dhcp offers, to fully delegate to an external dhcp/pxe configuration, even for confluent deployment.</p> <p>Valid values: 'dhcp', 'static', 'firmwaredhcp', 'firmwarenone', 'none'</p> </li> <li> <p><code>net.ipv6_address</code>:   When configuring static, use this address.  If unspecified, it will check if the node name resolves to an IP address.  Additionally, the subnet prefix may be specified with a suffix, e.g. \"/64\".  If not specified, it will attempt to autodetect based on current network configuration.</p> </li> <li> <p><code>net.ipv6_gateway</code>:   The IPv6 gateway to use if applicable.  As is the case for other net attributes, net.eth0.ipv6_gateway and similar is accepted.</p> </li> <li> <p><code>net.ipv6_method</code>:   Whether to use static or dhcp when configuring this interface for IPv6. \"firmwaredhcp\" means to defer to external DHCP server during firmware execution, but use static for OS. \"firmwarenone\" means to suppress even the no-IP dhcp offers, to fully delegate to an external dhcp/pxe configuration, even for confluent deployment</p> <p>Valid values: 'dhcp', 'static', 'firmwaredhcp', 'firmwarenone', 'none'</p> </li> <li> <p><code>net.switch</code>:   An ethernet switch the node is connected to.  Note that net.* attributes may be indexed by interface. For example instead of using net.switch, it is possible to use net.eth0.switch and net.eth1.switch or net.0.switch and net.1.switch to define multiple sets of net connectivity associated with each other.</p> </li> <li> <p><code>net.switchport</code>:   The port on the switch that corresponds to this node. See information on net.switch for more on the flexibility of net.* attributes.</p> </li> <li> <p><code>net.team_mode</code>:   Indicates that this interface should be a team and what mode or runner to use when teamed. If this covers a deployment interface, one of the member interfaces may be brought up as a standalone interface until deployment is complete, as supported by the OS deployment profile. To support this scenario, the switch should be set up to allow independent operation of member ports (e.g. lacp bypass mode or fallback mode).</p> <p>Valid values: 'lacp', 'loadbalance', 'roundrobin', 'activebackup', 'none'</p> </li> <li> <p><code>net.vlan_id</code>:   Ethernet VLAN or InfiniBand PKEY to use for this connection. Specify the parent device using net.interface_names.</p> </li> <li> <p><code>ntp.servers</code>:   NTP server or servers to provide to node during deployment. An OS profile may default to internet NTP, depending on default configuration of the respective operating system</p> </li> <li> <p><code>power.outlet</code>:   Species the outlet identifier on the PDU associoted with a power input on the node</p> </li> <li> <p><code>power.pdu</code>:   Specifies the managed PDU associated with a power input on the node</p> </li> <li> <p><code>pubkeys.addpolicy</code>:   Policy to use when encountering unknown public keys.  Choices are \"automatic\" to accept and store new key if no key known and \"manual\" to always reject a new key, even if no key knownNote that if the trusted CA verifies the certificate, that is accepted ignoring this policy.  Default policy is \"automatic\"</p> <p>Valid values: 'automatic', 'manual'</p> </li> <li> <p><code>pubkeys.ssh</code>:   Fingerprint of the SSH key of the OS running on the system.</p> </li> <li> <p><code>pubkeys.tls</code>:   Fingerprint of the TLS certificate for service running on host.</p> </li> <li> <p><code>pubkeys.tls_hardwaremanager</code>:   Fingerprint of the TLS certificate recognized asbelonging to the hardware manager of the server</p> </li> <li> <p><code>secret.hardwaremanagementpassword</code>:   Password to use when connecting to the hardware manager.  Aliases for this attribute include bmcpass and switchpass</p> </li> <li> <p><code>secret.hardwaremanagementuser</code>:   The username to use when connecting to the hardware manager. Aliases for this attribute include bmcuser and switchuser</p> </li> <li> <p><code>secret.ipmikg</code>:   Optional Integrity key for IPMI communication.  This should generally be ignored, as mutual authentication is normally done with the password alone (which is a shared secret in IPMI)</p> </li> <li> <p><code>secret.selfapiarmtoken</code>:   A one-time use shared secret to authenticate a node api token</p> </li> <li> <p><code>secret.snmpcommunity</code>:   SNMPv1 community string, it is highly recommended tostep up to SNMPv3</p> </li> <li> <p><code>ssh.trustnodes</code>:   Nodes that are allowed to ssh into the node, expressed in noderange syntax.  This is used during deployment if the confluent SSH certificate authority is configured.  Default behavior is for all nodes to trust each other.</p> </li> <li> <p><code>trusted.subnets</code>:   Remote subnets in CIDR notation that should be considered as trusted as local networks</p> </li> <li> <p><code>type</code>:   The type of node.  This may be switch, server, rackmount, dense, enclosure or not set to be generic.</p> <p>Valid values: 'switch', 'server', 'rackmount', 'dense', 'enclosure', ''</p> </li> </ul>"},{"location":"manuals/nodegroupdefine/","title":"nodegroupdefine(8) -- Define new confluent node group","text":""},{"location":"manuals/nodegroupdefine/#synopsis","title":"SYNOPSIS","text":"<p><code>nodegroupdefine &lt;var&gt;groupname&lt;/var&gt; [nodeattribute1=value1&gt; &lt;var&gt;nodeattribute2=value2&lt;/var&gt; ...]</code> </p>"},{"location":"manuals/nodegroupdefine/#description","title":"DESCRIPTION","text":"<p><code>nodegroupdefine</code> allows the definition of a new nodegroup for the confluent management service.  It may only define a single group name at a time. It has the same syntax as <code>nodegroupattrib(8)</code>, and the commands differ in that <code>nodegroupattrib(8)</code> will error if a node group does not exist.</p>"},{"location":"manuals/nodegroupdefine/#examples","title":"EXAMPLES","text":"<ul> <li>Create a group called <code>compute</code>:     <code># nodegroupdefine compute</code> <code>compute: created</code> </li> </ul>"},{"location":"manuals/nodegroupdefine/#see-also","title":"SEE ALSO","text":"<p>nodeattribexpressions(8), nodegroupattrib(8), nodegroupremove(8)</p>"},{"location":"manuals/nodegrouplist/","title":"nodegrouplist(8) -- List the defined confluent nodegroups","text":""},{"location":"manuals/nodegrouplist/#synopsis","title":"SYNOPSIS","text":"<p><code>nodegrouplist</code> </p>"},{"location":"manuals/nodegrouplist/#description","title":"DESCRIPTION","text":"<p><code>nodegrouplist</code> lists the currently defined groups in confluent.</p>"},{"location":"manuals/nodegrouplist/#see-also","title":"SEE ALSO","text":"<p>nodeattrib(8), nodeattribexpressions(5), nodegroupattrib(8)</p>"},{"location":"manuals/nodegroupremove/","title":"nodegroupremove(8) -- Remove a nodegroup from the confluent database","text":""},{"location":"manuals/nodegroupremove/#synopsis","title":"SYNOPSIS","text":"<p><code>nodegroupremove &lt;var&gt;noderange&lt;/var&gt;</code> </p>"},{"location":"manuals/nodegroupremove/#description","title":"DESCRIPTION","text":"<p><code>nodegroupremove</code> simply removes the given single nodegroup from the confluent database.</p>"},{"location":"manuals/nodegroupremove/#examples","title":"EXAMPLES","text":"<ul> <li>Remove group called testgroup     <code># nodegroupremove testgroup</code> <code>testgroup: deleted</code> </li> </ul>"},{"location":"manuals/nodehealth/","title":"nodehealth(8) -- Show health summary of confluent nodes","text":""},{"location":"manuals/nodehealth/#synopsis","title":"SYNOPSIS","text":"<p><code>nodehealth &lt;var&gt;noderange&lt;/var&gt;</code> </p>"},{"location":"manuals/nodehealth/#description","title":"DESCRIPTION","text":"<p><code>nodehealth</code> reports the current health assessment of a confluent node.  It will report either <code>ok</code>, <code>warning</code>, <code>critical</code>, or <code>failed</code>, along with a string explaining the reason for any result other than <code>ok</code>.</p>"},{"location":"manuals/nodehealth/#examples","title":"EXAMPLES","text":"<ul> <li>Pull health summary of 5 nodes:   <code># nodehealth n1-n4,r1</code> <code>n1: critical (Mezz Exp 2 Fault:Critical)</code> <code>n3: ok</code> <code>n2: ok</code> <code>r1: ok</code> <code>n4: ok</code></li> </ul>"},{"location":"manuals/nodeidentify/","title":"nodeidentify(8) -- Control the identify LED of confluent nodes","text":""},{"location":"manuals/nodeidentify/#synopsis","title":"SYNOPSIS","text":"<p><code>nodidentify &lt;var&gt;noderange&lt;/var&gt; [on|off|blink]</code> </p>"},{"location":"manuals/nodeidentify/#description","title":"DESCRIPTION","text":"<p><code>nodeidentify</code> allows you to turn on or off the location LED of conflueunt nodes, making it easier to determine the physical location of the nodes.  The following options are supported:</p> <ul> <li><code>on</code>: Turn on the identify LED</li> <li><code>off</code>: Turn off the identify LED</li> <li><code>blink</code>: Set the identify LED to blink (when supported by the system)</li> </ul>"},{"location":"manuals/nodeidentify/#examples","title":"EXAMPLES:","text":"<ul> <li> <p>Turn on the identify LED on nodes n1 through n4:   <code># nodeidentify n1-n4 on</code> <code>n1: on</code> <code>n2: on</code> <code>n3: on</code> <code>n4: on</code> </p> </li> <li> <p>Turn off the identify LED on nodes n1 thorugh n4:   <code># nodeidentify n1-n4 off</code> <code>n1: off</code> <code>n2: off</code> <code>n4: off</code> <code>n3: off</code> </p> </li> </ul>"},{"location":"manuals/nodeinventory/","title":"nodeinventory(8) -- Get hardware inventory of confluent node","text":""},{"location":"manuals/nodeinventory/#synopsis","title":"SYNOPSIS","text":"<p><code>nodeinventory &lt;var&gt;noderange&lt;/var&gt; [serial|model|uuid|mac]</code></p>"},{"location":"manuals/nodeinventory/#description","title":"DESCRIPTION","text":"<p><code>nodeinventory</code> pulls information about hardware of a node.  This includes  information such as adapters, serial numbers, processors, and memory modules, as supported by the platforms hardware management implementation.  It accepts arguments such as serial or model or others as listed above to filter output to specific data.</p>"},{"location":"manuals/nodeinventory/#examples","title":"EXAMPLES","text":"<ul> <li> <p>Pulling inventory of a node named r1:   <code># nodeinventory r1</code> <code>r1: System MAC Address 1: 40:f2:e9:af:45:a0</code> <code>r1: System MAC Address 2: 40:f2:e9:af:45:a1</code> <code>r1: System MAC Address 3: 40:f2:e9:af:45:a2</code> <code>r1: System MAC Address 4: 40:f2:e9:af:45:a3</code> <code>r1: System Board manufacturer: IBM</code> <code>r1: System Product name: System x3650 M5</code> <code>r1: System Device ID: 32</code> <code>r1: System Revision: 9</code> <code>r1: System Product ID: 323</code> <code>r1: System Board model: 00KG915</code> <code>r1: System Device Revision: 0</code> <code>r1: System Serial Number: E2K4831</code> <code>r1: System Board manufacture date: 2014-10-20T12:00</code> <code>r1: System Board serial number: Y010UF4AL0B5</code> <code>r1: System Manufacturer: IBM</code> <code>r1: System FRU Number: 00FK639</code> <code>r1: System Board product name: System Board</code> <code>r1: System Model: 5462AC1</code> <code>r1: System UUID: 1B29CE46-765E-31A3-A3B9-B5FB934F15AB</code> <code>r1: System Hardware Version: 0x0000</code> <code>r1: System Manufacturer ID: 20301</code> <code>r1: System Chassis serial number: E2K4831</code> <code>r1: System Asset Number:</code> <code>r1: System Chassis type: Other</code> <code>r1: Power Supply 1 Board model: 94Y8136</code> <code>r1: Power Supply 1 Board manufacturer: EMER</code> <code>r1: Power Supply 1 FRU Number: 94Y8137</code> <code>r1: Power Supply 1 Board product name: IBM Designed Device</code> <code>r1: Power Supply 1 Board manufacture date: 2014-11-08T00:00</code> <code>r1: Power Supply 1 Board serial number:  K13814B88ED</code> <code>r1: Power Supply 1 Revision: 49</code> <code>r1: Power Supply 2: Not Present</code> <code>r1: DASD Backplane 1 Board model: 00JY139</code> <code>r1: DASD Backplane 1 Board manufacturer: WIST</code> <code>r1: DASD Backplane 1 FRU Number: 00FJ756</code> <code>r1: DASD Backplane 1 Board product name: IBM Designed Device</code> <code>r1: DASD Backplane 1 Board manufacture date: 2014-08-28T00:00</code> <code>r1: DASD Backplane 1 Board serial number: Y011UF48W02U</code> <code>r1: DASD Backplane 1 Revision: 0</code> <code>r1: DASD Backplane 2: Not Present</code> <code>r1: DASD Backplane 3: Not Present</code> <code>r1: DASD Backplane 4: Not Present</code> <code>r1: DASD Backplane 5 Board model: 00YJ530</code> <code>r1: DASD Backplane 5 Board manufacturer: WIST</code> <code>r1: DASD Backplane 5 FRU Number: 00AL953</code> <code>r1: DASD Backplane 5 Board product name: IBM Designed Device</code> <code>r1: DASD Backplane 5 Board manufacture date: 2016-02-04T00:00</code> <code>r1: DASD Backplane 5 Board serial number: Y010UF624024</code> <code>r1: DASD Backplane 5 Revision: 0</code> <code>r1: DASD Backplane 6: Not Present</code> <code>r1: CPU 1 Hardware Version: Intel(R) Xeon(R) CPU E5-2640 v3 @ 2.60GHz</code> <code>r1: CPU 1 Asset Number: Unknown</code> <code>r1: CPU 1 Manufacturer: Intel(R) Corporation</code> <code>r1: CPU 2: Not Present</code> <code>r1: ML2 Card: Not Present</code> <code>r1: DIMM 1: Not Present</code> <code>r1: DIMM 2: Not Present</code> <code>r1: DIMM 3: Not Present</code> <code>r1: DIMM 4: Not Present</code> <code>r1: DIMM 5: Not Present</code> <code>r1: DIMM 6: Not Present</code> <code>r1: DIMM 7: Not Present</code> <code>r1: DIMM 8: Not Present</code> <code>r1: DIMM 9: Not Present</code> <code>r1: DIMM 10: Not Present</code> <code>r1: DIMM 11: Not Present</code> <code>r1: DIMM 12: Not Present</code> <code>r1: DIMM 13: Not Present</code> <code>r1: DIMM 14: Not Present</code> <code>r1: DIMM 15: Not Present</code> <code>r1: DIMM 16: Not Present</code> <code>r1: DIMM 17: Not Present</code> <code>r1: DIMM 18: Not Present</code> <code>r1: DIMM 19: Not Present</code> <code>r1: DIMM 20: Not Present</code> <code>r1: DIMM 21: Not Present</code> <code>r1: DIMM 22: Not Present</code> <code>r1: DIMM 23: Not Present</code> <code>r1: DIMM 24: Not Present</code> <code>r1: X8 PCI 1: Not Present</code> <code>r1: X8 PCI 2: Not Present</code> <code>r1: X8 PCI 6: Not Present</code> <code>r1: X8 PCI 7: Not Present</code> <code>r1: Broadcom NetXtreme Gigabit Ethernet Controller MAC Address 1: 40:f2:e9:af:45:a0</code> <code>r1: Broadcom NetXtreme Gigabit Ethernet Controller MAC Address 2: 40:f2:e9:af:45:a1</code> <code>r1: Broadcom NetXtreme Gigabit Ethernet Controller MAC Address 3: 40:f2:e9:af:45:a2</code> <code>r1: Broadcom NetXtreme Gigabit Ethernet Controller MAC Address 4: 40:f2:e9:af:45:a3</code> <code>r1: Broadcom NetXtreme Gigabit Ethernet Controller PCI slot: 1b:00</code> <code>r1: Broadcom NetXtreme Gigabit Ethernet Controller location: Onboard</code> </p> </li> <li> <p>Reporting just the mac addresses of a node named r2:   <code># nodeinventory r2 mac</code> <code>r2: System MAC Address 1: 40:f2:e9:b9:10:18</code> <code>r2: System MAC Address 2: 40:f2:e9:b9:10:19</code> <code>r2: System MAC Address 3: 40:f2:e9:b9:10:1a</code> <code>r2: System MAC Address 4: 40:f2:e9:b9:10:1b</code></p> </li> <li> <p>Getting the model number and serial number of a node named s2:   <code># nodeinventory stark2 serial model</code> <code>s2: System Product name: LENOVO THINKSYSTEM SD530 SERVER</code> <code>s2: System Serial Number: DEV0000002</code> <code>s2: System Model: 7X2104Z028</code></p> </li> </ul>"},{"location":"manuals/nodel2traceroute/","title":"nodel2traceroute(8) -- returns the layer 2 route through an Ethernet network managed by confluent given 2 end points.","text":""},{"location":"manuals/nodel2traceroute/#synopsis","title":"SYNOPSIS","text":"<p><code>nodel2traceroute [options] &lt;var&gt;start_node&lt;/var&gt; &lt;var&gt;end_noderange&lt;/var&gt;</code> </p>"},{"location":"manuals/nodel2traceroute/#description","title":"DESCRIPTION","text":"<p>nodel2traceroute is a command that returns the layer 2 route for the configered interfaces in nodeattrib. It can also be used with the -i and -e options to check against specific interfaces on the endpoints. If the  --interface or --eface option are not used then the command will check for routes against all the defined  interfaces in nodeattrib (net.*.switch) for the nodes.</p>"},{"location":"manuals/nodel2traceroute/#prerequisites","title":"PREREQUISITES","text":"<p>nodel2traceroute the net.interface.switch attributes have to be set on the end points if endpoint is not a switch</p>"},{"location":"manuals/nodel2traceroute/#options","title":"OPTIONS","text":"<ul> <li><code>-e</code> EFACE, --eface=INTERFACE    interface to check against for the second end point or end points if using checking against multiple nodes </li> <li><code>-i</code> INTERFACE, --interface=INTERFACE    interface to check against for the first end point  </li> <li><code>-c</code> CUMULUS, --cumulus=CUMULUS    return layer 2 route through cumulus switches only </li> <li><code>-h</code>, <code>--help</code>:   Show help message and exit      </li> </ul>"},{"location":"manuals/nodel2traceroute/#examples","title":"EXAMPLES","text":"<ul> <li> <p>Checking route between two nodes: <code># nodel2traceroute n244 n1851</code> <code>n244 to n1851: ['switch114']</code> </p> </li> <li> <p>Checking route from one node to multiple nodes: <code># nodel2traceroute n244 n1833,n1851</code> <code>n244 to n1833: ['switch114', 'switch7', 'switch32', 'switch253', 'switch85', 'switch72', 'switch21', 'switch2', 'switch96', 'switch103', 'switch115']    n244 to n1851: ['switch114']</code> </p> </li> </ul>"},{"location":"manuals/nodelicense/","title":"nodelicense(8) -- Manage license keys on BMC","text":""},{"location":"manuals/nodelicense/#synopsis","title":"SYNOPSIS","text":"<p><code>nodelicense &lt;var&gt;noderange&lt;/var&gt; [list][install &lt;var&gt;license_filename&lt;/var&gt;|save &lt;var&gt;directory&lt;/var&gt;|delete &lt;var&gt;license_feature_name&lt;/var&gt;]</code></p>"},{"location":"manuals/nodelicense/#description","title":"DESCRIPTION","text":"<p><code>nodelicense</code> manages license keys on supported BMCs. Without an argument, the command lists currently installed license.  Using <code>delete</code> will remove the specified license name from the BMC.  The <code>save</code> subcommand will take the passed directory (which may be in the form of /path/to/{node}/ to have the node name substituted for each node) and back up installed licenses to that directory. The <code>install</code> command will take the specified filename and install.  The filename argument may be of the form  xcc_fod_0034_7X21{id.serial}.key to have the serial number substituted to allow unique licenses to be specified in a single command.</p>"},{"location":"manuals/nodelicense/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-m MAXNODES</code>, <code>--maxnodes=MAXNODES</code>:   Specify a maximum number of nodes to delete licenses from, prompting if over the threshold</p> </li> <li> <p><code>-h</code>, <code>--help</code>:   Show help message and exit</p> </li> </ul>"},{"location":"manuals/nodelist/","title":"nodelist(8) -- List confluent nodes and their attributes","text":""},{"location":"manuals/nodelist/#synopsis","title":"SYNOPSIS","text":"<p><code>nodelist &lt;var&gt;noderange&lt;/var&gt;</code> <code>nodelist &lt;var&gt;noderange&lt;/var&gt; [-b] [-d] {string} &lt;var&gt;nodeattribute&lt;/var&gt;...</code> </p>"},{"location":"manuals/nodelist/#description","title":"DESCRIPTION","text":"<p>nodelist queries the confluent server to get information about nodes.  In the simplest form, it simply takes the given noderange(5) and lists the matching nodes, one line at a time.</p> <p>If a list of node attribute names are given, the value of those are also displayed.  If <code>-b</code> is specified, it will also display information on how inherited and expression based attributes are defined.  There is more information on node attributes in nodeattributes(5) man page.</p> <p>Attributes may be specified by wildcard, for example <code>net.*switch</code> will report all attributes that begin with <code>net.</code> and end with <code>switch</code>.</p>"},{"location":"manuals/nodelist/#options","title":"OPTIONS","text":"<ul> <li><code>-b</code>, <code>--blame</code>:   Annotate inherited and expression based attributes to show their base value.</li> <li><code>-d</code>, <code>--delim</code>:   Choose a delimiter to separat the values. Default - ENTER.</li> </ul>"},{"location":"manuals/nodelist/#examples","title":"EXAMPLES","text":"<ul> <li> <p>Listing matching nodes of a simple noderange:   <code># nodelist n1-n4</code> <code>n1</code> <code>n2</code> <code>n3</code> <code>n4</code> </p> </li> <li> <p>Getting an attribute of nodes matching a noderange:   <code># nodelist n1,n2 hardwaremanagement.manager</code> <code>n1: hardwaremanagement.manager: 172.30.3.1</code> <code>n2: hardwaremanagement.manager: 172.30.3.2</code> </p> </li> <li> <p>Getting a group of attributes while determining what group defines them:   <code># nodelist n1,n2 hardwaremanegement --blame</code> <code>n1: hardwaremanagement.manager: 172.30.3.1</code> <code>n1: hardwaremanagement.method: ipmi (inherited from group everything)</code> <code>n1: hardwaremanagement.switch: r8e1</code> <code>n1: hardwaremanagement.switchport: 14</code> <code>n2: hardwaremanagement.manager: 172.30.3.2</code> <code>n2: hardwaremanagement.method: ipmi (inherited from group everything)</code> <code>n2: hardwaremanagement.switch: r8e1</code> <code>n2: hardwaremanagement.switchport: 2</code> </p> </li> </ul>"},{"location":"manuals/nodemedia/","title":"nodemedia(8) -- Manage server remote media","text":""},{"location":"manuals/nodemedia/#synopsis","title":"SYNOPSIS","text":"<p><code>nodemedia &lt;var&gt;noderange&lt;/var&gt; [attach|detachall|list|upload] [options] &lt;var&gt;media&lt;/var&gt;</code></p>"},{"location":"manuals/nodemedia/#description","title":"DESCRIPTION","text":"<p>nodemedia manages the remote media functionality of supported BMCs.</p> <p><code>list</code> shows all the current remote media the BMCs of the noderange are providing to the host platform.  The string (insecure) is appended to URLs that are mounted in an insecure fashion.  http is insecure, and https is also insecure when no meaningful certificate validation is performed.  Currently there is no action that can change this, and this is purely informational.  A future version of software may provide a means to increase security of attached remote media.  If no media is mounted, this will provide no output, error conditions will result in output to standard error.</p> <p><code>detachall</code> removes all the currently provided media to the host.  This unlinks remote media from urls and deletes uploaded media from the BMC.</p> <p><code>upload</code> takes the given media image and uploads it to the BMC.  This causes the remote media to reside internally to the system without having to go to the network after the upload.  This is more constrained, for example the Lenovo xClarity Controller has a limit of 50 megabytes, but it has zero ongoing load on the media source.</p> <p><code>attach</code> takes a URL to a remote media as an argument, and has the given BMCs map a virtual USB device to that url.  Content is loaded on demand, and as such that URL is referenced potentially once for every IO operation that the host platform attempts.</p>"},{"location":"manuals/nodemedia/#options","title":"OPTIONS","text":"<ul> <li><code>-h</code>, <code>--help</code>:   Show help message and exit</li> </ul>"},{"location":"manuals/nodemedia/#examples","title":"EXAMPLES","text":"<ul> <li> <p>Listing currently mounted media:   <code># nodemedia s1-s4 list</code> <code>s1: boot.img</code> <code>s2: boot.img</code> <code>s4: boot.img</code> </p> </li> <li> <p>Uploading a small boot image to the BMC:   <code># nodemedia s1-s4 upload boot.img</code> <code>s1:complete: 100%     s2:complete: 100%     s3:complete: 100%     s4:complete: 100%</code> <code>s1: boot.img</code> <code>s4: boot.img</code> <code>s2: boot.img</code> </p> </li> <li> <p>Attaching a larger ISO for on-demand access:   <code># nodemedia s1,s4 attach http://172.30.0.6/install/rhel74.iso</code> <code>s4: http://172.30.0.6/install/rhel74.iso (insecure)</code> <code>s1: http://172.30.0.6/install/rhel74.iso (insecure)</code></p> </li> </ul>"},{"location":"manuals/nodeping/","title":"nodeping(8) -- Pings a node or a noderange.","text":""},{"location":"manuals/nodeping/#synopsis","title":"SYNOPSIS","text":"<p><code>nodeping [options] noderange</code> </p>"},{"location":"manuals/nodeping/#description","title":"DESCRIPTION","text":"<p>nodeping is a command that pings the default NIC on a node. It can also be used with the <code>-s</code> flag to change the ping location to something that is 'non primary'</p>"},{"location":"manuals/nodeping/#options","title":"OPTIONS","text":"<ul> <li><code>-f</code> COUNT, <code>-c</code> COUNT, --count=COUNT    Number of commands to run at a time  </li> <li><code>-h</code>, <code>--help</code>:   Show help message and exit      </li> <li><code>-s</code> SUBSTITUTENAME, --substitutename=SUBSTITUTENAME   Use a different name other than the nodename for ping. This may be a    expression, such as {bmc} or, if no { character is present, it is treated as a suffix.  -s -eth1 would make n1 become n1-eth1, for example. </li> </ul>"},{"location":"manuals/nodeping/#examples","title":"EXAMPLES","text":"<ul> <li> <p>Pinging a node : <code># nodeping &lt;var&gt;node&lt;/var&gt;</code> <code>node : ping</code> </p> </li> <li> <p>Pinging a group: <code># nodeping &lt;var&gt;groupname&lt;/var&gt;</code> <code>Node1 : ping       Node2 : ping       Node3 : ping</code> </p> </li> <li> <p>Pinging BMC on a node: <code># nodeping -s {bmc} &lt;var&gt;noderange&lt;/var&gt;</code> <code>Node-bmc : ping</code> </p> </li> <li> <p>Pinging by specifying a suffix:   <code># nodeping d1-d4 -s -eth1</code> <code>d2-eth1: no_ping</code> <code>d1-eth1: no_ping</code> <code>d3-eth1: no_ping</code> <code>d4-eth1: no_ping</code> </p> </li> <li> <p>Fail to ping node: <code># nodeping &lt;var&gt;node&lt;/var&gt;</code> <code>node : no_ping</code> </p> </li> </ul>"},{"location":"manuals/nodepower/","title":"nodepower(8) -- Check or change power state of confluent nodes","text":""},{"location":"manuals/nodepower/#synopsis","title":"SYNOPSIS","text":"<p><code>nodepower [options] &lt;var&gt;noderange&lt;/var&gt; ([status|on|off|shutdown|boot|reset])</code></p>"},{"location":"manuals/nodepower/#description","title":"DESCRIPTION","text":"<p>nodepower with only a noderange will retrieve current power state of nodes through confluent.  When given an additional argument, it will request a change to the power state of the nodes.  The following arguments are recognized:</p> <ul> <li><code>on</code>: Turn on the specified noderange.  Nothing will happen to nodes of the noderange that are already on.</li> <li><code>off</code>:  Immediately turn off the specified noderange, without waiting for OS to shutdown.  Nothing will happen to nodes of the noderange that are already on.</li> <li><code>boot</code>:  Immediately boot a system.  This will power on nodes of the noderange that are off, and reset nodes of the noderange that are on.  The previous state will be reflected in the output.</li> <li><code>shutdown</code>:  Request the OS gracefully shut down.  Nothing will happen for nodes that are off, and nodes will not shutdown if the OS fails to gracefully respond.</li> <li><code>reset</code>:  Request immediate reset of nodes of the noderange.  Nodes that are off will not react to this request.</li> <li><code>status</code>:  Behave identically to having no argument passed at all.</li> <li><code>pdu_status</code>: Query state of associated PDU outlets, if configured.</li> <li><code>pdu_on</code>: Energize all PDU outlets associated with the noderange.</li> <li><code>pdu_off</code>: De-energize all PDU outlets associated with the noderange.</li> </ul>"},{"location":"manuals/nodepower/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-p</code>, <code>--showprevious</code>:    Show previous power state for all directives that may change power state.</p> </li> <li> <p><code>-m MAXNODES</code>, <code>--maxnodes=MAXNODES</code>:    Specify a maximum number of nodes to change power state, prompting if    over the threshold</p> </li> <li> <p><code>-h</code>, <code>--help</code>:   Show help message and exit   </p> </li> </ul>"},{"location":"manuals/nodepower/#examples","title":"EXAMPLES","text":"<ul> <li> <p>Get power state of nodes n1 through n4:   <code># nodepower n1-n4</code> <code>n1: on</code> <code>n2: on</code> <code>n3: on</code> <code>n4: off</code> </p> </li> <li> <p>Forcing a reboot of nodes n1-n4:     <code># nodepower n1-n4 boot</code> <code>n3: on-&gt;reset</code> <code>n1: on-&gt;reset</code> <code>n2: on-&gt;reset</code> <code>n4: off-&gt;on</code> </p> </li> </ul>"},{"location":"manuals/noderange/","title":"noderange(5) -- Indicate a target set of nodes in confluent","text":""},{"location":"manuals/noderange/#synopsis","title":"SYNOPSIS","text":"<p><code>&lt;var&gt;noderange&lt;/var&gt;</code> </p>"},{"location":"manuals/noderange/#description","title":"DESCRIPTION","text":"<p>noderange is a syntax that can be used in most Confluent commands to conveniently specify a list of nodes. The result is that the command will be applied to a range of nodes, often in parallel.</p>"},{"location":"manuals/noderange/#examples","title":"EXAMPLES:","text":"<p>The simplest noderange is a single node name: <code>n1</code></p> <p>Nodes and groups may be used interchangeably. The following may be used in any context where n1 would be accepted as a noderange: <code>rack1</code></p> <p>Commonly, there is a desire to target a range of elements. There are a few identically behaving syntaxes for the purpose. <code>n1:n20</code> <code>n1-n20</code> <code>n[1-20]</code></p> <p>Note that numbers may be zero padded or not, it will automatically detect the padding amount and adjust members of the range accordingly. Ranges also can understand multiple numeric values changing: <code>r[1-3]u[01-10]</code> <code>r1u01-r3u10</code></p> <p>Ranges can also be applied to group names, and all above syntaxes are compatible: <code>rack1-rack10</code> <code>rack[1-10]</code></p> <p>Also, regular expressions may be used to indicate nodes with names matching certain patterns: <code>~r1u..</code></p> <p>The other major noderange primitive is indicating nodes by some attribute value: <code>location.rack=7</code></p> <p>The attribute name may use a wildcard: <code>net.*switch=switch1</code></p> <p>Commas can be used to indicate multiple nodes, and can mix and match any of the above primitives. The following can be a valid single noderange, combining any and all members of each comma separated component <code>n1,n2,rack1,storage,location.rack=9,~s1..,n20-n30</code></p> <p>Exclusions can be done by prepending a '-' before a portion of a noderange: <code>rack1,-n2</code> <code>compute,-rack1</code> <code>compute,-location.row=12</code></p> <p>To indicate nodes that match multiple selections at once (set intersection), the @ symbol may be used: <code>compute@rack1</code> <code>location.rack=10@compute</code></p> <p>For complex expressions, () may be used to indicate order of expanding the noderange to be explicit <code>rack1,-(console.logging=full@compute)</code></p> <p>Noderange syntax can also indicate 'pagination', or separating the nodes into well defined chunks. &gt; is used to indicate how many nodes to display at a time, and &lt; is used to indicate how many nodes to skip into a noderange: <code>rack1&gt;3&lt;6</code></p> <p>The above would show the seventh through ninth nodes of the rack1 group. Like all other noderange operations, this may be combined with any of the above, but must appear as the very last operation. Ordering is done with a natural sort.</p>"},{"location":"manuals/noderemove/","title":"noderemove(8) -- Remove nodes from the confluent management service","text":""},{"location":"manuals/noderemove/#synopsis","title":"SYNOPSIS","text":"<p><code>noderemove &lt;var&gt;noderange&lt;/var&gt;</code> </p>"},{"location":"manuals/noderemove/#description","title":"DESCRIPTION","text":"<p><code>noderemove</code> simply removes the given noderange from the confluent database.</p>"},{"location":"manuals/noderemove/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-m MAXNODES</code>, <code>--maxnodes=MAXNODES</code>:     Specify a maximum number of nodes to delete, prompting if over the     threshold</p> </li> <li> <p><code>-h</code>, <code>--help</code>:   Show help message and exit    </p> </li> </ul>"},{"location":"manuals/noderemove/#examples","title":"EXAMPLES","text":"<ul> <li>Remove two racks each with 4 nodes:     <code># noderemove r1u1-r2u4</code> <code>r1u4: deleted</code> <code>r1u1: deleted</code> <code>r1u2: deleted</code> <code>r1u3: deleted</code> <code>r2u4: deleted</code> <code>r2u3: deleted</code> <code>r2u2: deleted</code> <code>r2u1: deleted</code> </li> </ul>"},{"location":"manuals/nodereseat/","title":"nodereseat(8) -- Request a reseat of a node","text":""},{"location":"manuals/nodereseat/#synopsis","title":"SYNOPSIS","text":"<p><code>nodereseat &lt;var&gt;noderange&lt;/var&gt;</code> </p>"},{"location":"manuals/nodereseat/#description","title":"DESCRIPTION","text":"<p><code>nodereseat</code> requests the enclosure manager of the current node to reseat that node's slot.  This should be equivalent to removing the system entirely from the chassis and putting it back in, but without actually having to do so.</p>"},{"location":"manuals/nodereseat/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-m MAXNODES</code>, <code>--maxnodes=MAXNODES</code>:     Specify a maximum number of nodes to reseat, prompting if over the threshold</p> </li> <li> <p><code>-h</code>, <code>--help</code>:   Show help message and exit    </p> </li> </ul>"},{"location":"manuals/nodereseat/#examples","title":"EXAMPLES","text":"<ul> <li>Reseating the node <code>s1</code>:     <code># nodereseat s1</code> <code>s1: Reseat successful</code> </li> </ul>"},{"location":"manuals/nodersync/","title":"nodersync(8) -- Run rsync in parallel against a noderange","text":""},{"location":"manuals/nodersync/#synopsis","title":"SYNOPSIS","text":"<p><code>nodersync &lt;file/directorylist&gt; &lt;var&gt;noderange&lt;/var&gt;:&lt;var&gt;destination&lt;/var&gt;</code> </p>"},{"location":"manuals/nodersync/#description","title":"DESCRIPTION","text":"<p>Supervises execution of rsync to push files or a directory tree to the specified noderange. This will present progress as percentage for all nodes.</p>"},{"location":"manuals/nodersync/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-f COUNT</code>, <code>-c COUNT</code>, <code>--count=COUNT</code>:   Specify how many rsync executions to do concurrently.  If noderange   exceeds the count, then excess nodes will wait until one of the   active count completes. </p> </li> <li> <p><code>-s</code>, <code>--substitutename</code>:   'Use a different name other than the nodename for rsync'</p> </li> <li> <p><code>-m MAXNODES</code>, <code>--maxnodes=MAXNODES</code>:   Specify a maximum number of nodes to run rsync to, prompting if over the   threshold</p> </li> <li> <p><code>-h</code>, <code>--help</code>:   Show help message and exit</p> </li> </ul>"},{"location":"manuals/noderun/","title":"noderun(8) -- Run arbitrary commands per node in a noderange","text":""},{"location":"manuals/noderun/#synopsis","title":"SYNOPSIS","text":"<p><code>noderun [options] &lt;var&gt;noderange&lt;/var&gt; &lt;var&gt;command expression&lt;/var&gt;</code></p>"},{"location":"manuals/noderun/#description","title":"DESCRIPTION","text":"<p><code>noderun</code> will take a given command and execute it in parallel once per node in the specified noderange.  Attribute expressions as documented in nodeattribexpressions(5) are expanded prior to execution of the command.  For noderun, the commands are locally executed.  To execute commands on the nodes themselves, see nodeshell(8).</p>"},{"location":"manuals/noderun/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-f COUNT</code>, <code>-c COUNT</code>, <code>--count=COUNT</code>:   Number of commands to run at a time</p> </li> <li> <p><code>-n</code>, <code>--nonodeprefix</code>:   Do not prefix output with node names</p> </li> <li> <p><code>-m MAXNODES</code>, <code>--maxnodes=MAXNODES</code>:   Specify a maximum number of nodes to run the command with, prompting if over   the threshold</p> </li> <li> <p><code>-h</code>, <code>--help</code>:   Show help message and exit</p> </li> </ul>"},{"location":"manuals/noderun/#examples","title":"EXAMPLES","text":"<ul> <li> <p>Run ping against nodes n1 through n4:   <code># noderun n1-n4 ping -c 1 {nodename}</code> <code>n3: PING n3 (172.30.2.3) 56(84) bytes of data.</code> <code>n3: 64 bytes from n3 (172.30.2.3): icmp_seq=1 ttl=64 time=0.387 ms</code> <code>n3:</code> <code>n3: --- n3 ping statistics ---</code> <code>n3: 1 packets transmitted, 1 received, 0% packet loss, time 0ms</code> <code>n3: rtt min/avg/max/mdev = 0.387/0.387/0.387/0.000 ms</code> <code>n4: PING n4 (172.30.2.4) 56(84) bytes of data.</code> <code>n4: 64 bytes from n4 (172.30.2.4): icmp_seq=1 ttl=64 time=0.325 ms</code> <code>n4:</code> <code>n4: --- n4 ping statistics ---</code> <code>n4: 1 packets transmitted, 1 received, 0% packet loss, time 0ms</code> <code>n4: rtt min/avg/max/mdev = 0.325/0.325/0.325/0.000 ms</code> <code>n2: PING n2 (172.30.2.2) 56(84) bytes of data.</code> <code>n2: From odin (172.30.0.6) icmp_seq=1 Destination Host Unreachable</code> <code>n2:</code> <code>n2: --- n2 ping statistics ---</code> <code>n2: 1 packets transmitted, 0 received, +1 errors, 100% packet loss, time 3000ms</code> <code>n2:</code> <code>n1: PING n1 (172.30.2.1) 56(84) bytes of data.</code> <code>n1:</code> <code>n1: --- n1 ping statistics ---</code> <code>n1: 1 packets transmitted, 0 received, 100% packet loss, time 10000ms</code> <code>n1:</code> </p> </li> <li> <p>Run an ipmitool raw command against the management controllers of n1 through n4:   <code># noderun n1-n4 ipmitool -I lanplus -U USERID -E -H {hardwaremanagement.manager} raw 0 1</code> <code>n3:  01 10 00</code> <code>n1:  01 10 00</code> <code>n4:  01 10 00</code> <code>n2:  01 10 00</code> </p> </li> <li> <p>If wanting to use literal {} in the command, they must be escaped by doubling:   <code># noderun n1-n4 \"echo {node} | awk '{{print $1}}'\"</code></p> </li> </ul>"},{"location":"manuals/noderun/#see-also","title":"SEE ALSO","text":"<p>nodeshell(8)</p>"},{"location":"manuals/nodesensors/","title":"nodesensors(8) --- Retrieve telemetry for sensors of confluent nodes","text":""},{"location":"manuals/nodesensors/#synopsis","title":"SYNOPSIS","text":"<p><code>nodesensors &lt;var&gt;noderange&lt;/var&gt; [-c] [-i &lt;var&gt;interval&lt;/var&gt;] [-n &lt;var&gt;samplecount&lt;/var&gt;]  [&lt;var&gt;sensor name  or category&lt;/var&gt;...]</code> </p>"},{"location":"manuals/nodesensors/#description","title":"DESCRIPTION","text":"<p>nodesensors queries the confluent server to get telemetry from nodes.  Telemetry can include data such as temperature, power, and so forth.  Without arguments, it lists all available sensors and their current values.  If <code>-c</code> is specified, CSV format is used for output.  Normally nodesensors outputs once and exits.  Repeated periodic gathering can be done with <code>-i</code> to specify interval and <code>-n</code> to specify number of requests.  If <code>-i</code> is specified without <code>-n</code>, then it will retrieve data at the requested interval indefinitely.  If '-n' is specified without <code>-i</code>, an interval of 1 second is used.</p>"},{"location":"manuals/nodesensors/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-c</code>, <code>--csv</code>:   Organize output into CSV format, one sensor per column.</p> </li> <li> <p><code>-i</code>, <code>--interval</code>=SECONDS:   Repeat data gathering waiting, waiting the specified time between samples.  Unless <code>-n</code> is   specified, indefinite retrieval is assumed.</p> </li> <li> <p><code>-n</code>, <code>--numreadings</code>=SAMPLES:   Perform the specified number of readings, waiting <code>-i</code> indicated interval or 1 second if not   otherwise indicated.</p> </li> <li> <p><code>-s</code>, <code>--skipnumberless</code>:   Return only sensors that provide numeric data (e.g. temperature, fanspeed),   ignoring sensors that do not provide numeric data.</p> </li> </ul>"},{"location":"manuals/nodesensors/#examples","title":"EXAMPLES","text":"<ul> <li> <p>Retrieving all temperature related sensors from one system <code># nodesensors n1 temperature</code> <code>n1: CPU 1 Overtemp: Ok</code> <code>n1: CPU 2 Overtemp: Ok</code> <code>n1: Inlet Temp: 16.0 \u00b0C</code> <code>n1: PCH Overtemp: Ok</code> <code>n1: LOM Temp: Ok</code> </p> </li> <li> <p>Retrieving a sensor named \"Inlet Temp\" for 4 systems over a 3 second period of time: <code># nodesensors n1-n4 'Inlet Temp' -c -n 3</code> <code>time,node,Inlet Temp (\u00b0C)</code> <code>2016-10-04T15:09:20,n1,19.0</code> <code>2016-10-04T15:09:20,n2,18.0</code> <code>2016-10-04T15:09:20,n3,18.0</code> <code>2016-10-04T15:09:20,n4,17.0</code> <code>2016-10-04T15:09:21,n1,19.0</code> <code>2016-10-04T15:09:21,n2,18.0</code> <code>2016-10-04T15:09:21,n3,18.0</code> <code>2016-10-04T15:09:21,n4,17.0</code> <code>2016-10-04T15:09:22,n1,19.0</code> <code>2016-10-04T15:09:22,n2,18.0</code> <code>2016-10-04T15:09:22,n3,18.0</code> <code>2016-10-04T15:09:22,n4,17.0</code> </p> </li> </ul>"},{"location":"manuals/nodesetboot/","title":"nodesetboot(8) -- Check or set next boot device for noderange","text":""},{"location":"manuals/nodesetboot/#synopsis","title":"SYNOPSIS","text":"<p><code>nodesetboot [options] &lt;var&gt;noderange&lt;/var&gt; [default|cd|network|setup|hd|usb|floppy]</code></p>"},{"location":"manuals/nodesetboot/#description","title":"DESCRIPTION","text":"<p>Requests that the next boot occur from the specified device.  Unless otherwise specified, this is a one time boot option, and does not change the normal boot behavior of the system.  This is useful for taking a system that normally boots to the hard drive and startking a network install, or to go into the firmware setup menu without having to hit a keystroke at the correct time on the console.</p> <p>Generally, it's a bit more convenient and direct to use the nodeboot(8) command, which will follow up the boot device with an immediate power directive to take effect.  The <code>nodesetboot</code> command is still useful, particularly if you want to use <code>nodesetboot &lt;var&gt;noderange&lt;/var&gt; setup</code> and then initiate a reboot from within the operating system with ssh or similar rather than using the remote hardware control.</p> <p>Running the command with no target queries the current setting.</p>"},{"location":"manuals/nodesetboot/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-b</code>, <code>--bios</code>:   For a system that supports both BIOS and UEFI style boot, request BIOS style   boot if supported (some platforms will UEFI boot with this flag anyway).</p> </li> <li> <p><code>-p</code>, <code>--persist</code>:   For a system that supports it, mark the boot override to persist rather than   be a one time change.  Many systems do not support this functionality.</p> </li> <li> <p><code>-u</code>, <code>--uefi</code>:   This flag does nothing, it is for command compatibility with xCAT's rsetboot</p> </li> <li> <p><code>-m MAXNODES</code>, <code>--maxnodes=MAXNODES</code>:   Specify a maximum number of nodes to modify next boot device, prompting if   over the threshold</p> </li> <li> <p><code>-h</code>, <code>--help</code>:   Show help message and exit  </p> </li> <li> <p><code>default</code>:   Request a normal default boot with no particular device override</p> </li> <li> <p><code>cd</code>:   Request boot from media.  Note that this can include physical CD,   remote media mounted as CD/DVD, and detachable hard disks drives such as usb   key devices.</p> </li> <li> <p><code>floppy</code>:   Request boot from floppy.  Generally speaking firmware uses this to mean a USB   flash drive or similar (whether virtual or physical).</p> </li> <li> <p><code>usb</code>:   Request boot from usb.  Generally speaking firmware uses this to mean a USB   flash drive or similar (whether virtual or physical).</p> </li> <li> <p><code>network</code>:   Request boot to network</p> </li> <li> <p><code>setup</code>:   Request to enter the firmware configuration menu (e.g. F1 setup) on next boot.</p> </li> <li> <p><code>hd</code>:   Boot straight to hard disk drive</p> </li> </ul>"},{"location":"manuals/nodesetboot/#examples","title":"EXAMPLES","text":"<ul> <li> <p>Set next boot to setup for four nodes:   <code># nodesetboot n1-n4 setup</code> <code>n1: setup</code> <code>n3: setup</code> <code>n2: setup</code> <code>n4: setup</code> </p> </li> <li> <p>Check boot override settings on four nodes:   <code># nodesetboot n1-n4</code> <code>n1: setup</code> <code>n2: setup</code> <code>n3: setup</code> <code>n4: setup</code> </p> </li> </ul>"},{"location":"manuals/nodesetboot/#see-also","title":"SEE ALSO","text":"<p>nodeboot(8)</p>"},{"location":"manuals/nodeshell/","title":"nodeshell(8) -- Execute command on many nodes in a noderange through ssh","text":""},{"location":"manuals/nodeshell/#synopsis","title":"SYNOPSIS","text":"<p><code>nodeshell [options] &lt;var&gt;noderange&lt;/var&gt; &lt;var&gt;command to execute on each node&lt;/var&gt;</code></p>"},{"location":"manuals/nodeshell/#description","title":"DESCRIPTION","text":"<p>Allows execution of a command on many nodes in parallel.  Like noderun(8), it accepts and interpolates confluent attribute expressions as documented in  nodeattribexpressions(5).  <code>nodeshell</code> provides stdout as stdout and stderr as stderr, unlike psh which combines all stdout and stderr into stdout.</p>"},{"location":"manuals/nodeshell/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-c COUNT</code>, <code>-f COUNT</code>, <code>--count=COUNT</code>   Specify the maximum number of instances to run concurrently</p> </li> <li> <p><code>-l LOGINNAME</code>, <code>--loginname=LOGINNAME</code>   Username to use when connecting, defaults to current user.</p> </li> <li> <p><code>-m MAXNODES</code>, <code>--maxnodes=MAXNODES</code>   Specify a maximum number of nodes to run remote ssh command to, prompting   if over the threshold</p> </li> <li> <p><code>-n</code>, <code>--nonodeprefix</code>   Do not prefix output with node names  </p> </li> <li> <p><code>-p PORT</code>, <code>--port=PORT</code>   Specify a custom port for ssh</p> </li> <li> <p><code>-s SUBSTITUTION</code>, <code>--substitutename=SUBSTITITUTION</code>   Specify a substitution name instead of the nodename.  If no {} are in the substitution,   it is considered to be an append.  For example, '-s -ib' would produce 'node1-ib' from 'node1'.   Full expression syntax is supported, in which case the substitution is considered to be the entire   new name. {node}-ib would be equivalent to -ib.  For example, nodeshell -s {bmc} node1    would ssh to the BMC instead of the node.</p> </li> </ul>"},{"location":"manuals/nodeshell/#examples","title":"EXAMPLES","text":"<ul> <li> <p>Running <code>echo hi</code> on for nodes:   <code># nodeshell n1-n4 echo hi</code> <code>n1: hi</code> <code>n2: hi</code> <code>n3: hi</code> <code>n4: hi</code> </p> </li> <li> <p>Setting a new static ip address temporarily on secondary interface of four nodes:   <code># nodeshell n1-n4 ifconfig eth1 172.30.93.{n1}</code></p> </li> <li> <p>If wanting to use literal {} in the command, they must be escaped by doubling:   <code># nodeshell n1-n4 \"ps | awk '{{print $1}}'\"</code></p> </li> </ul>"},{"location":"manuals/nodeshell/#see-also","title":"SEE ALSO","text":"<p>noderun(8)</p>"},{"location":"manuals/nodestorage/","title":"nodestorage(8) -- Examine/Modify storage configuration of a node","text":""},{"location":"manuals/nodestorage/#synopsis","title":"SYNOPSIS","text":"<p><code>nodestorage &lt;var&gt;noderange&lt;/var&gt; [show|create|delete|diskset] [hotspare|jbod|unconfigured] [options]</code> </p>"},{"location":"manuals/nodestorage/#description","title":"DESCRIPTION","text":"<p><code>nodestorage</code> provides access to the remote storage configuration of the noderange. The <code>show</code> subcommand will show current storage configuration, <code>create</code> can be used to create new arrays or volumes, <code>delete</code> can be used to remove volumes and arrays, and <code>diskset</code> can modify the usage of disks indicated by <code>-d</code> to either be <code>unconfigured</code>, <code>jbod</code>, or <code>hotspare</code>.</p>"},{"location":"manuals/nodestorage/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-r</code> RAIDLEVEL, <code>--raidlevel</code>=RAIDLEVEL:   RAID level to use when creating an array</p> </li> <li> <p><code>-d</code> DISKS, <code>--disks</code>=DISKS:    Comma separated list of disks to use, or the word \"rest\" to    indicate use of all available disks</p> </li> <li> <p><code>-s</code> SIZE, <code>--size</code>=SIZE:   Comma separated list of sizes to use when creating   volumes.  The sizes may be absolute size (e.g. 16gb),   percentage (10%) or the word \"rest\" to use remaining   capacity, default behavior is to use all capacity to   make a volume</p> </li> <li> <p><code>-n</code> NAME, <code>--name</code>=NAME:   Comma separated list of names to use when naming   volumes, or selecting a volume for delete.  Default   behavior is to use implementation provided default</p> </li> <li> <p><code>-z</code> STRIPSIZES, <code>--stripsizes</code>=STRIPSIZES:   Comma separated list of stripsizes to use when creating volumes.   This value is in kilobytes.  The default behavior is to allow the   storage controller to decide</p> </li> <li> <p><code>-m</code> MAXNODES, <code>--maxnodes</code>=MAXNODES:   Specify a maximum number of nodes to configure storage on, prompting   if over the threshold</p> </li> </ul>"},{"location":"manuals/nodestorage/#examples","title":"EXAMPLES","text":"<ul> <li> <p>Deleting the volume <code>somedata</code>:     <code>$ nodestorage d5 delete somedata</code> <code>Deleted: somedata</code> </p> </li> <li> <p>Creating a raid5 of 4 disks and a volume named <code>somedata</code>:     <code>$ nodestorage d5 create -r 5 -d drive0,drive_1,drive_2,drive_3 -n somedata</code> <code>d5: Volume somedata: Size: 1.905 TB</code> <code>d5: Volume somedata: State: Optimal</code> <code>d5: Volume somedata: Array 1-2</code> </p> </li> <li> <p>Showing current storage configuration of <code>d3</code>:     <code>$ nodestorage d3</code> <code>d3: Disk m.2-0 Description: 128GB M.2 SATA SSD</code> <code>d3: Disk m.2-0 State: online</code> <code>d3: Disk m.2-0 FRU: 00LF428</code> <code>d3: Disk m.2-0 Serial Number: H6B80054</code> <code>d3: Disk m.2-0 Array: 0-0</code> <code>d3: Disk m.2-1 Description: 128GB M.2 SATA SSD</code> <code>d3: Disk m.2-1 State: online</code> <code>d3: Disk m.2-1 FRU: 00LF428</code> <code>d3: Disk m.2-1 Serial Number: H6B80059</code> <code>d3: Disk m.2-1 Array: 0-0</code> <code>d3: Array 0-0 Available Capacity: 0.000 MB</code> <code>d3: Array 0-0 Total Capacity: 131.072 GB</code> <code>d3: Array 0-0 RAID: RAID 1</code> <code>d3: Array 0-0 Disks: m.2-0,m.2-1</code> <code>d3: Array 0-0 Volumes: new_vd</code> <code>d3: Volume new_vd: Size: 122.040 GB</code> <code>d3: Volume new_vd: State: Optimal</code> <code>d3: Volume new_vd: Array 0-0</code> </p> </li> </ul>"},{"location":"manuals/nodesupport/","title":"nodesupport(8) -- Utilities for interacting with vendor support","text":""},{"location":"manuals/nodesupport/#synopsis","title":"SYNOPSIS","text":"<p><code>nodesupport &lt;var&gt;noderange&lt;/var&gt; servicedata &lt;var&gt;directory or filename&lt;/var&gt;</code> </p>"},{"location":"manuals/nodesupport/#description","title":"DESCRIPTION","text":"<p><code>nodesupport</code> provides capabilities associated with interacting with support. Currently it only has the <code>servicedata</code> subcommand.  <code>servicedata</code> takes an argument that is either a directory name (that can be used for a single node or multiple nodes) or a file name (only to be used with single node noderange). Note that the file will be downloaded to the confluent server that actually connects to the managed system, so it will download to the remote system if running remotely and will download to the collective.manager indicated system if running in collective mode.</p> <p>Note that due to vendor filename requirements, any filename may have vendor specific suffixes added to any file produced.</p>"},{"location":"manuals/nodesupport/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-m MAXNODES</code>, <code>--maxnodes=MAXNODES</code>:   Specify a maximum number of nodes to download diagnostic data from, prompting   if over the threshold</p> </li> <li> <p><code>-h</code>, <code>--help</code>:   Show help message and exit  </p> </li> </ul>"},{"location":"manuals/nodesupport/#examples","title":"EXAMPLES","text":"<ul> <li> <p>Download support data from a single node to a specific filename <code># nodesupport d1 servicedata svcdata.out</code> <code>d1:initializing:  15%</code> </p> </li> <li> <p>Download support data from multiple nodes to a directory <code># nodesupport d1-d4 servicedata service/</code> <code>d1:initializing:   0% d2:initializing:   0% d3:initializing:   0% d4:initializing:   0%</code> <code># ls service/</code> <code>d1.svcdata d2.svcdata  d3.svcdata  d4.svcdata</code> </p> </li> </ul>"},{"location":"manuals/osdeploy/","title":"osdeploy(8) --- Configure general OS deployment facilities of confluent","text":""},{"location":"manuals/osdeploy/#synopsis","title":"SYNOPSIS","text":"<p><code>osdeploy import &lt;var&gt;iso&lt;/var&gt;</code> <code>osdeploy updateboot &lt;var&gt;profile&lt;/var&gt;</code> <code>osdeploy rebase &lt;var&gt;profile&lt;/var&gt;</code> <code>osdeploy initialize [-h] [-g] [-u] [-s] [-k] [-t] [-p] [-i] [-l] [-a]</code> </p>"},{"location":"manuals/osdeploy/#description","title":"DESCRIPTION","text":"<p>osdeploy manages the facilities and os deployment content of a confluent server. The <code>import</code> subcommand will generate profiles from an iso image. <code>updateboot</code> will take any changes in the specified update that need to be pushed into boot configuration and/or images and ensure those needed changes are performed. <code>initialize</code> provides assistance in setting up the most commonly required facilities. <code>rebase</code> has confluent attempt to update profile content that came from /opt/confluent in an rpm update, if profile supports it.  Run <code>osdeploy initialize -h</code> for more detail on the options offered by <code>osdeploy initialize</code>.</p>"},{"location":"manuals/stats/","title":"stats(8) -- Common basic statistics on typical numeric data in output","text":""},{"location":"manuals/stats/#synopsis","title":"SYNOPSIS","text":"<p>`other command | stats [-c N] [-d D] [-x|-g|-t|-o image.png] [-s N] [-v] [-b N]</p>"},{"location":"manuals/stats/#description","title":"DESCRIPTION","text":"<p>The stats command helps analyze common numerical data such as performance numbers or temperatures or any other numerical value.</p> <p>By default it looks for the last numerical output on the first line to identify the numerical column and analyze that number. This can be overriden by -c COLUMN to indicate a column. By default, whitespace and commas are treated to delimit columns, and -d DELIMITER can be used to override.</p> <p>By default it outputs basic statistics, but a histogram is available either text or through X11 output or sixel or output to an image file depending on whether -x, -g, -t*, or **-o image.png is used.</p>"},{"location":"manuals/stats/#options","title":"OPTIONS","text":"<ul> <li> <p><code>-c N</code>:    Select column number. Defaults to last column that appears numeric</p> </li> <li> <p><code>-d D</code>:    Specify a custom column delimiter</p> </li> <li> <p><code>-x</code>:      Output in Sixel format (supported by mlterm and PuTTY, among others)</p> </li> <li> <p><code>-g</code>:    Try to open histogram as an X window</p> </li> <li> <p><code>-t</code>:    Output histogram as bars rendered by =</p> </li> <li> <p><code>-o image.png</code>:    Write graphical histogram to image.png.</p> </li> <li> <p><code>-s N</code>:    Ignore specified number of lines as header content before processing numbers</p> </li> <li> <p><code>-v</code>:    Treat value before : on each line as a label, and show which labels belong to which histogram buckets.</p> </li> <li> <p><code>-b N</code>:    Specify a custom number of buckets for histogram. The default is 10.</p> </li> </ul>"},{"location":"miscellaneous/collective_arch/","title":"Confluent collective architecture","text":"<p>This document will describe the design of the confluent collective implementation.</p>"},{"location":"miscellaneous/collective_arch/#collective-contrasted-with-hierarchical-mode","title":"Collective contrasted with 'Hierarchical' mode","text":"<p>In xCAT, the design point was generally is 'head' system and some number of 'service nodes'. If desiring HA in the 'head' role, it was up to the user to provide an active-backup HA solution.  If the 'head' system is gone, this generally meant the 'service nodes' would no longer function (as the head node is conventionally also the shared database user).</p> <p>In confluent, as far as confluent itself is concerned, all members are equivalent and no member is considered 'head' versus 'service'. However, it may still be deployed in a hierarchical manner where conventionally certain nodes are considered the 'head' system by administrators and 'service nodes' are collective members that reside on the appropriate networks to manage/deploy a subset of systems.  The main apparent difference will be that service nodes no longer care about the 'head' nodes going offline compared to a similar xCAT configuration.</p>"},{"location":"miscellaneous/collective_arch/#example-topologies","title":"Example topologies","text":"<p>As confluent does not have restrictions around the role of collective members, there is flexibility in how you may approach a collective.</p> <p>The collective may be flat, with all nodes equally bound to any collective member: </p> <p>It may be hierarchical with a node designated a head node by convention and delegating nodes to specific collective members: </p> <p>It my be hierachical with pools of collective managers available to each segment: </p> <p>Or it may be a headless segmented collective, where the 'head' role is omitted: </p> <p>Any other number of mix and match of the above strategies may be used in a collective.</p>"},{"location":"miscellaneous/collective_arch/#intra-collective-trust","title":"Intra-collective trust","text":"<p>The invite token generated as part of the invite/join procedure is used as a shared secret to mutually attest to the in-use certificates for a join, and the persistent trust is managed through mutual TLS authentication. Every communication within a collective is protected by the certificates that were in-use at the time of issuing the join with the correct token.  Note that while the collective member that issued the invitation is validating the client, the client is also using the invitation to authenticate the collective member, assuring both parties that both certificates are valid with no intermediaries.</p>"},{"location":"miscellaneous/collective_arch/#replicated-data","title":"Replicated data","text":"<p>The node attribute database is inherently replicated internally by confluent by collective members. This contrasts to xCAT in that no external database is required, and replication of the database is handled implicitly by joining the collective.  At every point, every active collective member has a full copy of the node attribute database and persists it locally to /etc/confluent/cfg. When a collective member goes offline and later reconnects, the full node attribute database is replicated to the reconnecting member.</p>"},{"location":"miscellaneous/collective_arch/#quorum","title":"Quorum","text":"<p>Confluent collective is driven by a straightforward quorum scheme: if half or more collective members are unreachable, the collective locks down functionality. At this time this includes all collective members with no mechanism to indicate consideration of only a subset.</p>"},{"location":"miscellaneous/collective_arch/#shared-storage-consideration","title":"Shared storage consideration","text":"<p>While the node attribute database is replicated automatically among collective members, the /var/lib/confluent storage used by OS deployment must be synchronized or shared at the user's discretion.  There is no particular requirement placed on the mechanism beyond that it be consistent when used by the collective members, so a number of storage synchronization or remote/clustered filesystem approaches are acceptable. In contrast to xCAT, where /install was expected to be partially consistent, partially unique to the service node, confluent expects the entirety of the directory to be consistent.</p>"},{"location":"miscellaneous/collective_arch/#request-routing","title":"Request routing","text":"<p>A request/command may be issued to any member of the collective and will be internally distributed as appropriate among collective members according to nodes' respective collective.manager.</p>"},{"location":"miscellaneous/collective_arch/#failover-of-collective-manager","title":"Failover of collective manager","text":"<p>When a collective member goes offline, nodes currently managed as indicated by <code>collective.manager</code> can be automatically reassigned by setting <code>collective.managercandidates</code>.</p>"},{"location":"miscellaneous/collective_arch/#restricting-os-deployment-to-select-collective-members","title":"Restricting OS deployment to select collective members","text":"<p>In addition to indicating candidates for automatic failover, collective.managercandidates also indicates collective members that are allowed to offer deployment services to the respective node.</p>"},{"location":"miscellaneous/collective_arch/#considerations-for-local-services-like-dhcptftp","title":"Considerations for local services like DHCP/tftp","text":"<p>In xCAT, the head/service nodes required specific DHCP configuration and usually service node specific boot configuration files.  In confluent, there are no such requirements.  The DHCP activity may be delegated or static assignments are given from the confluent server direct from the replicated node attribute database. The deployment profiles no longer require the deployment server be indicated on the kernel command line, and code in the linux environments handle that, again directly interacting with confluent service and by extension the node attribute database.  There are no longer node-specific nor deployer-specific command line arguments.</p>"},{"location":"miscellaneous/confignet/","title":"Confluent multi interface configuration","text":"<p>Confluent profiles initialized as of 3.3 or later contain the <code>confignet</code> network configuration facility. It is invoked in the default firstboot sections of scripted install profiles and onboot sections of diskless profiles.</p>"},{"location":"miscellaneous/confignet/#specifiying-multiple-network-interface-configuration","title":"Specifiying multiple network interface configuration","text":"<p>The <code>net.*</code> attributes may be qualified by name. For example, it's possible to specify <code>net.management.ipv4_address=172.16.0.{n1}/16</code> and <code>net.compute.ipv4_address=172.17.0.{n1}/16</code>. The name between <code>net</code> and the specific attribute is up to the user and has no particular meaning to confluent apart from the name being used to group settings together.</p>"},{"location":"miscellaneous/confignet/#configuring-additional-interfaces-with-autosense","title":"Configuring additional interfaces with autosense","text":"<p>If a confluent deployment server is configured for a given subnet, the deploying server will autosense the correct IP subnet and match the group automatically. <pre><code>net.deployment.ipv4_address=1.2.3.4/16\n</code></pre></p>"},{"location":"miscellaneous/confignet/#configuring-additional-interfacces-manually","title":"Configuring additional interfacces manually","text":"<p>If autosense is not feasible or not desired, specifiy <code>net.name.interface_names</code> to indicate the interface to use with this network configuration.  For example: <pre><code>net.infiniband.interface_names=ib0\nnet.infiniband.ipv4_address=1.2.3.4/16\n</code></pre></p>"},{"location":"miscellaneous/confignet/#configuring-a-network-interface-team","title":"Configuring a network interface team","text":"<p>confignet supports configuring teams by specifiying the team mode by, for example, <code>net.compute.team_mode=lacp</code>. If the team members are on the same subnet as a confluent deployment servers, the members may be autodetected. If the member interfaces do not share a subnet with a confluent server, then the names must be explicitly specified in <code>net.*.interface_names</code>, e.g. <code>ib0,ib1</code>. </p> <p>Example of a team that shares a network segment with a confluent server: <pre><code>net.example.team_mode=lacp\nnet.example.ipv4_address=1.2.3.4/16\n</code></pre></p> <p>Example of a team that does not share a network with a confluent server: <pre><code>net.example.team_mode=lacp\nnet.example.ipv4_address=4.3.2.1/16\nnet.example.interface_names=eno1,eno2\n</code></pre></p>"},{"location":"miscellaneous/confignet/#features-not-implemented","title":"Features not implemented","text":"<p>The current features are not currently implemented as of this writing:</p> <ul> <li>VLAN tagging</li> <li>Bridging/vSwitch configuration</li> <li>Static routes apart from default gateway</li> </ul>"},{"location":"miscellaneous/confluentadoptnode/","title":"Adding an installed node to confluent SSH setup","text":"<p>This procedure will provide confluent SSH configuration to a node that was not installed by confluent.</p> <p>It is recommended to backup /etc/ssh on the target system before proceeding.</p> <p>First, have an OS profile available in confluent that roughly matches the distribution running on the target. For example, if the target is running any version or variant of Red Hat Enterprise Linux 7, then select a confluent profile based on an 'el7' distribution.</p> <p>Download three scripts to the confluent deployment server: <pre><code>https://raw.githubusercontent.com/xcat2/confluent/refs/heads/master/misc/adoptnode.sh\nhttps://raw.githubusercontent.com/xcat2/confluent/refs/heads/master/misc/finalizeadopt.sh\nhttps://raw.githubusercontent.com/xcat2/confluent/refs/heads/master/misc/prepadopt.sh\n</code></pre></p> <p>Invoke the adoptnode.sh script as follows: <pre><code>sh adoptnode.sh &lt;nodename&gt; &lt;profilename&gt;\n</code></pre></p> <p>This may prompt to accept the current host key and may prompt for password.</p> <p>After this procedure, ssh to and from the indicated nodename should behave as if it were installed by confluent, without having to reinstall the system.</p>"},{"location":"miscellaneous/confluentbackup/","title":"Confluent Database backup and restore","text":"<p>Confluent maintains its database in /etc/confluent/cfg</p> <p>For a plain text backup and restore capability, the <code>confluentdbutil</code> utility is provided.</p>"},{"location":"miscellaneous/confluentbackup/#backing-up-the-database","title":"Backing up the database","text":"<p>The recommended approach is to do at least one interactive backup:</p> <pre><code># confluentdbutil -p BackupPassw0rd dump /tmp/backup/\n</code></pre> <p>This will encrypt the encryption keys used to protect passwords that may need to be retained using a password that will be required to restore. The backup consists of some .json files:</p> <pre><code># ls /tmp/backup/\ncollective.json  keys.json  main.json\n</code></pre> <p>As an interactive backup is incompatible with a regular backup scheme, once you have one backup as above with a password protected keys.json file, the -s option may be used to skip keys.json for an unattended backup:</p> <pre><code># confluentdbutil -s dump /tmp/unattended/\n# ls /tmp/unattended/\ncollective.json  main.json\n</code></pre> <p>This backup is a full backup, but lacks a keys.json file to decrypt the content, and thus cannot be restored by itself.  </p>"},{"location":"miscellaneous/confluentbackup/#restoring-from-backup","title":"Restoring from backup","text":"<p>If following the example above, and desiring to restore from the '/tmp/unattended/' backup, first copy in a keys.json file from the interactive backup:</p> <pre><code># cp /tmp/backup/keys.json /tmp/unattended\n</code></pre> <p>This will turn the backup in /tmp/unattended into a password protected backup that can be restored.</p> <p>With this, /tmp/unattended may be restored:</p> <pre><code># confluentdbutil -p BackupPassw0rd restore /tmp/unattended\n</code></pre> <p>If running the restore as root, then you may need to change ownership back to confluent user:</p> <pre><code># chown confluent /etc/confluent/cfg/*\n</code></pre>"},{"location":"miscellaneous/confluentbackup/#redacting-configuration","title":"Redacting configuration","text":"<p>Additionally, <code>confluentdbutil dump -r</code> will generate a dump that redacts the potentially sensitive material, if wanting to share for diagnostic purposes.</p> <pre><code># confluentdbutil -r dump /tmp/redacted\n</code></pre> <p>See confluentdbutil man page for more detail.</p>"},{"location":"miscellaneous/confluentcumulus/","title":"Using a Cumulus switch with confluent","text":"<p>In order to use a Cumulus switch with confluent, it requires installation of the <code>affluent</code> agent.  Install the .deb file from /opt/confluent/share/affluent/ onto the switch:</p> <pre><code># scp /opt/confluent/share/affluent/*.deb cumulus@r4c1:~\n# ssh -t cumulus@r4c1 sudo apt install ~cumulus/affluent_*.deb\n</code></pre> <p>Note that if the installation occured after confluent tried to interrogate the switch, you may need to restart confluent:</p> <pre><code># systemctl restart confluent\n</code></pre> <p>With that installation complete, the switch merely has to be added to confluent.  Use the resolvable hostname or ip address as the nodename(s):</p> <pre><code># nodedefine r4c1 type=switch hardwaremanagement.method=affluent\n</code></pre> <p>If the user and password is not set by the group (e.g. everything), then set those attributes as well:</p> <pre><code># nodeattrib r4c1 -p switchuser switchpass\n</code></pre> <p>The user and password would be the same that you would use to ssh into the switch.</p> <p>With a managed switch, <code>nodehealth</code>, <code>nodesensors</code>, <code>nodefirmware</code>, and <code>nodeinventory</code> work:</p> <pre><code># nodehealth r4c1\nr4c1: critical (PSU1:status is all_not_ok, 1, 1, installed)\n# nodesensors r4c1\nr4c1: Fan Tray 3: 3863 RPM\nr4c1: Fan Tray 2: 3977 RPM\nr4c1: Fan Tray 1: 4204 RPM\nr4c1: PSU2:\nr4c1: PSU1: critical,status is all_not_ok, 1, 1, installed\nr4c1: CPU board: 37.50000 \u00b0C\nr4c1: Fan board: 33.00000 \u00b0C\nr4c1: Ambient 2: 47.00000 \u00b0C\nr4c1: Ambient 1: 36.50000 \u00b0C\nr4c1: Networking ASIC Die Temp Sensor: 50.10000 \u00b0C\nr4c1: Networking ASIC Die Temp Sensor: 51.30000 \u00b0C\nr4c1: Networking ASIC Die Temp Sensor: 50.10000 \u00b0C\nr4c1: Core 1: 29.00000 \u00b0C\nr4c1: Core 0: 29.00000 \u00b0C\n# nodeinventory r4c1\nr4c1: System Manufacturer: Lenovo\nr4c1: System Serial Number: NNNNNNNN\nr4c1: System Product name: Lenovo ThinkSystem NE0152T RackSwitch\nr4c1: System Model: 7Y81CTO1WW\nr4c1: System Board manufacture date: 03/05/2019 13:33:34\nr4c1: System Revision: 4\n# nodefirmware r4c1 \nr4c1: Cumulus Linux: 4.2.0\n</code></pre> <p>Also, the /networking API and dependent discovery functionality is enabled.</p>"},{"location":"miscellaneous/confluentdhcp/","title":"Confluent and DHCP interaction","text":"<p>For confluent OS deployment, a specific design goal is improved interoperability with DHCP infrastructure. The result is that a DHCP server is not required, but also an independent DHCP server can be used on a network.</p> <p>For a standalone deployment without specific need for a dynamic pool, this doesn't require much consideration, the network will 'just work'. However, there are some considerations in various scenarios.</p>"},{"location":"miscellaneous/confluentdhcp/#working-with-an-uncoordinated-dhcp-server-offering-dynamic-addresses","title":"Working with an uncoordinated DHCP server offering dynamic addresses","text":"<p>The node attribute <code>net.ipv4_method</code> supports two possible modes for working with a DHCP server on the same network.</p> <ul> <li><code>firmwaredhcp</code> delegates address management to the external DHCP server during Network boot by firmware, but static addressing will be used in the OS</li> <li><code>dhcp</code> fully delegates address management to the external DHCP server</li> </ul> <p>In a mostly static environment with a need for dynamic addressing, it is possible to use firmwaredhcp and setting dnsmasq or similar to serve up a dynamic range without having to coordinate the configuration.</p>"},{"location":"miscellaneous/confluentdhcp/#working-with-xcat-configured-dhcp-server","title":"Working with xCAT configured DHCP server","text":"<p>With xCAT, the biggest potential for conflict is the dynamic range, where xCAT will offer any network boot device a boot payload and potentially conflict.  There are a few strategies:</p> <ul> <li>Disabling the dynamic range.  Remove the dynamic ranges entirely from networks table, and either makedhcp -n to recreate dhcpd.conf, or manually comment out the range statements in dhcpd.conf</li> <li>Having devices only do HTTP boot.  xCAT does not support HTTP boot, so nodes doing HTTP boot will not receive offers from xCAT</li> <li>Removing the boot payload from dynamic offers.  In dhcpd.conf, comment/remove the gpxe.no-pxedhcp option as well as filename entries to make the xCAT dhcp server no longer offer boot direction to unknown systems</li> </ul>"},{"location":"miscellaneous/confluentdhcp/#how-confluent-works-without-a-dynamic-range","title":"How confluent works without a dynamic range","text":"<p>xCAT uses a dynamic range to boot linux on all unknown systems, and then in that linux environment work is done to try to discover the system.  In confluent, there are two discovery strategies:</p> <ul> <li>BMC first discovery: Confluent can do discovery based on accessing/configuring BMCs first, allowing traditional discovery and configuration to be possible, even when the system off.  This can succeed even without IPv4 configuration by use of IPv6 link-local addressing.</li> <li>IP-free PXE discovery: When doing PXE driven discovery when the BMC option is unavailable, confluent uses the contents of the DHCPDISCOVER packet to drive discovery, rather than a Linux payload.  This gathers UUID and MAC addresses, which is enough to drive discovery.</li> </ul>"},{"location":"miscellaneous/confluentdiskless/","title":"Using confluent diskless support","text":"<p>Confluent offers the ability to create diskless images to boot operating systems. This facility is managed through the <code>imgutil</code> command.</p>"},{"location":"miscellaneous/confluentdiskless/#importing-from-installation-media","title":"Importing from installation media","text":"<p>When going to build a diskless image, the default is to pull from the same repositories that the current operating system is using. However, it is possible to deploy from imported media.  If wanting to use this strategy, import the media as normal:</p> <pre><code># osdeploy import AlmaLinux-8.5-x86_64-dvd.iso \nImporting from /root/AlmaLinux-8.5-x86_64-dvd.iso to /var/lib/confluent/distributions/alma-8.5-x86_64\ncomplete: 100.00%    \nDeployment profile created: alma-8.5-x86_64-default\n</code></pre>"},{"location":"miscellaneous/confluentdiskless/#creating-initial-root-filesystem-tree","title":"Creating initial root filesystem tree","text":"<p>In confluent, the root filesystem can be built wherever you like and does not need to be retained after packing.  To build a new image from scratch:</p> <pre><code># imgutil build -s alma-8.5-x86_64 /tmp/scratchdir\n</code></pre> <p>The <code>-s</code> argument is optional, but when used should refer to a distribution in <code>osdeploy list</code>.  Tab completion also will work to help see the applicable options.  The /tmp/scratchdir directory tree is now ready for customization.</p>"},{"location":"miscellaneous/confluentdiskless/#customizing-the-root-filesystem-tree","title":"Customizing the root filesystem tree","text":"<p><code>imgutil</code> provides an <code>exec</code> facility to help customize an root filesystem tree.  It starts the tree specified using container technologies (namespaces and chroot). It is possible to make a directory available from the build system into the exec environment with the -v argument.  For example, to have root's home directory available:</p> <pre><code># imgutil exec -v /root:- /tmp/scratchdir\n[IMGUTIL EXEC scratchdir /]$ ls /root/\nMLNX_OFED_LINUX-5.4-3.1.0.0-rhel8.5-x86_64  MLNX_OFED_LINUX-5.4-3.1.0.0-rhel8.5-x86_64.tgz\n</code></pre> <p>This can be used to execute arbitrary commands in a scripted fashion:</p> <pre><code># imgutil exec /tmp/scratchdir -- yum -y install perl\n# imgutil exec -v /root:- /tmp/scratchdir -- /root/MLNX_OFED_LINUX-5.4-3.1.0.0-rhel8.5-x86_64/mlnxofedinstall --distro rhel8.5\n</code></pre>"},{"location":"miscellaneous/confluentdiskless/#packing-the-image-for-boot","title":"Packing the image for boot","text":"<p>Once the tree has been prepared, it needs to be packed to a profile name of your chosing, e.g.:</p> <pre><code># imgutil pack /tmp/scratchdir/ alma-8.5-diskless\n</code></pre> <p>Once packed, the /tmp/scratchdir may be deleted if desired:</p> <pre><code># rm -rf /tmp/scratchdir\n</code></pre>"},{"location":"miscellaneous/confluentdiskless/#unpacking-image-for-modification","title":"Unpacking image for modification","text":"<p>If at any point a modification or update is required, <code>imgutil</code> can unpack a profile to a new location:</p> <pre><code># imgutil unpack alma-8.5-diskless /tmp/newscratchdir\nParallel unsquashfs: Using 24 processors\n29355 inodes (40094 blocks) to write\n\n[=======================================================================/] 40094/40094 100%\n\ncreated 24563 files\ncreated 4940 directories\ncreated 2916 symlinks\ncreated 0 devices\ncreated 0 fifos\n</code></pre> <p>At which point modifications using imgutil exec or otherwise modifying the directory tree can be done.  If wanting to pack a new 'version' of an image while preserving customizations to scripts, you can use an existing diskless image profile to base a copy on:</p> <pre><code># imgutil pack -b alma-8.5-diskless /tmp/newscratchdir alma-8.5-disklesss-v2\n</code></pre> <p>Note that '-b' will not function correctly if the distribution and nature of the profile do not match (e.g. using a different major version of linux, or trying to use diskful profile as a base for a diskless image).</p> <p>This is a recommended method to preserve both copies until the new image is determined to be correctly working</p>"},{"location":"miscellaneous/confluentdiskless/#duplicating-an-image-without-repacking","title":"Duplicating an image without repacking","text":"<p>If wanting to copy a diskless profile for reasons that do not require repacking, then you must copy both /var/lib/confluent/private/os/ and /var/lib/confluent/public/os/. The private portion usually contains an encryption key needed for the packed image to boot."},{"location":"miscellaneous/confluentdiskless/#login-delays","title":"Login delays","text":"<p>If accounts suffer a one-time delay after initial login, this is likely due to systemd user slice failing to actually function. To mitigate, it is possible to modify thte TimeoutStopSec value in /usr/lib/systemd/system/user@.service to a smaller value, like 10s</p>"},{"location":"miscellaneous/confluentdiskless/#selinux-labelling-issues","title":"SELinux labelling issues","text":"<p>If errors arise during booting suggesting that, for example, sshd_config is not writable, it may be due to a mislabeled image. By default, the image should be labeled correctly, but if the scratch filesystem use did not support proper labelling, this can be a problem. To fix the labeling, select an appropriate filesystem (e.g. the root filesystem generally is well equipped) and do:</p> <pre><code>imgutil unpack image-name /tmp/scratchdir\ncd /tmp/scratchdir\nsetfiles -r . /etc/selinux/targeted/contexts/files/file_contexts .\nimgputil pack /tmp/scratchdir -b image-name new-image-name\n</code></pre>"},{"location":"miscellaneous/confluentdiskless/#moving-an-image-between-confluent-servers","title":"Moving an image between confluent servers","text":"<p>A diskless image is comprised of private and public directories in /var/lib/confluent. To archive an image for moving between different confluent instances, tar will suffice: <pre><code>[root@mgt1 confluent]# cd /var/lib/confluent/\n[root@mgt1 confluent]# tar cf stream-image.tar public/os/stream86-diskless private/os/stream86-diskless\n</code></pre></p> <p>On the server importing: <pre><code>[root@mgt2 confluent]# tar f stream-image.tar\n[root@mgt2 confluent]# osdeploy updateboot stream86-diskless\n</code></pre></p> <p>This will preserve permissions and owner as well as leave symbolic links in a state to pick up the new confluent server addons and site specific content.</p>"},{"location":"miscellaneous/confluentdiskless/#using-another-host-to-build-diskless-images","title":"Using another host to build diskless images","text":"<p>If building an image is easier on another system, this is possible. For example, if the operating system mismatches or some software requires specific hardware to install. This is best accomplished by installing confluent on the 'build' system, but not bothering to define any nodes. This will include osdeploy initialize to have the profiles be complete, but the TLS and SSH data will not be carried over by the tar file and will take the site data from the target confluent instance. In this scenario, simply build as documented here and then use the procedure for moving an image between confluent servers to place the image into your deployment infrastructure.</p>"},{"location":"miscellaneous/confluentdiskless/#sles-15-diskless-image-product-selection","title":"SLES 15 diskless image product selection","text":"<p>By default, building a SLES 15 diskless image will be setup as SuSE Linux Enterprise Server.  If the SuSE Linux Enterprise HPC product is desired, an additional package list file, including the SLE_HPC-release package should be created and specified with the \"imgutil build -a\" switch.</p>"},{"location":"miscellaneous/confluentdiskless_arch/","title":"Confluent diskless architecture","text":"<p>The confluent diskless implementation has a number of design points of interest compared to other diskless implementations or scripted install.</p>"},{"location":"miscellaneous/confluentdiskless_arch/#build-process","title":"Build process","text":"<p>In confluent, the <code>imgutil</code> command handles building, packing, unpacking, and modifying diskless images as well as cloning. Building and unpacking create a chroot-style directory. The <code>exec</code> subcommand allows spawning a specified directory in a new mount and process namespace with workable new filesystems mounted such as /proc and /sys. The images are generated in such a way as to naturally produce a diskless initramfs. As a result, a normal rpm upgrade that would generate an updated initramfs for a disk-installed system now also works in the <code>exec</code> environment of a diskless image. Additionally, the normal mkinitramfs/dracut/mkinitrd commands serve to generate the correct diskless filesystem.  Finally, packing an image produces a squashfs of the root filesystem, as well as extracting the appropriate kernel and initramfs.</p>"},{"location":"miscellaneous/confluentdiskless_arch/#tethered-diskless","title":"Tethered diskless","text":"<p>The default behavior is tethered diskless, where the diskless system detects paths to all relevant collective members and registers a filesystem to download from them in a multipath fashion on-demand. This avoids the up-front penalty in time and memory for downloading an entire diskless image, and avoids downloading unused portions of the image entirely. However, this precludes the ability of repacking in-place, and thus one must avoid packing over an in-use tethered diskless image.</p>"},{"location":"miscellaneous/confluentdiskless_arch/#untethered-diskless","title":"Untethered diskless","text":"<p>If wanting to uncouple from the filesystem, changing profile.yaml to untethered will alter the behavior. Rather than download on demand, the filesystem will be entirely downloaded to ram up-front. This will result in slower boot and larger memory consumption, but the memory consumption is still mitigated by leaving the filesystem compressed.</p>"},{"location":"miscellaneous/confluentdiskless_arch/#writing-to-root-filesystem-in-diskless-mode","title":"Writing to root filesystem in diskless mode","text":"<p>The root filesystem is combined through overlay with a compressed ram xfs filesystem, with discard enabled. This means writes are compressed to mitigate memory cost and memory may be reclaimed through deleting written files. All data written in this manner will be lost on reboot. As of this writing, selective persistence of writable files to a remote filesystem is up to the user to implement.</p>"},{"location":"miscellaneous/confluentdiskless_arch/#sensitive-information-in-diskless-images-and-encryption","title":"Sensitive information in diskless images and encryption","text":"<p>All effort is made to avoid writing sensitive information to the images, but rpms and exec may result in sensitive data in the filesystem beyond confluent's awareness.  Since the image is served over a public web server, it is therefore encrypted by default, with the private key stored in the 'private' directory alongside the 'public' directory.  This key is only provided through the confluent api</p>"},{"location":"miscellaneous/confluentdiskless_arch/#node-authentication-using-tpm2","title":"Node authentication using TPM2","text":"<p>No persistence to disk is possible to maintain node credentials such as ssh keys or the confluent node api key.  By default confluent diskless requires the use of a TPM2 to persist and protect the node api key.  During the diskless boot, an attempt is made to retrieve the Confluent Node API key from the TPM. If this fails it falls back to network attempt to get api key, and if that succeeds installs the new api key into the TPM.</p> <p>The TPM has a concept of 'Platform Configuration Registers', which may be used to measure various facets of the system and allow for certain data to be locked unless the registers are a certain value.  Prior to booting the OS, confluent diskless by default extends PCR 15 to lock the data such that the TPM is unable to provide the API key again until a system reboot.  This protects the node api key even if a user gains access to the TPM after boot.</p> <p>The api key is then used to retrieve information from the confluent service, such as the crypted root password. New ssh keys are generated every boot, and the api key is used to request a confluent server sign the new key, providing trust persistence for known_hosts despite a frequently changing host key.  This avoids transmission of any host or user private key in the confluent diskless environment, and enables secure trust persistence across reboots in a diskless environment.</p>"},{"location":"miscellaneous/confluentpxedisco/","title":"Using PXE driven discovery","text":"<p>While the best experience is through discovering the xClarity Controller first and having full management prior to PXE booting, sometimes this is not feasible. Two such scenarios would be:</p> <ul> <li>The management controller may not be a supported device for discovery (xClarity Controller, ThinkSystem Server Manager, and System Management Module are supported devices.</li> <li>The configuration has the management controller unavailable (for example, needing to move the management controller onto a port shared with the operating system)</li> </ul> <p>In such a scenario, doing discovery PXE first is a strategy to move forward.  Note that prior to confluent performing a PXE driven discovery, confluent must have OS deployment capability initialized</p>"},{"location":"miscellaneous/confluentpxedisco/#specifying-a-deployment-target-in-advance","title":"Specifying a deployment target in advance","text":"<p>In confluent, the deployment may be directed before MAC addresses are yet known. For example to boot to Genesis (a provided diskless image for basic servicing and setup):</p> <pre><code># nodedeploy n1 -n -p genesis-x86_64\n</code></pre> <p>Or to boot into the installer on first viable boot attempt:</p> <pre><code># nodedeploy d4 -n -p rhel-8.2-x86_64-default\n</code></pre> <p>Doing this in advance provides the earliest possible entry into a manageable operating system.</p>"},{"location":"miscellaneous/confluentpxedisco/#specifying-known-mac-address","title":"Specifying known mac address","text":"<p>It is supported to use a well known mac address without going through the discovery process.  Simply do:</p> <pre><code># nodedefine n1 net.hwaddr=00:01:02:03:04:05\n</code></pre> <p>To use it directly if mac address(es) are already known.</p>"},{"location":"miscellaneous/confluentpxedisco/#manual-discovery-of-unknown-mac-addresses","title":"Manual discovery of unknown mac addresses","text":"<p>The relevant system(s) must attempt a network boot. Generally new servers will tend to do this by default, so this is likely a matter of pressing the power button once.</p> <p>Once attempted, nodediscover will list all detected mac addresses: <pre><code># nodediscover list -t pxe-client\n Node| Model| Serial|                                 UUID|       Mac Address|       Type| Current IP Addresses\n-----|------|-------|-------------------------------------|------------------|-----------|---------------------\n     |      |       | 58962b3d-088b-11e7-b8b8-9e59e5cf61db| 08:94:ef:41:01:f0| pxe-client|                     \n</code></pre> An entry can be associated with a node in the same fashion as manual discovery</p> <pre><code># nodediscover assign -e 08:94:ef:41:01:f0 -n n1\nAssigned: n1\n</code></pre>"},{"location":"miscellaneous/confluentpxedisco/#automatic-discovery-of-mac-addresses","title":"Automatic discovery of mac addresses","text":"<p>The same mechanisms that may be used for management controller and enclosure controller discovery in using switch based discovery may be used to help gather the PXE information automatically.  The difference being that <code>nodediscover rescan</code> will not work for PXE attempts, and confluent must simply wait for an attempt before it can proceed.</p> <p>One example to designate the system cabled to a switch named <code>r4e1</code> on port <code>34</code> as <code>n1</code> and enable fully automatic mac gathering would be:</p> <pre><code># nodedefine n1 discovery.policy=permissive,pxe net.switch=r4e1 net.switchport=34\n</code></pre>"},{"location":"miscellaneous/confluentpxedisco/#using-pxe-driven-discovery-to-locally-configure-bmcs","title":"Using PXE driven discovery to locally configure BMCs","text":"<p>In this scenario it is generally desired to configure the BMC automatically, setting IP configuration and if applicable, moving it to the appropriate network port. The desired network port may be specified by the <code>hardwaremanagement.port</code> attribute. The most commonly desired values for PXE driven discovery would be <code>lom</code> to use the network port built into the system board of the device, or <code>ocp</code> to use an OCP card to provide BMC access.</p> <pre><code># nodeattrib n1 hardwaremanagement.port=lom\n</code></pre> <p>There are systems that have two <code>lom</code> ports that are configurable for hardware management. In this case it is possible to choose which port to use by specifying either the port number or the connecter type. </p> <pre><code># nodeattrib n1 hardwaremanagement.port=lom_1\n# nodeattrib n3 hardwaremanagement.port=low_sfp28\n</code></pre> <p>In order for this setting to be applied by the OS profile, the OS profile must invoke the configbmc script. For genesis, see <code>/var/lib/confluent/public/os/genesis-x86_64/scripts/onboot.sh</code> file for information on how to configure BMC locally, for OS install, see <code>/var/lib/confluent/public/os/&lt;profilename&gt;/scripts/pre.custom</code></p> <p>After configbmc runs, then out of band discovery can pick up newly available management controllers and finish configuration as needed for ipmi or setting username or passwords. Do a rescan to induce discovery of the newly available devices:</p> <pre><code># nodediscover rescan\n</code></pre>"},{"location":"miscellaneous/confluentvxcat/","title":"xCAT and confluent comparison","text":"<p>As of confluent 3.0, the scope of Confluent has increased to cover much of xCAT functionality. There will remain some differences and some gaps.</p>"},{"location":"miscellaneous/confluentvxcat/#features-not-currently-in-confluent","title":"Features not currently in confluent","text":"<p>Confluent does not cover all functionality of xCAT. Some functions of xCAT that are currently not in confluent are:</p> <ul> <li>Virtualization management</li> </ul>"},{"location":"miscellaneous/confluentvxcat/#interoperability","title":"Interoperability","text":"<p>xCAT generally is an all or nothing proposition. For full functionality, it must control DHCP, OS deployment, the BMC, and any data that is used in discovery can only be used to feed xCAT workflows.</p> <p>Confluent is designed for improved interoperability. It does not require control of services like DHCP, is less particular about DNS, and provides data more transparently to feed discovery data to alternative OS deployment software if desired rather than using the built in facilities.</p>"},{"location":"miscellaneous/confluentvxcat/#security","title":"Security","text":"<p>xCAT generally expects a trusted network and offers material unencrypted in various contexts. It does not support running under SELinux and it does not support SecureBoot.</p> <p>The default configuration of confluent protects sensitive data. Even after opting into more convenient behavior, confluent will still protect sensitive data more than xCAT. Notably: * Fully encrypted deployment over HTTPS is supported (Firmware configuration required) * tftp is now optional (Can use HTTP or HTTPS boot instead) * SecureBoot deployment is supported (HTTP or HTTPS boot only) * For RHEL/CentOS 8.2 or higher, encrypting the boot volume using the TPM is supported * For network deployments, a node api token is acquired by a node only once * All TLS communication is meaningfully validated against certificate authorities or stored fingerprints * System root password and grub passwords are stored only as non-recoverable hashes * Passwords are afforded greater protection when they must be stored (e.g. for accessing switches or BMCs) * Non-recoverable hash of root password is no longer trivially retrieved from default kickstart files or images * Default SSH configuration is more hardened, no private key of any sort is sent across the network</p>"},{"location":"miscellaneous/confluentvxcat/#name-resolution","title":"Name resolution","text":"<p>In xCAT, makedns is provided as an aid to generate ISC BIND configuration. However, it does not require this be used, and is content so long as forward and reverse lookup works exactly as expected.</p> <p>In confluent, no helper facility is provided for name configuration, documentation instead mentions how to use dnsmasq if no other name resolution is otherwise in use. It is strongly recommended for forward resolution to function, though not required, and reverse lookup no longer has an impact on identifying nodes and will not cause problem identifying nodes if missing or not particularly configured.</p>"},{"location":"miscellaneous/confluentvxcat/#dhcp","title":"DHCP","text":"<p>In xCAT, control of DHCP is mandatory for discovery and deployment functionality. No other DHCP server may be running on a network that xCAT needs to do discovery or deployment on.</p> <p>In Confluent, DHCP is optional and even when present is not managed by Confluent. No dynamic range is required for any discovery. The default behavior is to use static IP address. It may also be configured to always defer IP configuration to an external DHCP server or to do so only for the firmware phase (PXE/HTTP boot) but use static for the OS.</p>"},{"location":"miscellaneous/confluentvxcat/#discovery","title":"Discovery","text":"<p>In xCAT, discovery requires that xCAT generate a dhcp configuration with a pool of dynamic addresses and boot into Linux on the nodes to begin the process.</p> <p>In Confluent, discovery no longer has this requirement. For many scenarios, discovery can occur without the server ever powering on. If PXE driven discovery is required, the discovery occurs when firmware attempts the network boot, even if no DHCP answer will be sent. A genesis environment is provided, though no longer required. <code>configbmc</code> may be used from either genesis <code>scripts/onboot.sh</code> or see <code>scripts/pre.custom</code> for an example to run it during application of an OS installation profile.</p>"},{"location":"miscellaneous/confluentvxcat/#deployment-profiles","title":"Deployment profiles","text":"<p>In xCAT, deployment profiles  are comprised of content distributed across various directories combined and enhanced by data from various tables. This is powerful for having script content shared across images, but makes things complicated to follow and the implications of upgrading unclear.</p> <p>In Confluent, OS 'images' are simply the directories in /var/lib/confluent/public/os. All content is either a symbolic link or copy. If confluent is upgraded, no existing profiles will be altered in terms of kickstart, autoyast, autoinstall, or script content.  While it is encouraged to modify 'custom' files to keep it simple to pull in potential future enhancements, no content will be replaced automatically on upgrade unless it is a symbolic link.</p> <p>Additionally, all nodes download the exact same set of boot configuration files and kickstart (or similar) files. All per-node specialization takes place on the target system rather than on the deployment server, as was the case in xCAT.</p>"},{"location":"miscellaneous/confluentvxcat/#postscripts","title":"Postscripts","text":"<p>In xCAT, postscripts are in /install/postscripts and referenced by either osimage or per node entries across the pertinent tables.</p> <p>In confluent, scripts are always in the OS image profile itself, and invoking them is a matter of modifying the appropriate script for the phase of boot. Most commonly, scripts/firstboot.custom, scripts/post.custom. Unlike xCAT, having distinct postscripts per node sharing a common OS profile is not supported, and delegating that complexity to a facility such as salt or ansible is recommended.</p>"},{"location":"miscellaneous/confluentvxcat/#ssh-infrastructure","title":"SSH Infrastructure","text":"<p>In xCAT, known_hosts was mitigated through disabling strict host key checking and copying down a common private host key to all nodes. This means that the host key was not well protected and also not unique (which mattered for some applications that presumed unique keys).</p> <p>In confluent, strict host key checking is left at default, and host keys are managed through certificate authorities. Whenever a redeploy occurs, the node will generate brand new keys privately and the public key is given a certificate.</p> <p>In xCAT, root's public key from a head node is placed in authorized_keys on all nodes. Further it is popular to copy down root's private key to facilitate node to node ssh. On the other hand, this optional behavior puts root's private key at risk.  Non-root users receive no accommodations.</p> <p>In Confluent, each collective member root public key is added to deployed authorized_keys, to enable ssh from any collective member to any node. root's private key is never sent across the wire under any circumstance, instead the work to fix known_hosts across the board is leveraged to enable host-based authentication within a confluent cluster. This extends to both the root user and all other users on the systems.</p>"},{"location":"miscellaneous/confluentvxcat/#diskless","title":"Diskless","text":"<p>In xCAT, diskless images require a special script to run to generate the diskless and statelite initramfs.  Once ready, packimage tries to trim 'superfluous' content and creates a compressed image that is always downloaded and uncompressed into RAM. It is expected that the extracted form of the image persists in the <code>/install</code> directory.</p> <p>In confluent, more efforts are made to have the built image naturally regenerate its own initramfs, meaning rpm installs that naturally trigger initramfs updates no longer require the user to go back and specially generate.  The pack utilitiy leaves the entire image intact and creates a compressed image that is by default downloaded on demand into evictable cache. Further, the read-write layer of a diskless image is compressed to mitigate memory usage over time. Images may be booted <code>untethered</code>, but even then the image remains compressed in memory. The workflow is such that images can be unpacked from their packed form for updates and maintenance, removing requirements for retaining the extracted form in an particular location.  Further, an <code>imgutil exec</code> facility is provided to boot an extracted image in a container-like environment (dedicated mount and process namespaces with chroot).  Also, a diskless image retains initramfs access for root user of collective nodes after the main image has booted, to facilitate debug.</p>"},{"location":"miscellaneous/containerized-confluent/","title":"Containerized confluent run","text":""},{"location":"miscellaneous/containerized-confluent/#synopsys","title":"Synopsys","text":"<p>Containerized confluent image with docker</p>"},{"location":"miscellaneous/containerized-confluent/#solution","title":"Solution","text":"<p>To create a containerized confluent image with docker we need to edit the custom file \"/confluent/container/Dockerfile </p>"},{"location":"miscellaneous/containerized-confluent/#constrains","title":"Constrains:","text":"<p>Container must be run privileged. Container must be run with the ' --net = host' flag.</p>"},{"location":"miscellaneous/containerized-confluent/#dockerfile-customization","title":"Dockerfile customization","text":"<pre><code>1  FROM almalinux:8\n</code></pre> <p>Modify above line with the desired OS.</p> <p>Please note that Lenovo does NOT HOST any OS. The OS will be taken from a repository outside of Lenovo control. </p> <p>The next lines can be edited with the specific package manager commands. </p> <p>These will pull and install the dependencies needed to run confluent.</p> <pre><code>2   RUN   [\"yum\", \"-y\", \"update\"]\n\n3   RUN   [\"rpm\", \"-ivh\", \"https://hpc.lenovo.com/yum/latest/el8/x86_64/lenovo-hpc-yum-1-1.x86_64.rpm\"]\n\n4   RUN   [\"yum\", \"-y\", \"install\", \"lenovo-confluent\", \"tftp-server\", \"openssh-clients\", \"openssl\", \"vim-enhanced\", \"iproute\"]\n</code></pre> <p>At the end we have the last two commands:</p> <pre><code>5   ADD runconfluent.sh /bin/\n\n6   CMD [\"/bin/bash\", \"/bin/runconfluent.sh\"]\n</code></pre> <p>These will add to bin and run the \"runconfluent.sh\" file that will install and run confluent. (default /confluent/container/runconfluent.sh)</p>"},{"location":"miscellaneous/containerized-confluent/#reference","title":"Reference","text":"<p>https://github.com/lenovo/confluent/blob/master/container/Dockerfile https://github.com/lenovo/confluent/blob/master/container/runconfluent.sh</p>"},{"location":"miscellaneous/customosimage/","title":"Creating a custom confluent OS image","text":"<p>Sometimes the options available for <code>osdeploy import</code> are too limited and an additional boot payload is desired. In such a scenario, it is feasible to create a custom OS install image payload. The requirements for a confluent OS payload are, ultimately:</p> <ul> <li>Must be a directory located in /var/lib/confluent/public/os/</li> <li>Has a <code>profile.yaml</code> file that at least says 'label: Friendly label here` in it.</li> </ul> <p>While more options are possible, it is most straightforward to consider a 'custom' payload to be either a generic linux based OS payload or an utterly generic payload that is not linux based.</p> <p>For a custom Linux payload that is too different from a stock profile to start from a copy, the following additional requirements should be considered to be compatible with <code>osdeploy updateboot</code>: * Add desired kernel command line arguments to profile.yaml, e.g. <code>kernelargs: quiet</code> * Place the kernel in boot/kernel * Place any initramfs content into boot/initramfs/ directory. * Optionally, you may wish to link /var/lib/confluent/public/site/initramfs.cpio to the image sub-directory to get the site TLS and SSH certificates during initrd * It is highly recommended to put an appropriate grub and optionally shim into boot/efi/boot/grubx64.efi and efi/boot/BOOTX64.efi</p> <p>For a more generic OS payload (e.g. Windows), osdeploy updateboot cannot be supported, and the following must be done for the image,  * Contains a boot.ipxe file that is a valid ipxe script if wanting to support PXE boot (for Windows PE, this would generally include wimboot and the wim file that you want to boot) * Contains a boot.img file if wanting to support HTTP/HTTPS boot that is a VFAT filesystem with efi/boot/BOOTx64.efi file in it.</p>"},{"location":"miscellaneous/energyhistogram/","title":"Energy histogram","text":"<p>Lenovo servers capture power level over time and provide information about the power usage over time in the form of a histogram.</p> <p>In order to retrieve the current accumulated histogram data:</p> <pre><code># renergy n1 relhistogram\nn1: 30w-34w: 112\nn1: 70w-74w: 6561\nn1: 75w-79w: 36892\nn1: 80w-84w: 2814\nn1: 85w-89w: 27834\nn1: 90w-94w: 1104\nn1: 95w-99w: 1520\nn1: 100w-104w: 2272\nn1: 105w-109w: 2576\nn1: 110w-114w: 400\nn1: 115w-119w: 259\nn1: 120w-124w: 369\nn1: 125w-129w: 96\nn1: 130w-134w: 48\nn1: 135w-139w: 16\nn1: 145w-149w: 16\nn1: 150w-154w: 64\nn1: 155w-159w: 864\nn1: 160w-164w: 1776\nn1: 165w-169w: 3858\nn1: 170w-174w: 14398\nn1: 175w-179w: 50798\nn1: 180w-184w: 16\n</code></pre> <p>In order to use the data to measure the histogram of power usage over a desired interval, capture this data at the beginning of the interval and then again at the conclusion of the interval and subtract the final result from the initial.  Note that the interval should  not exceed 12 hours, as beyond that some of the individual counters may wrap.</p>"},{"location":"miscellaneous/makelimitedtls/","title":"Makelimitedtls","text":"<p>This will create a certificate authority that is identical, but constrained.</p> <p>It will also create a certificate with SAN values limited to the authorized scope, as TLS checks all possible SAN values against the constraints, rather than just the pertinent subset.</p> <p>Make a copy of the opensslcfg with a new section: [san_env] subjectAltName=${ENV::SAN}</p> <p>Make a new csr: openssl req -new -key /etc/pki/tls/private/localhost.key -out /tmp/huh.csr -subj /CN=r3u20.devcluster.net  </p> <p>Sign it with designated DNS as SAN:</p> <p>SAN=DNS:r3u20.devcluster.net openssl ca -config /tmp/openssltmp.cfg -in /tmp/huh.csr -out /etc/pki/tls/certs/fqdn.cert -batch -notext -startdate 19700101010101Z -enddate 21000101010101Z -extensions san_env</p> <p>Add some 'ServerName' directive to the existing virtualhost, do not match it to the name for everyone, but it need not match specifically what is used  ServerName unknownserver <p>Underneath the default, define specific virtualhost to indicate correct key material  ServerName r3u20.devcluster.net SSLCertificateFile /etc/pki/tls/certs/fqdn.crt SSLCertificateKeyFile /etc/pki/tls/private/localhost.key SSLEngine on </p>"},{"location":"miscellaneous/manageconfluent/","title":"Managing hardware using confluent","text":"<p>As mentioned in the configuring confluent section, confluent manages nodes through a few node attributes.</p> <p>The most critical attributes for this section are:</p> <ul> <li><code>hardwaremanagement.method</code> with the following options:</li> <li><code>ipmi</code> (default) - Most widely implemented and quick, the plugin may use non-IPMI protocols as needed to get additional information.</li> <li><code>redfish</code> - A newer standard that generally offers richer information, at the cost of generally being slower.</li> <li><code>affluent</code> - Communicate with a network switch with the affluent agent (see using a cumulus switch with confluent)</li> <li><code>cnos</code> - Communicate with a Lenovo network switch running CNOS</li> <li><code>console.method</code> - currently only provides ipmi.  Leave blank to opt out of <code>nodeconsole</code> and console logging, or set to <code>ipmi</code> to opt into <code>ipmi</code> console.</li> <li><code>hardwaremanagement.manager</code> - May alternatively be referred by alias <code>bmc</code>: The name or IP address of the xClarity Controller or equivalent associated with this node.</li> <li><code>enclosure.bay</code> - For systems that are installed into an enclosure, the bay the node is located (which can help with <code>nodereseat</code> as well as discovery)</li> <li><code>enclosure.manager</code> - The resolveable name or ip address of the device managing the enclosure that would ultimately perform commands like <code>nodereseat</code> on behalf of a node.)</li> <li><code>secret.hardwaremanagementpassword</code> - May alternatively be referred to by alias <code>bmcpass</code>: The password to log into the xClarity Controller or equivalent</li> <li><code>secret.hardwaremanagementuser</code> - May alternatively be referred to by alias <code>bmcuser</code>: The user to log into the xClarity Controller or equivalent</li> </ul> <p>Once a node has the necessary attributes defined, most commands that begin with node become functional.</p> <p>Some examples are provided here, see the list of man pages for more possibilities and more detail on each command.</p> <p>Hard resetting nodes:</p> <pre><code># nodepower d3-d6 boot\nd3: on-&gt;reset\nd5: on-&gt;reset\nd6: on-&gt;reset\nd4: on-&gt;reset\n</code></pre> <p>Forcing a boot into firmware configuration menu:</p> <pre><code># nodeboot d3-d6 setup\nd3: setup\nd4: setup\nd5: setup\nd6: setup\nd3: reset\nd4: reset\nd5: reset\nd6: reset\n</code></pre> <p>Accessing the console of a node:</p> <pre><code># nodeconsole d4\n</code></pre> <p>Forcing a boot to network (e.g. to do a PXE or HTTP based deployment)</p> <pre><code># nodeboot d3-d6 net\nd3: network\nd4: network\nd5: network\nd6: network\nd3: reset\nd4: reset\nd5: reset\nd6: reset\n</code></pre> <p>Examining firmware on a system:</p> <pre><code># nodefirmware d5\nd5: XCC: 4.00 (TEI3A4L 2020-07-13T23:58:08)\nd5: XCC Backup: 1.20 (TEI316A 2017-10-30T00:00:00)\nd5: XCC Trusted Image: TEI3A4L\nd5: XCC Pending Update: 4.00 (TEI3A4L 2020-07-13T00:00:00)\nd5: UEFI: 2.70 (TEE160L 2020-07-13T00:00:00)\nd5: LXPM: 1.10 (PDL110O 2017-10-17T00:00:00)\nd5: LXPM Windows Driver Bundle: 1.10 (PDL310P 2017-10-25T00:00:00)\nd5: LXPM Linux Driver Bundle: 1.10 (PDL210O 2017-10-17T00:00:00)\nd5: FPGA: 5.3.0\nd5: Intel X722 LOM Combined Option ROM Image: 1.1767.0\nd5: Intel X722 LOM Etrack ID: 80000D24\nd5: ThinkSystem RAID 530-8i Dense MegaRAID Controller Firmware: 50.0.1-0378 (2017-08-01T00:00:00)\nd5: ThinkSystem M.2 with Mirroring Enablement Kit Marvell Firmware: 2.3.10.1194 (2018-07-13T00:00:00)\nd5: ThinkSystem M.2 with Mirroring Enablement Kit MRVL UEFI AHCI Driver and BIOS: 0.0.10.1024 (2017-10-25T00:00:00)\nd5: Disk 0 ST1000NX0423: LE43\nd5: Disk 1 ST1000NX0423: LE43\nd5: Disk 2 ST1000NX0423: LE43\nd5: Disk 3 ST1000NX0423: LE43\nd5: Disk M.2-1 LITEON CV3-8D128: T87RA31 \nd5: Disk M.2-2 LITEON CV3-8D128: T87RA31\n</code></pre> <p>Applying a single XCC update across nodes d4,d5, and d6</p> <pre><code># nodefirmware d4-d6 update lnvgy_fw_xcc_tei3a4l-4.00_anyos_noarch.uxz \nd4:upload:   5%       d5:upload:   5%       d6:upload:   6%       \n...\n# nodebmcreset d4-d6\nd4: BMC Reset Successful\nd6: BMC Reset Successful\nd5: BMC Reset Successful\n</code></pre> <p>Checking firmware of XCC and using collate to check consistency:</p> <pre><code># nodefirmware d3-d6 xcc |collate\n====================================\nd4,d5,d6\n====================================\nXCC: 4.00 (TEI3A4L 2020-07-13T23:58:08)\n\n====================================\nd3\n====================================\nXCC: 4.00 (TEI3A3L 2020-07-10T06:43:45)\n</code></pre> <p>Using nodeconfig to view uefi settings and collate -d to find deviations:</p> <pre><code># nodeconfig d3-d6 processors | grep -v Processors.Processors13to16coresactive | collate -d\n====================================\nd3,d5,d6\n====================================\nProcessors.TurboMode: Enable\nProcessors.CPUPstateControl: Autonomous\nProcessors.CStates: Autonomous\nProcessors.C1EnhancedMode: Enable\nProcessors.HyperThreading: Enable\nProcessors.TrustedExecutionTechnology: Disable\nProcessors.IntelVirtualizationTechnology: Enable\nProcessors.HardwarePrefetcher: Enable\nProcessors.AdjacentCachePrefetch: Enable\nProcessors.DCUStreamerPrefetcher: Enable\nProcessors.DCUIPPrefetcher: Enable\nProcessors.DCA: Enable\nProcessors.EnergyEfficientTurbo: Enable\nProcessors.UncoreFrequencyScaling: Enable\nProcessors.MONITORMWAIT: Enable\nProcessors.SnoopResponseHoldOff: 9\nProcessors.UPIGateDisable: Enable\nProcessors.UPILinkDisable: Enable All Links\nProcessors.SNC: Disable\nProcessors.SnoopPreference: Home Snoop Plus\nProcessors.UPIPrefetcher: Enable\nProcessors.Autocstatemapping: Legacy\nProcessors.StaleAtoS: Auto\nProcessors.LLCdeadlinealloc: Enable\nProcessors.AesEnable: Enable\nProcessors.IrqThreshold: Auto\nProcessors.LLCPrefetch: Disable\nProcessors.PackageCstate: Enable\nProcessors.L2RFOPrefetchDisable: Auto\nProcessors.PECIIsTrusted: Enable\nProcessors.UncoreFrequencyLimit: 3F\nProcessors.PL2: 1.2\nProcessors.CoresinCPUPackage: All\nProcessors.MaxPState: P0\nProcessors.DisableProcessor: None\nProcessors.UPILinkFrequency: Max Performance\nProcessors.CPUFrequencyLimits: Full turbo uplift\nProcessors.CRCMode: Auto\nProcessors.L1: Enable\nProcessors.L0p: Enable\nProcessors.Processors1to2coresactive:\nProcessors.Processors3to4coresactive:\nProcessors.Processors5to8coresactive:\nProcessors.Processors9to12coresactive:\n\n====================================\nd4\n====================================\n@@\n  Processors.TurboMode: Enable\n- Processors.CPUPstateControl: Autonomous\n+ Processors.CPUPstateControl: Cooperative\n  Processors.CStates: Autonomous\n  Processors.C1EnhancedMode: Enable\n</code></pre> <p>Using nodeconfig to change the configuration:</p> <pre><code># nodeconfig d4 set Processors.CPUPstateControl=auto\n</code></pre>"},{"location":"miscellaneous/osdeploysecurity/","title":"SSH host and user authentication","text":"<p>In confluent, hosts are given SSH certificates when required to vouch for their identity. /etc/ssh/shosts.equiv and /etc/ssh/ssh_known_hosts are configured to facilitate node to node ssh without working about known_hosts and to enable host based authentication of users. This facility may be customized by setting <code>ssh.trustnodes</code> to limit the generated hosts.equiv file to a subset of hosts.  For example, if wanting to limit members of the group <code>storage</code> to only trust fellow members of <code>storage</code>, then set <code>ssh.trustnnodes</code> to <code>storage</code>. Conversely if a compute node has <code>ssh.trustnodes</code> set to <code>compute,storage</code>, then nodes would trust either group, allowing <code>storage</code> to ssh to <code>compute</code>, but not the other way around.</p> <p>As a result of node to node authentication being enabled from host based authentication, it is frequently possible to forgo managing user ssh keys within a confluent install (e.g. skipping setting up ~/.ssh/authorized_keys and ~/.ssh/id_* files).</p> <p>One exception to this is that root and syncfiles/ansible ssh user keys are added to the local root user to provide management and automation regardless of host based authentication state.</p>"},{"location":"miscellaneous/osdeploysecurity/#syncfiles-facility","title":"syncfiles facility","text":"<p>The syncfiles facility allows content from deployment server to be copied to a target node in flexible ways. The source content may be located anywhere on the deployment server, but must be accessible by the <code>confluent</code> user, as <code>confluent</code> does not run as <code>root</code>.  It may be convenient to use <code>sudo -u confluent bash</code> to examine files for access if you receive errors about inaccessible files. This may be used to convey more sensitive data by allowing confluent, but not other users to read the information</p>"},{"location":"miscellaneous/osdeploysecurity/#content-in-varlibconfluentprivate","title":"Content in /var/lib/confluent/private/","text":"<p>The confluent api offers material in /var/lib/confluent/private to nodes that authenticate using their node api key. For example, confluent uses this facility to provide the encryption key for encrypted diskless images and disk cloning. Custom scripts may use this facility. For example, if wanting to provide some sort of /etc/shadow entry for an account using the private facility: - Place hash of password in private file (substituting [os-profile] for the os profile that you specify in <code>nodedeploy</code>): `echo '$5$ssdUjvVexCw50Nvc$5uQMDLlikaiZKsTt4.8Xmlmr/O7qNXTrlBgnc20CQb7' &gt; /var/lib/confluent/private/os/[profilename]/pending/someaccount.passwd' - When in place, the client may access it either full time if diskless or prior to the conclusion of post by doing: <pre><code># python3 /opt/confluent/bin/apiclient /confluent-api/self/profileprivate/pending/someaccount.passwd &gt; /tmp/mylocalfile  \n# cat /tmp/mylocalfile  \n$5$ssdUjvVexCw50Nvc$5uQMDLlikaiZKsTt4.8Xmlmr/O7qNXTrlBgnc20CQb7  \n</code></pre></p>"},{"location":"miscellaneous/osdeploysecurity/#api-calls","title":"API calls","text":"<p>Confluent API calls provide information for deployment authenticated by the node API key.  For example in conjunction with custom node attributes, data can be stored and accessed in an authenticated fashion:</p> <pre><code>[root@mgt1 ~]# nodeattrib d11 custom.mysecret=area51\nd11: area51\n[root@mgt1 ~]# ssh d11\n[root@d11 ~]# python3 /opt/confluent/bin/apiclient /confluent-api/self/myattribs|grep custom.mysecret\ncustom.mysecret: area51\n</code></pre>"},{"location":"miscellaneous/osdeploysecurity/#content-in-varlibconfluentpublic-is-considered-public","title":"Content in /var/lib/confluent/public is considered public","text":"<p>Material is published without authentication from /var/lib/confluent/public, and thus sensitive information such as passwords or private keys should be avoided, and instead syncfiles, profile private area, or node attributes should be used. One borderline scenario is diskless and cloned images.  Confluent attempts to strip well known confidential information during capture or pack (e.g. shadow and private ssh keys), but custom OS content may contain unrecognized confidential material. To mitigate this issue without incurring logistical or performance penalty of the secure facilities, confluent defaults to encrypt these images and store the decryption keys in the profile private area on the filesystem.</p>"},{"location":"miscellaneous/raid-vroc-template/","title":"Template for RAID/VROC boot device","text":""},{"location":"miscellaneous/raid-vroc-template/#synopsis","title":"Synopsis","text":"<p>Add software RAID/md RAID for RHEL/Rocky Linux/Alma Linux, and VROC support for booting devices for RHEL/Rocky Linux/Alma Linux and SLES. </p>"},{"location":"miscellaneous/raid-vroc-template/#solution","title":"Solution","text":"<p>Confluent has a built-in feature to be able to load custom files in different parts of the booting process.</p> <p>After editing the sample file, place it in <code>/var/lib/confluent/public/os/&lt;&lt;profile name&gt;&gt;/scripts/pre.d</code>.</p> <p>For software RAID/md RAID instances please find below as a sample file may adapt for your needs:</p>"},{"location":"miscellaneous/raid-vroc-template/#example-file-for-software-raidmd-raid","title":"Example file for software RAID/md RAID","text":"<pre><code>DEVICES=\"/dev/sda /dev/sdb\"\nRAIDLEVEL=1\nmdadm --detail /dev/md*|grep 'Version : 1.0' &gt;&amp; /dev/null &amp;&amp; exit 0\nlvm vgchange -a n\nmdadm -S -s\nNUMDEVS=$(for dev in $DEVICES; do\n   echo wipefs -a $dev\ndone|wc -l)\nfor dev in $DEVICES; do\n   wipefs -a $dev\ndone\n# must use older metadata format to leave disks looking normal for uefi\nmdadm -C /dev/md/raid $DEVICES -n $NUMDEVS -e 1.0 -l $RAIDLEVEL\n# shut and restart array to prime things for anaconda\nmdadm -S -s\nmdadm --assemble --scan\nreadlink /dev/md/raid|sed -e 's/.*\\///' &gt; /tmp/installdisk\n</code></pre> <p>Reference  https://github.com/lenovo/confluent/blob/master/misc/swraid </p> <p>For VROC instances, please apply same principle as above (edit with needed info) :</p>"},{"location":"miscellaneous/raid-vroc-template/#example-file-for-vroc-raid","title":"Example file for VROC RAID:","text":"<pre><code>DEVICES=\"/dev/sda /dev/sdb\"\nRAIDLEVEL=1\nmdadm --detail /dev/md* | grep imsm &gt;&amp; /dev/null &amp;&amp; exit 0\nlvm vgchange -a n\nmdadm -S -s\nNUMDEVS=$(for dev in $DEVICES; do\n   echo wipefs -a $dev\ndone|wc -l)\nfor dev in $DEVICES; do\n   wipefs -a $dev\ndone\nmdadm -C /dev/md/imsm0 $DEVICES -n $NUMDEVS -e imsm\nmdadm -C /dev/md/md0_0 /dev/md/imsm0 -n $NUMDEVS -l $RAIDLEVEL\nmdadm -S -s\nmdadm --assemble --scan\n</code></pre> <p>Reference https://github.com/lenovo/confluent/blob/master/misc/vroc </p> <p>Please remember to put the file for the corresponding system in **/var/lib/confluent/public/os/&lt;&gt;/scripts/pre.d ** to run the script on the install of the profile."},{"location":"miscellaneous/rhinstallib/","title":"Installing EL7 over InfiniBand","text":"<p>This covers the process of EL7 deployment on a cluster using only InfiniBand.</p>"},{"location":"miscellaneous/rhinstallib/#preparing-for-infiniband-install","title":"Preparing for InfiniBand install","text":"<p>It is recommended to make groups to describe the required changes.  For example, this document will assume an 'ib' group.</p>"},{"location":"miscellaneous/rhinstallib/#setting-static-address-mode","title":"Setting static address mode","text":"<p>InfiniBand deployment is only supported in static mode.  Use the following command to have xCAT do static addressing:</p> <p># chtab key=managedaddressmode site.value=static</p>"},{"location":"miscellaneous/rhinstallib/#net-config-fixup-postscript","title":"Net config fixup postscript","text":"<p>InfiniBand network configuration does not work as expected out of the box.  If not installing Mellanox OFED, the following is an example of a postscript that can be added to correct that behavior:</p> <pre><code># cat /install/postscripts/fixipoib\necho 'install mlx5_core /sbin/modprobe --ignore-install mlx5_core; /sbin/modprobe mlx5_ib; /sbin/modprobe ib_ipoib' &gt;&gt; /etc/modprobe.d/mlx.conf\necho 'add_drivers+=\"mlx5_ib ib_ipoib\"' &gt; /etc/dracut.conf.d/mlx.conf\ndracut -f\n</code></pre>"},{"location":"miscellaneous/rhinstallib/#xcat-configuration","title":"xCAT configuration","text":"<p>Define the ib group to have the required install argument changes, interface name, and to invoke the postscript shown above:</p> <pre><code># nodegrpch ib bootparams.addkcmdline=\"rd.driver.pre=mlx5_ib,ib_ipoib rd.net.timeout.carrier=80 rd.bootif=0\" noderes.primarynic=ib0 postscripts.postscripts=fixipoib\n</code></pre>"},{"location":"miscellaneous/rhinstallib/#confluent-configuration","title":"confluent configuration","text":"<p>xCAT does not understand how to collect addresses for InfiniBand.  Instead, enable confluent collection of the InfinBand addresses:</p> <pre><code># nodegroupdefine ib net.ib.bootable=1 discovery.policy=permissive,pxe\n</code></pre>"},{"location":"miscellaneous/rhinstallib/#gathering-infiniband-hardware-addresses-and-putting-into-xcat","title":"Gathering InfiniBand hardware addresses and putting into xCAT","text":"<p>When confluent is configured to do 'zero power' discovery, it can collect mac addresses for boot devices such as InfiniBand without having to describe the fabric topology.  This document assumes familiarity with Node discovery and autoconfiguration with confluent and that the management network discovery has been configured.</p> <p>Have the systems attempt to network boot over infiniBand.  For example:</p> <pre><code># nodeboot ib net\n</code></pre> <p>After the system attempts PXE boot, the discovery mechanism should provide attributes suitable for feeding to xCAT.  To examine addresses seen by confluent and collected into the confluent attributes, the following commands are available: <pre><code># nodediscover list -t pxe-client\n Node|      Model|   Serial|                                 UUID|       Mac Address|       Type| Current IP Addresses\n-----|-----------|---------|-------------------------------------|------------------|-----------|---------------------\n  ib1| 7X2104Z000| DVJJ1022| 58962b3d-088b-11e7-b8b8-9e59e5cf61db| 50:6b:4b:09:2a:5c| pxe-client|                     \n</code></pre></p> <pre><code># nodeattrib ib net.ib.hwaddr\nib1: net.ib.hwaddr: 50:6b:4b:09:2a:5c\n</code></pre> <p>To actually populate xCAT, you can use the confluent2xcat command.  If you have not defined nodes in xCAT at all:</p> <pre><code># confluent2xcat ib -o xcatnodes.def\n# mkdef -z &lt; xcatnodes.def\n1 object definitions have been created or modified.\n</code></pre> <p>Alternatively, if you have xCAT nodes already defined, but only want to augment the xCAT definition with the mac data:</p> <pre><code># confluent2xcat ib -m mac.csv\n# tabrestore -a mac.csv\n</code></pre> <p>Also, it is possible to use nodeinventory to collect the hardware addresses of the InfiniBand adapters.  Note that Mellanox removes the middle two bytes (03:00) of their address during netboot, so remove it here:</p> <pre><code># nodeinventory d3 mac |grep Mellanox|sed -e s/50:6b:4b:03:00/50:6b:4b/\nd3: Mellanox ConnectX-5 2x100GbE / EDR IB QSFP28 VPI Adapter MAC Address 1: 50:6b:4b:09:2a:ac\nd3: Mellanox ConnectX-5 2x100GbE / EDR IB QSFP28 VPI Adapter MAC Address 2: 50:6b:4b:09:2a:ad\n</code></pre>"},{"location":"miscellaneous/rhinstallib/#performing-the-install","title":"Performing the install","text":"<p>At this point, install can proceed as any normal install:</p> <pre><code># nodeset ib1 osimage=centos7.4-x86_64-install-compute\n# nodeboot ib1 net\n</code></pre>"},{"location":"miscellaneous/rhinstallib/#accessing-without-fabric","title":"Accessing without fabric","text":"<p>If an issue occurs where the server is up, but the fabric is unreachable and login or scp is required, a backup path is available through the XCC:</p> <pre><code># ssh -p 3389 $(noderun -n ib1 echo {bmc})\nLast login: Wed Apr 10 14:23:19 2019 from gateway\n[root@ib1 ~]#\n</code></pre> <p>All ssh capabilities are available, including scp:</p> <pre><code># scp -P 3389 testfile $(noderun -n ib1 echo [{bmc}]):~\ntestfile                       75%   48MB   2.6MB/s   00:06 ETA\n</code></pre> <p>As well as rsync:</p> <pre><code># rsync -ave 'ssh -p 3389' testfile $(noderun -n ib1 echo [{bmc}]):/\nsending incremental file list\ntestfile\n\nsent 67,125,334 bytes  received 35 bytes  2,355,276.11 bytes/sec\ntotal size is 67,108,864  speedup is 1.00\n</code></pre>"},{"location":"miscellaneous/rhinstallopa/","title":"Installing EL7 over OmniPath","text":"<p>It is possible with the Lenovo xCAT and confluent software to install EL7 over Omnipath.</p>"},{"location":"miscellaneous/rhinstallopa/#preparing-for-opa-install","title":"Preparing for OPA install","text":"<p>It is recommended to make groups to describe the required changes.  For example, this document will assume an 'opa' group.</p>"},{"location":"miscellaneous/rhinstallopa/#net-config-fixup-postscript","title":"Net config fixup postscript","text":"<p>OPA network configuration does not work as expected out of the box.  Here is a postscript to fix:</p> <pre><code># cat /install/postscripts/opaboot \n#!/bin/sh\necho 'install hfi1 /sbin/modprobe --ignore-install hfi1; sleep 10; /sbin/modprobe ib_ipoib' &gt; /etc/modprobe.d/hfi.conf\necho 'ACTION==\"add\", SUBSYSTEM==\"net\", ATTR{type}==\"32\", RUN+=\"/sbin/ifup %E{INTERFACE}\"' &gt; /etc/udev/rules.d/60-ib.rules\n</code></pre>"},{"location":"miscellaneous/rhinstallopa/#xcat-configuration","title":"xCAT configuration","text":"<p>Define the opa group to have the required install argument changes, interface name, and to invoke the postscript shown above:</p> <pre><code># nodegrpch opa bootparams.addkcmdline=\"rd.driver.pre=ib_ipoib rd.net.timeout.carrier=80 rd.bootif=0\" noderes.primarynic=ib0 postscripts.postscripts=opaboot\n</code></pre>"},{"location":"miscellaneous/rhinstallopa/#confluent-configuration","title":"confluent configuration","text":"<p>xCAT does not understand how to collect addresses for omnipath.  Enable confluent collection of the omnipath mac addresses:</p> <pre><code># nodegroupdefine opa net.opa.bootable=1 discovery.policy=permissive,pxe\n</code></pre>"},{"location":"miscellaneous/rhinstallopa/#gathering-opa-hardware-addresses-and-putting-into-xcat","title":"Gathering OPA hardware addresses and putting into xCAT","text":"<p>When confluent is configured to do 'zero power' discovery, it can collect mac addresses for boot devices such as OmniPath without having to describe the fabric topology.  This document assumes familiarity with Node discovery and autoconfiguration with confluent and that the management network discovery has been configured..</p> <p>Have the systems attempt to network boot over OPA.  For example:</p> <pre><code># nodeboot opa net\n</code></pre> <p>After the system attempts PXE boot, the discovery mechanism should provide attributes suitable for feeding to xCAT.  The following commands can help show this:</p> <pre><code># nodediscover list -t pxe-client -f node,serial,mac\n Node|   Serial|                     Mac\n-----|---------|------------------------\n opa1| J1001PNE| 00:11:75:01:01:0d:cd:c7\n opa1| J1001PNE|       08:94:ef:50:23:60\n\n\n# nodeattrib opa1 net.opa.hwaddr\nopa1: net.opa.hwaddr: 00:11:75:01:01:0d:cd:c7\n</code></pre> <p>To actually populate xCAT, the confluent2xcat command may be used.  If the node is not yet defined to xCAT at all: <pre><code>[root@mgt ~]# confluent2xcat opa1 -o opa.stanza\n[root@mgt ~]# mkdef -z &lt; opa.stanza \n1 object definitions have been created or modified.\n</code></pre></p> <p>Or to add the mac address to existing node, the mac.csv may be useful: <pre><code>[root@mgt ~]# confluent2xcat opa -m mac.csv\n[root@mgt ~]# tabrestore -a mac.csv \n</code></pre></p>"},{"location":"miscellaneous/rhinstallopa/#performing-the-install","title":"Performing the install","text":"<p>At this point, install can proceed as any normal install:</p> <pre><code># nodeset opa1 osimage=centos7.4-x86_64-install-compute\n# nodeboot opa1 net\n</code></pre>"},{"location":"miscellaneous/rhinstallopa/#accessing-without-fabric","title":"Accessing without fabric","text":"<p>If an issue occurs where the server is up, but the fabric is unreachable and login or scp is required, a backup path is available through the XCC:</p> <pre><code># ssh -p 3389 $(noderun -n opa1 echo {bmc})\nLast login: Wed Apr 16 13:09:47 2017 from 192.168.1.1\n[root@opa1 ~]#\n</code></pre> <p>All ssh capabilities are available, including scp:</p> <pre><code># scp -P 3389 testfile $(noderun -n opa1 echo [{bmc}]):~\ntestfile                                        100%   16MB   2.7MB/s   00:06\n</code></pre> <p>As well as rsync:</p> <pre><code># rsync -ave 'ssh -p 3389' testfile $(noderun -n opa1 echo [{bmc}]):/\n</code></pre>"},{"location":"miscellaneous/routeddeployment/","title":"Deployment through a routed network","text":"<p>While it is most straightforward to do OS deployment when on the same network, sometimes there is a need to deploy through a routed network.  Note that regardless of the strategy, the routed network will incur more manual configuration and have more chances for a failure to occur, so it is strongly advised, if at all possible, to have confluent on the local network, or use the confluent collective mechanism to have confluent instances on the same network to have the highest chance of success with the least network.</p> <p>That said, there are a number of strategies to perform deployment through a router:</p>"},{"location":"miscellaneous/routeddeployment/#remote-media-boot","title":"Remote media boot","text":"<p>You can use the remote media to boot a confluent image, in conjunction with an 'identity' image.</p> <p>Benefits of this approach: - Requires no particular coordination with the network administration responsibilities - More hardened mechanism for authenticating the node during the OS deployment.</p> <p>Drawbacks: - Additional license keys may be required or the node BMC may not support at all - It may be slower to boot compared to traditional network boot - The network configuration may not be as robust as a network deployment, causing longer network configuration times or failure</p> <p>To proceed:</p> <ul> <li>Generate an identity image for the node.</li> </ul> <pre><code># confetty set /noderange/rackmount/deployment/ident_image=create\ncreated: nodes/r3u21/deployment/ident_image\ncreated: nodes/r3u24/deployment/ident_image\ncreated: nodes/r3u22/deployment/ident_image\ncreated: nodes/r3u23/deployment/ident_image\ncreated: nodes/r3u25/deployment/ident_image\n</code></pre> <ul> <li>Upload the identity images to the xClarity controllers:</li> </ul> <p><pre><code>noderun rackmount nodemedia {node} upload /var/lib/confluent/private/identity_images/{node}.img\n</code></pre> Be aware that use of <code>nodemedia attach</code> is likely to insecurely expose the contents of the image file, which contains an API token that can be used to get SSH certificates, so it is advised to only use <code>upload</code>.</p> <ul> <li>Attach or upload the <code>boot.img</code> file from the profile.</li> </ul> <p><pre><code># nodemedia rackmount attach https://172.30.193.20/confluent-public/os/rocky-9.4-x86_64-default/boot.img\n</code></pre> Note that attach is frequently needed, as boot.img is often larger than the space allowed by the xClarity Controller for upload. However, the boot.img should contain no particularly confidential information.</p>"},{"location":"miscellaneous/routeddeployment/#url-driven-remote-boot-using-ipxe","title":"URL driven remote boot using iPXE","text":"<p>This approach has the local DHCP server handle chainloading iPXE and sending a URL parameter only to iPXE.</p> <p>Benefits: - Provides maximum flexibility for the DHCP configuration to own more of the boot process</p> <p>Drawbacks: - Requires the most DHCP configuration to be sorted out in the DHCP configuration - It does not support direct UEFI HTTP boot, and thus currently is incompatible with confluent SecureBoot support - Requires the administrator to modiy an OS image profile to indicate the location of the confluent server - Requires the administrator to designate remote network as \"trusted\"</p> <p>To proceed:</p> <ul> <li>Ensure you have collected either node UUIDs (id.uuid) or mac addresses (net.*hwaddr), depending on your preference.</li> <li>Set the remote network to be a trusted network for the node: <code>nodeattrib [nodes] trusted.subnets=172.20.0.0/24</code></li> <li>Modify the profile.yaml of the OS profile(s) and add <code>confluent=[ip.of.confluent.server]</code> to the kernel arguments</li> <li>osdeploy updateboot [osimagename]</li> <li>Have the local DHCP configuration ultimately tell iPXE to boot <code>http://[ip.of.confluent.server]/confluent-api/boot/by-uuid/${uuid}/ipxe</code> or <code>http://[ip.of.confluent.server]/confluent-api/boot/by-mac/${mac:hexhyp}/ipxe</code>, depending on whether you collected UUID or mac addresses previously</li> </ul>"},{"location":"miscellaneous/routeddeployment/#dhcp-delegation-of-pxe","title":"DHCP delegation of PXE","text":"<p>This approach has the local DHCP server only handling addressing, and pointing the booting system towards confluent for further instructions</p> <p>Benefits: - Requires relatively light DHCP configuration</p> <p>Drawbacks: - Still requires some DHCP configuration - Requires the administrator to modiy an OS image profile to indicate the location of the confluent server - It only supports PXE boot, and thus currently is incompatible with confluent SecureBoot support - Requires the administrator to designate remote network as \"trusted\"</p> <p>To proceed:</p> <ul> <li>Ensure you have collected either node UUIDs (id.uuid) or mac addresses (net.*hwaddr), depending on your preference.</li> <li>Set the remote network to be a trusted network for the node: <code>nodeattrib [nodes] trusted.subnets=172.20.0.0/24</code></li> <li>Modify the profile.yaml of the OS profile(s) and add <code>confluent=[ip.of.confluent.server]</code> to the kernel arguments</li> <li>osdeploy updateboot [osimagename]</li> <li>Have the DHCP server send option 67 \"PXEClient\".  As an example, here is an exceprt from an ISC DHCP configuration file </li> </ul> <pre><code>     class \"PXE\" {\n       match if substring(option vendor-class-identifier, 0, 9) =\"PXEClient\"; \n       option vendor-class-identifier \"PXEClient\"; \n       vendor-option-space PXE; \n       next-server 172.26.129.213;\n       filename = \"\";\n    }\n</code></pre>"},{"location":"miscellaneous/samplepostscripts/","title":"Osdeployment sample postscripts and their usage","text":"<p>Listed here are some sample post scripts that you might choose to use when deploying  confluent surported operating systems. These scripts are located in the initialized  profiles scripts directory, <code>/var/lib/confluent/public/os/&lt;profile&gt;/scripts/sample</code>.</p> <ol> <li> <p>Post script to comment out the terminal and serial lines in the grub.conf after install on el9 or suse15</p> <ul> <li>location <code>/var/lib/confluent/public/os/&lt;profile&gt;/scripts/sample/consoleredirect</code></li> <li> <p>When serial console redirect is enabled after POST in the UEFI settings and in grub this might result in double text  appearing in console. Commenting out the terminal and serial lines in the grub.cfg file will fix this. This script works for either SuSE or RHEL deployments.  </p> </li> <li> <p>Execution: To run the script on an installed system and ensure the changes are in effect from the onset you should add the <code>consoleredirect</code> script to the <code>firstboot.d</code> directory. </p> </li> </ul> </li> </ol>"},{"location":"miscellaneous/sd650sharednote/","title":"Configured for shared port in SD650 in xCAT","text":"<p>The SD650 water cooled system requires the following value for the <code>ipmi.bmcport</code> field of the node to induce bmcsetup to correctly move the XCC to the shared port.</p> <p>The value can be set by the following command, if your SD650 are in a group called <code>dwc</code>:</p> <pre><code>nodegrpch dwc ipmi.bmcport=`0 2'\n</code></pre>"},{"location":"miscellaneous/sles12deploy/","title":"OS Deployment Notes for SLES 12.3","text":"<p>After performing copycds on disk 2 of the SLES 12 media, SUSE may experience problems interacting with the install source, such as:                                                             </p> <pre><code>File '/media.2/media' not found on medium                       \n'http://10.16.0.10:80/install/sles12.3/x86_64/1'                \n\nAbort, retry, ignore? [a/r/i/...? shows all options] (a):\n</code></pre> <p>The media can be fixed up as follows:                           </p> <pre><code>cd /&lt;xCAT installdir&gt;/sles12.3/x86_64/1                                   \nln -s ../2/media.2 .                                            \nmkdir -p suse/src/                                              \ncd suse/src                                                     \nfor src in ../../../2/suse/src/*rpm; do                         \n    ln -s $src .                                                \ndone                                                            \n\ncd ../../../2/                                                  \nln -s ../1/media.1 .\n</code></pre>"},{"location":"miscellaneous/sshdesign/","title":"SSH authentication architecture as configured by confluent","text":"<p>In confluent, some more advanced SSH features are leveraged to tighten secure use of passwordless SSH and known_hosts.  Generally speaking, the details are handled and the operator need not worry about the details.  This document is provided to help show the details for those who need to know the mechanisms at work and how they are manipulated.</p>"},{"location":"miscellaneous/sshdesign/#ssh-certificate-authority","title":"SSH certificate authority","text":"<p>SSH supports the concept of a certificate authority, allowing one SSH key to vouch for another.  In confluent, <code>osdeploy initialize -s</code> requests initialization of such an authority on the local management server.  The private key of that authority is stored as /etc/confluent/ssh/ca and the public key is in /etc/confluent/ssh/ca.pub.  Additionally, the public key is copied to /var/lib/confluent/public/site/ssh/{name}.ca for inclusion for nodes to trust.  Note that in a confluent collective, each collective member will generate their own.  When doing a deployment, the deployed node will have a certificate signed by whatever collective member deployed it.  Notably, when a node that will one day be a collective member is installed, it will be signed by the system that provided deployment, not itself.</p>"},{"location":"miscellaneous/sshdesign/#certificate-authority-and-role-in-host-key-trust","title":"Certificate authority and role in host key trust","text":"<p>In traditional ssh usage, each time the user connects to a new host, they are prompted and that specific key is added to ~/.ssh/known_hosts.  This may also be done in /etc/ssh/ssh_known_hosts, to provide that repository system-wide. A certificate authority being added to /etc/ssh/ssh_known_hosts extends it's trust over any matching host that has been vouched for by that authority. Here is an example where a 4 collective members get added, and the authorities are configured to be allowed to vouch for any name or ip address at all:</p> <pre><code># cat /etc/ssh/ssh_known_hosts\n@cert-authority * ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIGysD2cqWwwkVFvPePgtGkRKrgmFPdjKbXyN1oFFGMlm d5 SSH CA\n@cert-authority * ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIGnF5/iTUmAGY7WZ80rY/Ko1D77HIoa32G1NjBMXozO4 d6 SSH CA\n@cert-authority * ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIBLCdA9ONJjk/ai2XZJqHDF+lN9Nvs4TMnz8h2HYbmSE d7 SSH CA\n@cert-authority * ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAICqOJB/ksETgYDj7bRLRO0ZCOZ1UVsBdIBRx23Fs5XCb d8 SSH CA\n</code></pre> <p>The <code>*</code> wildcard refers to the names the authority is allowed to issue certificates for and be trusted.  By default, confluent instructs the nodes to trust the confluent authorities to generate any name. This effectively replaces the requirement to use ~/.ssh/known_hosts for users within a site, as the global known hosts file covers all the host keys that have or will be generated.  Note that <code>/var/lib/confluent/public/site/ssh/*.ca</code> will be incorporated, whether confluent or other software or manual placement has created the files. This permits custom SSH certificate authorities to be added without confluent being aware of the operational details.</p>"},{"location":"miscellaneous/sshdesign/#host-key-certificate","title":"Host key certificate","text":"<p>During deployment, a node is granted a certificate, and the certificates are stored along the key files in <code>/etc/ssh/ssh_host_*_key-cert.pub</code>.  HostCertificate entries are also added to /etc/ssh/sshd_config, for example: <pre><code>HostCertificate /etc/ssh/ssh_host_ecdsa_key-cert.pub\nHostCertificate /etc/ssh/ssh_host_ed25519_key-cert.pub\nHostCertificate /etc/ssh/ssh_host_rsa_key-cert.pub\n</code></pre></p>"},{"location":"miscellaneous/sshdesign/#host-based-authentication","title":"Host based authentication","text":"<p>When doing ssh key based authentication, there are two general strategies.  The most popular method involves each user having a ~/.ssh/authorized_keys file enumerating the specific keys that are allowed to authenticate. Confluent focuses on enabling use of the host key.  The first step is for the host key to be recognized by way of known_hosts.  Per the above section, this is handled.  All that is left is enabling host based authentication and specifying which hosts are trusted to vouch for users that connect from them.</p>"},{"location":"miscellaneous/sshdesign/#sshd-configuration-changes-for-host-based-authentication","title":"sshd configuration changes for host based authentication","text":"<p>The following configuration changes are placed into sshd_config: <pre><code>HostbasedAuthentication yes\nHostbasedUsesNameFromPacketOnly yes \n</code></pre></p> <p>The latter permits the client to specify it's own name, rather than relying on reverse DNS.  This means that the client node will do the equivalent of <code>getent hosts &lt;ip of client nic&gt;</code> and that result will be the name seen by the server.</p>"},{"location":"miscellaneous/sshdesign/#ssh-client-configuration-changes-for-host-based-authentication","title":"ssh client configuration changes for host based authentication","text":"<p>This is an example configuration change made for ssh_config to dictate client behavior, enabling use of the host key to authenticate, and limiting ed25519 toward the end of minimizing key based authentication attempts in a system with many key types: <pre><code>Host *\n    HostbasedAuthentication yes\n    EnableSSHKeysign yes\n    HostbasedKeyTypes *ed25519*\n</code></pre></p>"},{"location":"miscellaneous/sshdesign/#specifying-permitted-peer-nodes","title":"Specifying permitted peer nodes","text":"<p>Confluent provides an attribute called <code>ssh.trustnodes</code> to designate which managed nodes are allowed to authenticate.  If unspecified, all nodes are assumed to be trusted.  The specified noderange will be expanded during deployment or, as of confluent 3.7.1, refresh of the ssh configuration using <code>run_remote setupssh</code>.  The expanded set will be placed into two files, <code>/etc/ssh/shosts.equiv</code> to enable users other than root, and <code>/root/.shosts</code> to enable node to node ssh as root.  The contents of those two files are the only things effected by this attribute.</p>"},{"location":"miscellaneous/sshdesign/#user-based-authentication-for-root","title":"User based authentication for root","text":"<p>In addition to the host based configuration specified above, the root user on target system is generally given two user keys for <code>/root/.ssh/authorized_keys</code> per collective member.  When using <code>osdeploy initialize -u</code>, a suitable ssh public key from <code>/root/.ssh/*.pub</code> will be copied to <code>/var/lib/confluent/public/ssh/site/{host}.rootpubkey</code>.  This key is not used by confluent, but this service is provided as a convenience for operators using root user on the management node.  Note that any other files matching <code>/var/lib/confluent/public/ssh/site/*.rootpubkey</code> will also be added, whether confluent added them or not, so other users may be added in this manner as desired.</p>"},{"location":"miscellaneous/sshdesign/#user-based-authentication-for-confluent","title":"User based authentication for confluent","text":"<p>confluent is not permitted to read ssh keys in <code>/root/.ssh</code>.  Therefore, running <code>osdeploy initialize -a</code> generates a separate user keypair in <code>/etc/confluent/ssh/</code>.  This key is used for tasks such as executing ansible plays, or  synchronizing files in the <code>syncfiles</code> of an OS profile.  The public portion is placed into <code>/var/lib/confluent/public/site/ssh/*.automationpubkey</code></p>"},{"location":"miscellaneous/tlsdesign/","title":"Challenges of using TLS in a private network","text":"<p>Using TLS in a private network configuration can be daunting. The usual approach requires that DNS be in order and resolving the way that is intended and imposes a requirement that the user explicitly tell the software correctly the name that will be used.  Further, when faced with multihomed systems, it adds more complexity, as the certificate must cover all possible names and the software must use the correct name at the correct time, depending on context.</p>"},{"location":"miscellaneous/tlsdesign/#confluent-tls-strategy","title":"Confluent TLS strategy","text":"<p>Due to the challenges with relying upon and configuration of DNS, Confluent steers towards use of IP addresses as it goes.  In typical confluent environments, the IP addresses of the management nodes are fixed, and easy to programatically detect the correct one without user guidance.  Thus <code>osdeploy initialize -t</code> focuses on enabling IP addresses, for example, here is a typical SAN field for a confluent generated certificate:</p> <pre><code>X509v3 Subject Alternative Name:\n    IP Address:172.30.1.5, IP Address:FDEC:46F7:9B7F:3001:0:0:2:5, IP Address:FE80:0:0:0:A94:EFFF:FE50:BEC2, DNS:172.30.1.5, DNS:fdec:46f7:9b7f:3001::2:5, DNS:fe80::a94:efff:fe50:bec2, DNS:d5\n</code></pre> <p>Note that every possible ip address is added, and added both properly as IP address fields, and as DNS fields, due to certain TLS clients incorrectly skipping IP address fields.</p>"},{"location":"miscellaneous/tlsdesign/#the-confluent-tls-authority","title":"The confluent TLS authority","text":"<p>To allow easily updating the certificate to accomodate IP address changes, confluent tends to make it's own certificate authority: <pre><code>/etc/confluent/tls/cakey.pem\n/etc/confluent/tls/cacert.pem\n</code></pre> The public certificate of the CA is placed into the site deployment directory, using the server hostname as the filename.  In the case of a collective where each collective member provides an authority, they should all be present: <pre><code># ls -l /var/lib/confluent/public/site/tls/\ntotal 6\nlrwxrwxrwx. 1 root root   6 Mar 16 09:17 0e6578bf.0 -&gt; d8.pem\nlrwxrwxrwx. 1 root root   6 May 31 15:34 36e70825.0 -&gt; d5.pem\nlrwxrwxrwx. 1 root root   6 Mar 16 09:17 61dc1437.0 -&gt; d6.pem\nlrwxrwxrwx. 1 root root   6 Mar 16 09:17 a8959d66.0 -&gt; d7.pem\n-rw-r--r--. 1 root root 656 Mar 23  2022 d5.pem\n-rw-r--r--. 1 root root 631 Mar 16 09:17 d6.pem\n-rw-r--r--. 1 root root 656 Mar 23  2022 d7.pem\n-rw-r--r--. 1 root root 656 Mar 23  2022 d8.pem\n</code></pre></p>"},{"location":"miscellaneous/tlsdesign/#using-a-custom-certificate-authority","title":"Using a custom certificate authority","text":"<p>Unfortunately, while this approach makes things easier for those that do not wish to manually sort out the details of DNS and TLS, it poses a challenge for those that wish to use a TLS certificate globally.  There are some options to proceed.</p> <ul> <li>Automatically adding a custom CA certificate to your deployment</li> </ul> <p>No matter the chosen approach, it is generally desirable to add your custom authority to the deployed systems. In addition to methods that you may be accustomed to being viable during post.d or onboot.d, you may also choose to add your organization's CA certificates to /var/lib/confluent/public/site/tls/.  While collective server certificates use the directory, any other .pem and .0 will be consumed as trusted CA certificates for deployment and beyond.  Note this will only add the authority as trusted, this is likely not to make things work, as the certificate will generally use DNS names, and the deployment will still use IP addresses.</p> <ul> <li>Use the custom CA alongside the confluent CA</li> </ul> <p>The recommended approach is to use certificates from both certificate authorities on a confluent server.  The organizational CA for those who access by the expected name, and the confluent one to facilitate access by IP address. In this approach, use the virtual host feature of the webserver to use different certificates in different contexts.  For example in apache, you would want a <code>&lt;VirtualHost your.name.org&gt;</code> section to indicate use of your organizational TLS certificate, leaving the <code>_default_</code> section to use the confluent authority.  This should enable SNI to select the correct certificate given the context allowing both use cases to proceed.</p> <ul> <li>Using the custom CA to issue a confluent friendly certificate.</li> </ul> <p>In addition to the names desired, you may wish to add the IP addresses as subject alternative names to the certificate.  If this is possible, then confluent should be able to proceed as nomal.  However, this may be onerous at best (having to redo the certificate process with your organization for an ip address change) or impossible at worst (a common policy is to forbid IP address based SAN entries).</p>"},{"location":"miscellaneous/xccdeployment/","title":"Deploying servers using the xClarity Controller","text":"<p>This procedure will leverage the Virtual USB function on appropriately licensed xClarity Controllers to aid in deployment, which is particularly useful when doing deployment over a routed network with minimal external configuration.</p>"},{"location":"miscellaneous/xccdeployment/#ensure-net-attributes-contain-the-networking-configuration","title":"Ensure net attributes contain the networking configuration","text":"<p>For static IP deployments, it is important that confluent be given the prefix length and the gateway.</p> <pre><code># nodeattrib d1 net.ipv4_address=192.168.16.35/24 net.ipv4_gateway=192.168.16.254\nd1: 192.168.16.35/24\nd1: 192.168.16.254\n</code></pre>"},{"location":"miscellaneous/xccdeployment/#set-the-desired-profile-to-be-pending","title":"Set the desired profile to be pending","text":"<pre><code># nodeattrib d1-d4 deployment.pendingprofile=rocky-8.7-x86_64-default\nd1: rocky-8.7-x86_64-default\nd2: rocky-8.7-x86_64-default\nd3: rocky-8.7-x86_64-default\nd4: rocky-8.7-x86_64-default\n</code></pre>"},{"location":"miscellaneous/xccdeployment/#create-an-identity-image","title":"Create an identity image","text":"<p>The identity image contains credentials, network configuration, and information about the deployment server.</p> <pre><code># confetty set /noderange/d1-d4/deployment/ident_image=create\ncreated: nodes/d2/deployment/ident_image\ncreated: nodes/d4/deployment/ident_image\ncreated: nodes/d3/deployment/ident_image\ncreated: nodes/d1/deployment/ident_image\n</code></pre>"},{"location":"miscellaneous/xccdeployment/#upload-the-identity-image-to-the-xclarity-controller","title":"Upload the identity image to the xClarity Controller","text":"<pre><code># noderun d1-d4 nodemedia {node} upload /var/lib/confluent/private/identity_images/{node}.img\nd1: d1: initializing:   0%\nd2: d2: initializing:   0%\nd4: d4: initializing:   0%\nd3: d3: initializing:   0%\nd1: d1: upload: 100%\nd2: d2: upload: 100%\nd4: d4: upload: 100%\nd3: d3: upload: 100%\nd4: d4: complete: 100%\nd3: d3: complete: 100%\nd1: d1: complete: 100%\nd2: d2: complete: 100%\nd4: d4: d4.img\nd3: d3: d3.img\nd2: d2: d2.img\nd1: d1: d1.img\n</code></pre>"},{"location":"miscellaneous/xccdeployment/#attach-the-boot-image-for-the-desired-profile","title":"Attach the boot image for the desired profile","text":"<pre><code># nodemedia d1-d4 attach http://172.30.1.5/confluent-public/os/rocky-8.7-x86_64-default/boot.img\nd1: http://172.30.1.5/confluent-public/os/rocky-8.7-x86_64-default/boot.img (insecure)\nd1: d1.img\nd2: http://172.30.1.5/confluent-public/os/rocky-8.7-x86_64-default/boot.img (insecure)\nd2: d2.img\nd3: http://172.30.1.5/confluent-public/os/rocky-8.7-x86_64-default/boot.img (insecure)\nd3: d3.img\nd4: http://172.30.1.5/confluent-public/os/rocky-8.7-x86_64-default/boot.img (insecure)\nd4: d4.img\n</code></pre>"},{"location":"miscellaneous/xccdeployment/#boot-nodes-to-usb-to-commence-deployment","title":"Boot nodes to usb to commence deployment","text":"<pre><code># nodeboot d1-d usb\nd1: usb\nd1: reset\nd2: usb\nd2: reset\nd3: usb\nd3: reset\nd4: usb\nd4: reset\n</code></pre>"},{"location":"miscellaneous/xccdeployment/#deployment-should-proceed-to-completion","title":"Deployment should proceed to completion","text":"<p>From this point forward, deployment should proceed automatically, similar to how it would progress with a network based deployment.</p>"},{"location":"release_notes/","title":"Release notes","text":""},{"location":"release_notes/2017/12/04/recent-confluent-features/","title":"Recent Confluent Features","text":"<p>Confluent has a new discovery mechanism.  This allows for zero-power xCAT style discovery and configuration of lenovo systems.</p> <p>New to 1.7.2 is the <code>nodediscover</code> command: <pre><code>mn10:~ # nodediscover list\n           Node|          Model|         Serial|                                UUID|      Mac Address|        Type|                            Current IP Addresses\n---------------|---------------|---------------|------------------------------------|-----------------|------------|------------------------------------------------\n               |               |               |                                    |08:94:ef:3b:de:d4|  lenovo-smm|               fe80::a94:efff:fe3b:ded4%eth0.103\n           n972|     7X12ABC1WW|       00000972|5d09c001-0015-11e7-ac42-f0b2116de94f|08:94:ef:40:77:91|  lenovo-xcc|                                    10.19.67.204\n           n974|     7X12ABC1WW|       00000974|839ab980-ff3d-11e6-9998-c3776b1f3327|08:94:ef:40:78:81|  lenovo-xcc|                                    10.19.67.206\n           n973|     7X12ABC1WW|       00000973|5b767e21-0224-11e7-b141-e0d42e02a772|08:94:ef:40:79:35|  lenovo-xcc|                                    10.19.67.205\n               |     7X12ABC1WW|       00000971|aee7ccee-00cd-11e7-ab9a-f6503ce8c5f9|08:94:ef:40:79:91|  lenovo-xcc|                                    10.19.67.203\n           n881|     7X2106Z000|       00000881|4f2b8ff7-0329-11e7-8af9-e9166c58475d|08:94:ef:40:86:a8|  lenovo-xcc|                                    10.19.67.113\n           n875|     7X2106Z000|       00000875|d0c8c6d8-0260-11e7-9f49-c74a3f22502e|08:94:ef:40:86:b9|  lenovo-xcc|                                    10.19.67.107\n           n879|     7X2106Z000|       00000879|418420a7-0264-11e7-9abe-9abc80ea0f53|08:94:ef:40:86:dd|  lenovo-xcc|                                    10.19.67.111\n           n878|     7X2104Z000|       00000878|6ac9fdd8-0277-11e7-a5d0-f6d9cd5bccb1|08:94:ef:40:87:11|  lenovo-xcc|                                    10.19.67.110\n           n887|     7X2104Z000|       00000872|9746b41f-114d-11e7-b026-efba1952ac2a|08:94:ef:40:87:2d|  lenovo-xcc|  10.19.67.104,fe80::a94:efff:fe40:872d%eth0.103\n           n880|     7X2106Z000|       00000880|aa512271-02d5-11e7-87cb-f0f5d95c9267|08:94:ef:40:88:50|  lenovo-xcc|                                    10.20.67.112\n           n873|     7X2104Z000|       00000873|63b2ab2c-031e-11e7-aefe-d8531125e361|08:94:ef:40:88:89|  lenovo-xcc|  10.19.67.105,fe80::a94:efff:fe40:8889%eth0.103\n          n1050|     7X2106Z000|       DG17000A|89c6f82e-032b-11e7-ac1f-8377fd1aa62c|08:94:ef:40:89:09|  lenovo-xcc|               fe80::a94:efff:fe40:8909%eth0.103\n           n882|     7X2104Z000|       00000882|6b09d40e-0304-11e7-af7e-f3663703a759|08:94:ef:40:89:5d|  lenovo-xcc|                                    10.19.67.114\n           n876|     7X2104Z000|       00000876|828a0a32-0358-11e7-a2c7-c0c2c8ac60e5|08:94:ef:40:89:e9|  lenovo-xcc|                                    10.19.67.108\n          n1051|     7X2106Z000|       DG17000B|9ec10203-0261-11e7-aad9-9c80ee2c78c9|08:94:ef:40:8a:39|  lenovo-xcc|               fe80::a94:efff:fe40:8a39%eth0.103\n           n874|     7X2106Z000|       00000874|d43a6361-033e-11e7-8d7b-d8e30aa8bc5a|08:94:ef:40:8a:49|  lenovo-xcc|                                    10.19.67.106\n</code></pre></p> <p>The nodediscover command can also perform manual discovery, including import from .csv to assign IP addresses:</p> <pre><code>Usage: nodediscover [list|assign|rescan] [options]\n\nOptions:\n  -h, --help            show this help message and exit\n  -m MODEL, --model=MODEL\n                        Operate with nodes matching the specified model number\n  -s SERIAL, --serial=SERIAL\n                        Operate against the system matching the specified\n                        serial number\n  -u UUID, --uuid=UUID  Operate against the system matching the specified UUID\n  -n NODE, --node=NODE  Operate with the given nodename\n  -e MAC, --ethaddr=MAC\n                        Operate against the system with the specified MAC\n                        address\n  -t TYPE, --type=TYPE  Operate against the system of the specified type\n  -c, --csv             Use CSV formatted output\n  -i IMPORT.CSV, --import=IMPORT.CSV\n                        Import bulk assignment data from given CSV file\n</code></pre> <p>It is now possible to explore the full mac address and LLDP data of ethernet switches, whether they are related to nodes or not::</p> <pre><code>/ -&gt; show /networking/macs/by-mac/7c-d3-0a-ce-39-0d\nmac: 7c:d3:0a:ce:39:0d\npossiblenode=\"\"\nports=[\n {\n  \"switch\": \"172.16.2.6\", \n  \"macsonport\": 374, \n  \"port\": \"Port-Channel65\"\n }, \n {\n  \"switch\": \"172.16.2.51\", \n  \"macsonport\": 367, \n  \"port\": \"Port-Channel53\"\n }, \n {\n  \"switch\": \"172.16.2.10\", \n  \"macsonport\": 1, \n  \"port\": \"Ethernet37\"\n }\n]\n\n\n/ -&gt; show /networking/neighbors/by-peername/n748/by-peerid/40-f2-e9-c7-82-6e.40-f2-e9-c7-82-6e\nchassisid: a8:97:dc:ed:50:00\npeerchassisid: 40:f2:e9:c7:82:6e\npeerdescription: \npeerid: 40-f2-e9-c7-82-6e.40-f2-e9-c7-82-6e\npeername: n748\npeerportid: 40-f2-e9-c7-82-6e\nport: 22\nportid: 22\nswitch: 172.16.2.51\nverified: False\n</code></pre> <p>Confluent now reports energy meters on Lenovo System X and ThinkSystem servers:</p> <pre><code>[root@odin ~]# nodesensors s1 energy\ns1: DC Energy: 10.28510 kWh\n</code></pre> <p>Confluent can now update firmware of Lenovo XCC managed systems and SMM:</p> <pre><code># nodefirmware dense update lnvgy_fw_uefi_tee119n-1.20_anyos_32-64.uxz \ns1:upload:  67%       s2:upload:  70%       s3:upload:  59%       s4:upload:  63%       \ns1:pending: 100%      s2:pending: 100%      s3:apply:  35%        s4:apply:  59%\n</code></pre> <p>Confluent now has a command called <code>collate</code>, to help analyze similar results.  It  can also highlight differences to the most common output:</p> <pre><code># pasu dense show Processors|collate -d\n====================================\ns1,s2,s4\n====================================\nProcessors.TurboMode=Enable\nProcessors.CPUPstateControl=Cooperative\nProcessors.CStates=Disable\nProcessors.C1EnhancedMode=Enable\nProcessors.HyperThreading=Enable\nProcessors.ExecuteDisableBit=Enable\nProcessors.TrustedExecutionTechnology=Disable\nProcessors.IntelVirtualizationTechnology=Enable\nProcessors.HardwarePrefetcher=Enable\nProcessors.AdjacentCachePrefetch=Enable\nProcessors.DCUStreamerPrefetcher=Enable\nProcessors.DCUIPPrefetcher=Enable\nProcessors.DCA=Disable\nProcessors.EnergyEfficientTurbo=Enable\nProcessors.UncoreFrequencyScaling=Enable\nProcessors.UPILinkDisable=Enable All Links\nProcessors.SnoopPreference=HS w. Directory + OSB +HitME cache\nProcessors.PerCorePstate=Enable\nProcessors.UPIPrefetcher=Enable\nProcessors.CoresinCPUPackage=All\nProcessors.UPILinkFrequency=Max Performance\nProcessors.CPUFrequencyLimits=Full turbo uplift\nProcessors.L1=Enable\nProcessors.L0p=Enable\n\n====================================\ns3\n====================================\n@@\n  Processors.TurboMode=Enable\n- Processors.CPUPstateControl=Cooperative\n+ Processors.CPUPstateControl=Autonomous\n- Processors.CStates=Disable\n+ Processors.CStates=Legacy\n  Processors.C1EnhancedMode=Enable\n  Processors.HyperThreading=Enable\n</code></pre>"},{"location":"release_notes/2017/12/04/recent-confluent-features/#web-ui","title":"Web UI","text":"<p>The Web UI will now allow you to open the web interface of the node management controllers, even if you have no proxy or route to them:</p> <p> </p> <p>There is a new 'Fit to Screen' function for the terminals:</p> <p> </p> <p>If one of the small windows appears to have useful information that is illegible, you can now double click the titlebar to toggle zoom in/out of the given terminal:</p> <p></p> <p>Also, keyboard focus to terminals is now more clearly indicated by a green bar, and this works as seen above in the zoomed screenshot, as well as with 'Type in all Terminals':</p> <p></p> <p>It is now possible to add nodes to confluent via the GUI, under Configuration/Add Node.</p>"},{"location":"release_notes/2018/11/14/210-confluent-release/","title":"2.1.0 Confluent release","text":"<p>There is an update to the HPC software stack, bringing xCAT to 2.14.3.lenovo3, based on 2.14.3, and confluent is brought to 2.1.0.</p> <p>Here are some of the highlighted changes:</p>"},{"location":"release_notes/2018/11/14/210-confluent-release/#greatly-improved-collective-recovery-behavior","title":"Greatly improved collective recovery behavior","text":"<p>The collective functionality in 2.0 was unable to automatically continue running well under various circumstances and would require manual intervention.  2.1 greatly improves this to automatically recover more reliably and quickly.</p>"},{"location":"release_notes/2018/11/14/210-confluent-release/#gui-now-provides-auto-completion-in-the-noderange-field-of-the-overview-page","title":"GUI now provides auto completion in the noderange field of the overview page","text":"<p>When typing into noderange, it will now offer completion options:</p> <p></p>"},{"location":"release_notes/2018/11/14/210-confluent-release/#nodeconfig-can-now-provide-access-to-advanced-uefi-settings","title":"nodeconfig can now provide access to advanced UEFI settings","text":"<p><code>nodeconfig</code> has a new option, <code>-a</code> to work with advanced UEFI configuration settings.</p>"},{"location":"release_notes/2018/11/14/210-confluent-release/#nodeconfig-can-now-request-restoring-uefi-to-factory-default-configuration","title":"nodeconfig can now request restoring UEFI to factory default configuration","text":"<p><code>nodeconfig</code> has a new option, <code>-r uefi</code> to reset the node to UEFI factory default settings</p>"},{"location":"release_notes/2018/11/14/210-confluent-release/#nodeconfig-and-nodeattrib-commands-can-now-accept-wildcard-expressinos","title":"nodeconfig and nodeattrib commands can now accept wildcard expressinos","text":"<p>Commands can now target attribute or settings using wildcards.  For example to use this to configure all Mellanox ConnectX5 adapters as Ethernet:</p> <pre><code>$ nodeconfig d3,d4 MellanoxNetworkAdapter-*.NetworkLinkType=Ethernet\n$ nodeconfig d3,d4 MellanoxNetworkAdapter-*.NetworkLinkType\nd3: MellanoxNetworkAdapter-0600.NetworkLinkType: Ethernet\nd3: MellanoxNetworkAdapter-0601.NetworkLinkType: Ethernet\nd4: MellanoxNetworkAdapter-0600.NetworkLinkType: Ethernet\nd4: MellanoxNetworkAdapter-0601.NetworkLinkType: Ethernet\n</code></pre>"},{"location":"release_notes/2018/11/14/210-confluent-release/#nodegroupattrib-and-nodeattrib-can-now-prompt-for-attribute-values-interactively","title":"nodegroupattrib and nodeattrib can now prompt for attribute values interactively","text":"<p>This can be used to enter credentials interactively rather than passing them on command line or via environment variable.  For example to globally declare a particular user and password.</p> <pre><code>$ nodegroupattrib everything -p bmcuser bmcpass\nEnter value for bmcuser: \nConfirm value for bmcuser: \nEnter value for bmcpass: \nConfirm value for bmcpass: \neverything: secret.hardwaremanagementpassword: ********\neverything: secret.hardwaremanagementuser: ********\n</code></pre>"},{"location":"release_notes/2018/11/14/210-confluent-release/#discovery-process-can-now-apply-relaxed-password-policy-rules-if-desired","title":"Discovery process can now apply relaxed password policy rules if desired","text":"<p>If the default policies on the XCC are not desireable, they may be customised as part of discovery. For example to disable password expiration and the account lockout on too many incorrect attempts:</p> <pre><code>$ nodegroupattrib everything discovery.passwordrules=expiration=no,loginfailures=no\n</code></pre>"},{"location":"release_notes/2018/11/14/210-confluent-release/#nodeinventory-has-had-significant-improvements","title":"nodeinventory has had significant improvements","text":"<p>The structure of nodeinventory output has greatly improved for tracking multiple of the same part in a system.  Additionally it will try to resolve genericly named adapters to more descriptive names:</p> <pre><code> # nodeinventory n771 |grep GPU\n n771: GV100GL [Tesla V100 PCIe 32GB] Type: GPU\n n771: GV100GL [Tesla V100 PCIe 32GB] 2 Type: GPU\n n771: GV100GL [Tesla V100 PCIe 32GB] 3 Type: GPU\n n771: GV100GL [Tesla V100 PCIe 32GB] 4 Type: GPU\n # nodeinventory d5 |grep Fabric\n d5: Omni-Path HFI Silicon 100 Series [discrete] Type: Fabric Controller\n</code></pre>"},{"location":"release_notes/2018/11/14/210-confluent-release/#command-line-tab-completion-for-confluent-commands-for-bash-users","title":"Command line tab completion for confluent commands for bash users","text":"<p>Most confluent commands have been augmented with appropriate bash completion capability, expanding suggested noderange completions as well as arguments following the noderange.</p>"},{"location":"release_notes/2018/11/14/210-confluent-release/#collate-can-now-create-per-node-output-files","title":"collate can now create per-node output files","text":"<p>In addition to grouping data, collate can now organize node: data output into distinct files:</p> <pre><code>$ nodeeventlog d1-d8 clear | collate -l {node}.log\n$ ls\nd1.log  d2.log  d3.log  d4.log  d5.log  d6.log  d7.log  d8.log\n</code></pre>"},{"location":"release_notes/2018/11/14/210-confluent-release/#add-interface-for-retrieving-service-data","title":"Add interface for retrieving service data","text":"<p>See the documentation for the <code>nodesupport</code> command.</p>"},{"location":"release_notes/2018/11/14/210-confluent-release/#improve-consistency-of-the-networkingmacs-api","title":"Improve consistency of the /networking/macs API","text":"<p>The /networking/macs API would clear during a rescan.  Now it presents the previous data until the scan completes.</p>"},{"location":"release_notes/2018/11/14/210-confluent-release/#the-networkingmacsrescan-and-discoveryrescan-apis-can-now-be-read-to-show-current-scanning-state","title":"The /networking/macs/rescan and /discovery/rescan APIs can now be read to show current scanning state","text":"<p>Developers wanting to track the completion of scan activities may now do so via the same resources that are used to initiate rescans.</p>"},{"location":"release_notes/2018/11/14/210-confluent-release/#various-bug-fixes","title":"Various bug fixes","text":"<p>For a complete list of changes, see our git revisions</p>"},{"location":"release_notes/2018/03/05/180-confluent-release/","title":"1.8.0 Confluent release","text":"<p>There is an update to the HPC software stack, bringing xCAT to 2.13.8.lenovo2, based on 2.13.8, and confluent is brought to 1.8.0.</p> <p>Here are some of the highlighted changes:</p>"},{"location":"release_notes/2018/03/05/180-confluent-release/#added-a-nodemedia-command","title":"Added a <code>nodemedia</code> command","text":"<p>There is a new command <code>nodemedia</code> that can manage upload and attaching files as virtual USB devices on Lenovo ThinkSystem servers.</p>"},{"location":"release_notes/2018/03/05/180-confluent-release/#lenovo-switches-in-the-discovery-facility-as-exposed-by-nodediscover-as-type-lenovo-switch","title":"Lenovo switches in the discovery facility as exposed by <code>nodediscover</code> as type <code>lenovo-switch</code>","text":"<p>Lenovo switches will now have their addresses enumerated if their management ports are connected by default.  As of 1.8.0, this is merely listing the addresses, and does not yet auto-deploy configuration.</p>"},{"location":"release_notes/2018/03/05/180-confluent-release/#zero-power-discovery-of-chained-thinksystem-d2-enclosures-with-newer-firmware","title":"Zero-power discovery of chained ThinkSystem D2 enclosures with newer firmware","text":"<p>confluent can now discover chained D2 enclosures without requiring the nodes to PXE boot.  More can be read at chained D2 discovery</p>"},{"location":"release_notes/2018/03/05/180-confluent-release/#add-nodediscover-clear","title":"Add <code>nodediscover clear</code>","text":"<p>Discovery entries can now be cleared by the <code>clear</code> argument to <code>nodediscover</code>.  This can also selectively clear data by specifying the usual selectors documented in the command.</p>"},{"location":"release_notes/2018/03/05/180-confluent-release/#uefi-and-other-settings-can-now-be-managed-by-nodeconfig","title":"UEFI and other settings can now be managed by <code>nodeconfig</code>","text":"<p>The <code>nodeconfig</code> command has been extended to show UEFI data.  To get the previous behavior and only the previous behavior, can do <code>nodeconfig noderange bmc</code> for faster execution.  See the man page for more details.</p>"},{"location":"release_notes/2018/03/05/180-confluent-release/#specifically-target-different-firmware-version-retrieval-in-nodefirmware","title":"Specifically target different firmware version retrieval in <code>nodefirmware</code>","text":"<p>Notably, <code>nodefirmware noderange core</code> will get only core firmware, which tends to be a quicker operation.</p>"},{"location":"release_notes/2018/03/05/180-confluent-release/#group-membership-can-now-by-managed-by-nodeattrib-and-nodegroupattrib-using-and","title":"Group membership can now by managed by <code>nodeattrib</code> and <code>nodegroupattrib</code> using <code>,=</code> and <code>^=</code>","text":"<p>It is now easier to add and remove nodes from a group, and vice-versa.  See the man page for more detail.</p>"},{"location":"release_notes/2018/03/05/180-confluent-release/#dynamically-adjust-console-session-retry-timer","title":"Dynamically adjust console session retry timer","text":"<p>Console's should reconnect naturally on a more aggressive timescale for smaller clusters</p>"},{"location":"release_notes/2018/03/05/180-confluent-release/#environment-variables-may-now-be-used-to-pass-attribute-values-to-nodeattrib","title":"Environment variables may now be used to pass attribute values to <code>nodeattrib</code>","text":"<p><code>-e</code> has been added to the nodeattrib to read values from environment variables.  For example, to set a password without it showing up in <code>ps</code> output, <code>export BMCPASS=Passw0rd; nodeattrib n1 -e bmcpass</code></p>"},{"location":"release_notes/2018/03/05/180-confluent-release/#the-web-interface-has-a-new-rackview","title":"The web interface has a new rackview","text":"<p>The rackview has been revamped significantly.</p>"},{"location":"release_notes/2018/03/05/180-confluent-release/#web-ui-now-allows-addingremoving-nodes-and-groups","title":"Web UI now allows adding/removing nodes and groups","text":"<p>The configuration menu now has options to edit nodes and groups.</p>"},{"location":"release_notes/2018/03/05/180-confluent-release/#numerous-bugfixes","title":"Numerous bugfixes","text":"<p>For a complete list of changes, see our git revisions</p>"},{"location":"release_notes/2018/08/06/200-confluent-release/","title":"2.0.0 Confluent release","text":"<p>There is an update to the HPC software stack, bringing xCAT to 2.14.1.lenovo1, based on 2.14.1, and confluent is brought to 2.0.0.</p> <p>Here are some of the highlighted changes:</p>"},{"location":"release_notes/2018/08/06/200-confluent-release/#confluent-collective-mode","title":"Confluent collective mode","text":"<p>The largest new addition is confluent collective mode.  This allows scaling out confluent services in an active-active HA fashion.  More details are available in the documentation</p>"},{"location":"release_notes/2018/08/06/200-confluent-release/#allow-disabling-the-autosense-capability","title":"Allow disabling the autosense capability","text":"<p>The autosense capability may now be disabled if desired:</p> <pre><code>confetty set /discovery/autosense enabled=0\n</code></pre>"},{"location":"release_notes/2018/08/06/200-confluent-release/#improved-discovery-behavior-of-chained-thinksystem-d2-enclosures","title":"Improved discovery behavior of chained ThinkSystem D2 enclosures","text":"<p>Discovery of chained D2 enclosures is now more robust, notably with respect to replacement of SMMs.</p>"},{"location":"release_notes/2018/08/06/200-confluent-release/#nodeinventory-now-offers-json-output","title":"nodeinventory now offers JSON output","text":"<p><code>nodeinventory</code> command adds --json option for alternate output format</p>"},{"location":"release_notes/2018/08/06/200-confluent-release/#secure-incremental-database-backup","title":"Secure incremental database backup","text":"<p><code>confluentdbutil</code> adds <code>-s</code> argument to enable automated secure backup.  keys.json can be password protected, and does not need to be backed up in incremental backups.  Therefore it is possible to do one dump with a password protected keys.json, and then -s to do the incremental changes.  Combine the password protected keys.json with the most recent incremental backup in order to perform a restore.</p>"},{"location":"release_notes/2018/08/06/200-confluent-release/#performance-improvement","title":"Performance improvement","text":"<p>Significant optimization was performed to deliver significantly improved performance for many use cases.</p>"},{"location":"release_notes/2018/08/06/200-confluent-release/#various-bug-fixes","title":"Various bug fixes","text":"<p>For a complete list of changes, see our git revisions</p>"},{"location":"release_notes/2019/04/17/220-confluent-release/","title":"2.2.0 Confluent release","text":"<p>There is an update to the HPC software stack, bringing xCAT to 2.14.5.lenovo1, based on 2.14.5, and confluent is brought to 2.2.0.</p> <p>Here are some of the highlighted changes:</p>"},{"location":"release_notes/2019/04/17/220-confluent-release/#nodersync-command","title":"<code>nodersync</code> command","text":"<p>Like <code>nodeshell</code> does for ssh commands, nodersync supervises using rsync to push a file or directory to multiple nodes.</p>"},{"location":"release_notes/2019/04/17/220-confluent-release/#nodestorage-command","title":"nodestorage command","text":"<p>Ability to create and delete volumes and arrays through the xClarity Controller.  Examples: <pre><code>$ nodestorage d5 show\nd5: Disk drive_0 Description: 1.00TB 7.2K 6Gbps SATA 2.5\" HDD\nd5: Disk drive_0 State: unconfigured\nd5: Disk drive_0 FRU: 00LF039\nd5: Disk drive_0 Serial Number: S470YV16\nd5: Disk drive_1 Description: 1.00TB 7.2K 6Gbps SATA 2.5\" HDD\nd5: Disk drive_1 State: unconfigured\nd5: Disk drive_1 FRU: 00LF039\nd5: Disk drive_1 Serial Number: S470RYXR\nd5: Disk drive_2 Description: 1.00TB 7.2K 6Gbps SATA 2.5\" HDD\nd5: Disk drive_2 State: unconfigured\nd5: Disk drive_2 FRU: 00LF039\nd5: Disk drive_2 Serial Number: S470Z5QA\nd5: Disk drive_3 Description: 1.00TB 7.2K 6Gbps SATA 2.5\" HDD\nd5: Disk drive_3 State: unconfigured\nd5: Disk drive_3 FRU: 00LF039\nd5: Disk drive_3 Serial Number: S470XWRZ\nd5: Disk m.2-0 Description: 128GB M.2 SATA SSD\nd5: Disk m.2-0 State: unconfigured\nd5: Disk m.2-0 FRU: 00LF428\nd5: Disk m.2-0 Serial Number: H688001Y\nd5: Disk m.2-1 Description: 128GB M.2 SATA SSD\nd5: Disk m.2-1 State: unconfigured\nd5: Disk m.2-1 FRU: 00LF428\nd5: Disk m.2-1 Serial Number: H688001Z\n$ nodestorage d5 create -r 0 -d drive_0,drive_1,drive_2,drive_3 -n data\nd5: Volume data: Size: 3.811 TB\nd5: Volume data: State: Optimal\nd5: Volume data: Array 1-4\n$ nodestorage d5 create -r 1 -d rest -n os\nd5: Volume os: Size: 122.040 GB\nd5: Volume os: State: Optimal\nd5: Volume os: Array 0-0\n$ nodestorage d5 show\nd5: Disk drive_0 Description: 1.00TB 7.2K 6Gbps SATA 2.5\" HDD\nd5: Disk drive_0 State: online\nd5: Disk drive_0 FRU: 00LF039\nd5: Disk drive_0 Serial Number: S470YV16\nd5: Disk drive_0 Array: 1-4\nd5: Disk drive_1 Description: 1.00TB 7.2K 6Gbps SATA 2.5\" HDD\nd5: Disk drive_1 State: online\nd5: Disk drive_1 FRU: 00LF039\nd5: Disk drive_1 Serial Number: S470RYXR\nd5: Disk drive_1 Array: 1-4\nd5: Disk drive_2 Description: 1.00TB 7.2K 6Gbps SATA 2.5\" HDD\nd5: Disk drive_2 State: online\nd5: Disk drive_2 FRU: 00LF039\nd5: Disk drive_2 Serial Number: S470Z5QA\nd5: Disk drive_2 Array: 1-4\nd5: Disk drive_3 Description: 1.00TB 7.2K 6Gbps SATA 2.5\" HDD\nd5: Disk drive_3 State: online\nd5: Disk drive_3 FRU: 00LF039\nd5: Disk drive_3 Serial Number: S470XWRZ\nd5: Disk drive_3 Array: 1-4\nd5: Disk m.2-0 Description: 128GB M.2 SATA SSD\nd5: Disk m.2-0 State: online\nd5: Disk m.2-0 FRU: 00LF428\nd5: Disk m.2-0 Serial Number: H688001Y\nd5: Disk m.2-0 Array: 0-0\nd5: Disk m.2-1 Description: 128GB M.2 SATA SSD\nd5: Disk m.2-1 State: online\nd5: Disk m.2-1 FRU: 00LF428\nd5: Disk m.2-1 Serial Number: H688001Z\nd5: Disk m.2-1 Array: 0-0\nd5: Array 1-4 Available Capacity: 0.000 MB\nd5: Array 1-4 Total Capacity: 3.811 TB\nd5: Array 1-4 RAID: RAID 0\nd5: Array 1-4 Disks: drive_0,drive_1,drive_2,drive_3\nd5: Array 1-4 Volumes: data\nd5: Array 0-0 Available Capacity: 0.000 MB\nd5: Array 0-0 Total Capacity: 131.072 GB\nd5: Array 0-0 RAID: RAID 1\nd5: Array 0-0 Disks: m.2-0,m.2-1\nd5: Array 0-0 Volumes: os\nd5: Volume data: Size: 3.811 TB\nd5: Volume data: State: Optimal\nd5: Volume data: Array 1-4\nd5: Volume os: Size: 122.040 GB\nd5: Volume os: State: Optimal\nd5: Volume os: Array 0-0\n$ nodestorage d5 delete -n data\nDeleted: data\n</code></pre></p>"},{"location":"release_notes/2019/04/17/220-confluent-release/#revamped-nodediscover-command-behavior","title":"Revamped nodediscover command behavior","text":"<p>Fields can now be selected and the results can be ordered by any requested field.  New fields include switch, port, otherip, and bay.</p> <pre><code>$ nodediscover list -o node -f node,serial,model,type,switch,port,bay -t lenovo-xcc\n  Node|   Serial|      Model|       Type| Switch|       Port| Bay\n------|---------|-----------|-----------|-------|-----------|----\n      | J30001C1| 7X83CTO3WW| lenovo-xcc|   r8e1| Ethernet48|    \n      | J30008VD| 7X02CTO1WW| lenovo-xcc|   r8e1| Ethernet48|    \n    d1| DVJJ1086| 7X2106Z009| lenovo-xcc|   r8e1| Ethernet35|   1\n    d2| J1001PNG| 7X21CTO1WW| lenovo-xcc|   r8e1| Ethernet35|   2\n    d3| DVJJ1042| 7X2104Z000| lenovo-xcc|   r8e1| Ethernet35|   3\n    d4| DVJJ1022| 7X2104Z000| lenovo-xcc|   r8e1| Ethernet35|   4\n    d5| J1001PNF| 7X21CTO1WW| lenovo-xcc|   r8e1| Ethernet37|   1\n    d6| J1001PNE| 7X21CTO1WW| lenovo-xcc|   r8e1| Ethernet37|   2\n    d7| 00000864| 7X2104Z023| lenovo-xcc|   r8e1| Ethernet37|   3\n    d8| DVJJ1003| 7X2104Z000| lenovo-xcc|   r8e1| Ethernet37|   4\n r8u32| J30002HG| 7X07CTO1WW| lenovo-xcc|   r8e1| Ethernet32|    \n r8u33| J30002H3| 7X03CTO1WW| lenovo-xcc|   r8e1| Ethernet33|    \n</code></pre>"},{"location":"release_notes/2019/04/17/220-confluent-release/#switches-may-now-be-added-directly-and-indirectly","title":"switches may now be added directly and indirectly","text":"<p>Switches previously could only be indirectly referenced to appear in the /networking apis, now setting a node with type='switch' will cause it to be included even if it has no nodes. <pre><code>$ nodedefine r8t1 type=switch\nr8t1: created\n</code></pre></p>"},{"location":"release_notes/2019/04/17/220-confluent-release/#default-autofill-of-collectivemanager-on-discovery","title":"Default autofill of collective.manager on discovery","text":"<p>If in a collective, confluent now by default selects the node that performs discovery as the collective manager.  It continues to honor manually indicated collective.manager, this only changes the behavior if confluent is in a collective, a node is discovered, and no collective.manager is set.  collective.manager still must be manually set if bypassing the discovery facility in a collective configuration.</p>"},{"location":"release_notes/2019/04/17/220-confluent-release/#confluent2lxca-confluent2xcat-and-confluent2ansible","title":"confluent2lxca, confluent2xcat, and confluent2ansible","text":"<p>Commands to generate import data for xClarity Administrator, xCAT, and ansible from confluent attributes.</p> <pre><code>$ confluent2xcat d3-d6 -m mac.csv\n$ cat mac.csv\n#node,mac\nd3,08:94:ef:3f:e1:32\nd4,08:94:ef:41:01:f0\nd5,08:94:ef:50:be:c2\nd6,08:94:ef:50:23:60\n$ confluent2xcat d3-d6 -o nodes.stanza\n$ cat nodes.stanza \nd3:\n   objtype=node\n   arch=x86_64\n   netboot=xnba\n   mgt=ipmi\n   bmc=fe80::a94:efff:fe3f:e0af%eth1\n   mac=08:94:ef:3f:e1:32\n   slotid=3\n   groups=everything,hoplite,dense,compute\n   mpa=smm1\n\nd4:\n   objtype=node\n   arch=x86_64\n   netboot=xnba\n   mgt=ipmi\n   bmc=fe80::a94:efff:fe41:1b5%eth1\n   mac=08:94:ef:41:01:f0\n   slotid=4\n   groups=everything,dense,compute\n   mpa=smm1\n\nd5:\n   objtype=node\n   arch=x86_64\n   netboot=xnba\n   mgt=ipmi\n   bmc=fe80::a94:efff:fe50:b75d%eth1\n   mac=08:94:ef:50:be:c2\n   slotid=1\n   groups=everything,dense,compute\n   mpa=smm2\n\nd6:\n   objtype=node\n   arch=x86_64\n   netboot=xnba\n   mgt=ipmi\n   bmc=fe80::a94:efff:fe50:1c6b%eth1\n   mac=08:94:ef:50:23:60\n   slotid=2\n   groups=everything,dense,compute\n   mpa=smm2\n</code></pre>"},{"location":"release_notes/2019/04/17/220-confluent-release/#pam-enabled-by-default-usable-alongside-internal-database","title":"PAM enabled by default, usable alongside internal database","text":"<p>PAM passwords for confluent accounts is new enabled by default.  Unlike before, internal accounts can be used while PAM is also enabled.  Performance is also improved with PAM authentication.</p>"},{"location":"release_notes/2019/04/17/220-confluent-release/#nodeconsole-can-now-open-terminals-tiled","title":"nodeconsole can now open terminals tiled","text":"<p><code>nodeconsole -t</code> can be used to open a noderange of consoles in a terminal, using tmux to share the screen</p>"},{"location":"release_notes/2019/04/17/220-confluent-release/#nodeconfig-now-accepts-batch-scripts","title":"nodeconfig now accepts batch scripts","text":"<p>The batch files can mix and match three syntaxes: <pre><code>$ cat settings.batch \nset Processors.HyperThreading Disable\nProcessors.IntelVirtualizationTechnology: Disable\nProcessors.SNC=Enable\n$ nodeconfig d3 -b settings.batch\n$ nodeconfig d3 processors.hyperthreading processors.intelvirtualizationtechnology processors.snc\nd3: Processors.HyperThreading: Disable\nd3: Processors.IntelVirtualizationTechnology: Disable\nd3: Processors.SNC: Enable\n</code></pre></p>"},{"location":"release_notes/2019/04/17/220-confluent-release/#improved-performance-of-nodesensorsnodehealth","title":"Improved performance of nodesensors/nodehealth","text":"<p>IPMI SDR caches are now retained across restarts of the service.</p>"},{"location":"release_notes/2019/04/17/220-confluent-release/#nodelicense-command-now-available-to-manage-firmware-license-keys","title":"<code>nodelicense</code> command now available to manage firmware license keys","text":""},{"location":"release_notes/2019/04/17/220-confluent-release/#nodemedia-can-now-take-a-parameterized-filename-to-be-unique-per-node","title":"<code>nodemedia</code> can now take a parameterized filename to be unique per node","text":"<pre><code>$ nodemedia d4,d6 attach http://172.30.0.254/install/isos/{node}.iso\nd6: http://172.30.0.254/install/isos/d6.iso (insecure)\nd4: http://172.30.0.254/install/isos/d4.iso (insecure)\n</code></pre>"},{"location":"release_notes/2019/04/17/220-confluent-release/#discovery-process-can-now-relax-reuse-and-complexity-password-policies","title":"Discovery process can now relax reuse and complexity password policies","text":"<p>A commonly requested set of behaviors is shown: <pre><code>$ nodeattrib d3 discovery.passwordrules=expiration=no,loginfailures=no,reuse=0,complexity=no\nd3: expiration=no,loginfailures=no,reuse=0,complexity=no\n</code></pre></p>"},{"location":"release_notes/2019/04/17/220-confluent-release/#collate-now-alows-selection-of-the-base-for-comparison","title":"<code>collate</code> now alows selection of the base for comparison","text":"<p><code>collate -d -b &lt;node&gt;</code> indicates to collate that  is the base of comparison for <code>-d</code> diff behavior"},{"location":"release_notes/2019/04/17/220-confluent-release/#nodeattrib-now-provides-some-error-checking-of-select-attributes","title":"nodeattrib now provides some error checking of select attributes","text":"<pre><code>$ nodeattrib d3 discovery.policy=invalid\nError: Bad Request - Attribute discovery.policy does not accept list member invalid (valid values would be manual,permissive,pxe,open)\n</code></pre>"},{"location":"release_notes/2019/04/17/220-confluent-release/#nodeattrib-and-nodegroupattrib-now-provide-tab-completion-for-attribute-names","title":"<code>nodeattrib</code> and <code>nodegroupattrib</code> now provide tab completion for attribute names","text":"<p>Tab may now be pressed while entering attribute names into the <code>nodeattrib</code> and <code>nodegroupattrib</code> commands.</p>"},{"location":"release_notes/2019/04/17/220-confluent-release/#nodefirmware-and-nodeinventory-provide-more-detail-about-psus-in-thinksystem-servers","title":"nodefirmware and nodeinventory provide more detail about PSUs in ThinkSystem servers","text":"<pre><code>$ nodefirmware r8u32|grep PSU\nr8u32: PSU 1 FSF055: 2.50\nr8u32: PSU 2 FSF055: 2.50\n$ nodeinventory r8u32|grep PSU\nr8u32: PSU 1 Board model: SP50L09195\nr8u32: PSU 1 Wattage: 750\nr8u32: PSU 1 Board manufacturer: ACBE\nr8u32: PSU 1 FRU Number: 01GV266\nr8u32: PSU 1 Board product name: LENOVO Product\nr8u32: PSU 1 Board manufacture date: 2017-01-02T12:00\nr8u32: PSU 1 Board serial number: A1DB7131023\nr8u32: PSU 1 Revision: \nr8u32: PSU 2 Board model: SP50L09195\nr8u32: PSU 2 Wattage: 750\nr8u32: PSU 2 Board manufacturer: ACBE\nr8u32: PSU 2 FRU Number: 01GV266\nr8u32: PSU 2 Board product name: LENOVO Product\nr8u32: PSU 2 Board manufacture date: 2017-01-02T12:00\nr8u32: PSU 2 Board serial number: A1DB7131052\nr8u32: PSU 2 Revision: \n</code></pre>"},{"location":"release_notes/2019/04/17/220-confluent-release/#noderanges-may-now-operate-against-wildcard-attrib-names-nethwaddr","title":"noderanges may now operate against wildcard attrib names (<code>net.*hwaddr</code>)","text":"<pre><code>$ nodeattrib net.*hwaddr=08:94:ef:3f:e1:32 net.*hwaddr\nd3: net.hwaddr:\nd3: net.pxe.hwaddr: 08:94:ef:3f:e1:32\n</code></pre>"},{"location":"release_notes/2019/04/17/220-confluent-release/#new-cnos-plugin-for-nodehealth-on-lenovo-ne-series-switches","title":"New CNOS plugin for <code>nodehealth</code> on Lenovo NE series switches","text":"<pre><code>$ nodedefine r8t1 hardwaremanagement.method=cnos\nr8t1: created\n$ nodehealth r8t1\nr8t1: critical (Power Supply 1:12V Output Fail)\n</code></pre>"},{"location":"release_notes/2019/04/17/220-confluent-release/#various-fixes-and-minor-enhancements","title":"Various fixes and minor enhancements","text":""},{"location":"release_notes/2019/07/29/230-confluent-release/","title":"2.3.0 Confluent release","text":"<p>There is an update to the HPC software stack, bringing xCAT to 2.14.6.lenovo1, based on 2.14.6, and confluent is brought to 2.3.0.</p> <p>Here are some of the highlighted changes:</p>"},{"location":"release_notes/2019/07/29/230-confluent-release/#redfish-plugin","title":"redfish plugin","text":"<p>2.3.0 contains the initial release of the redfish plugin.  This provides more capability on an industry standard system.  Note that ipmi remains the default and generally recommended plugin to use with Lenovo systems (on Lenovo systems, the ipmi plugin will use redfish or other protocols as appropriate already).  The following scenarios would be reasons to use redfish plugin on Lenovo systems</p> <ul> <li>Wanting to use an authentication method such as LDAP, which is incompatible with ipmi</li> <li>Requirement not to use UDP port 623</li> <li>Faster nodeconfig access to select UEFI settings (not all settings are available).</li> </ul> <p>At this point, redfish implementations are generally slower than their IPMI counterparts.  Additionally system firmware redfish support has been maturing only recently, and as such firmware from 2019 is strongly recommended regardless of vendor.</p> <p>To use, set the <code>hardwaremanagement.method</code> attribute to <code>redfish</code>.</p>"},{"location":"release_notes/2019/07/29/230-confluent-release/#nodeshell-and-noderun-commands-have-n-argument","title":"nodeshell and noderun commands have -n argument","text":"<p>This will suppress the nodename portion of the output.  For example, one could do an ad-hoc creation of /etc/hosts entries through a command such as: <pre><code>$ noderun -n rackmount echo 172.20.{n1}.{n2} {node}.domain\n172.20.8.32 r8u32.domain\n172.20.8.33 r8u33.domain\n</code></pre></p>"},{"location":"release_notes/2019/07/29/230-confluent-release/#new-stats-command","title":"New <code>stats</code> command","text":"<p>The <code>stats</code> command has been added to help analyze numerical output. By default it gives a few frequently useful statistics: <pre><code>$ grep 2R2 node*.log | stats\nSamples: 54 Min: 1680.54 Median: 1682.485 Mean: 1682.51018519 Max: 1688.49 StandardDeviation: 1.2434755515 Sum: 90855.55\n</code></pre></p> <p>It can optionally produce a textual histogram. <pre><code>$ grep 2R2 node*.log | stats -t\n1680.5|=======================\n1681.3|==========================================================\n1682.1|=========================================================================\n1682.9|===================================\n1683.7|============\n1684.5|====\n1685.3|\n1686.1|\n1686.9|\n1687.7|====\nSamples: 54 Min: 1680.54 Median: 1682.485 Mean: 1682.51018519 Max: 1688.49 StandardDeviation: 1.2434755515 Sum: 90855.55\n</code></pre></p> <p>If you have a sixel enabled terminal, a graphical chart may be requested:</p> <p></p>"},{"location":"release_notes/2019/07/29/230-confluent-release/#confluent-now-supports-user-groups","title":"Confluent now supports user groups","text":"<p>The /usergroups/ api is now available to create groups.  This is mapped by default to system group names and memberships, which may be /etc/group or LDAP groups.</p> <p>To confer access to any member of the wheel group to confluent: <pre><code>confetty create /usergroups/wheel\n</code></pre></p>"},{"location":"release_notes/2019/07/29/230-confluent-release/#confluent-now-has-user-roles","title":"Confluent now has user roles","text":"<p>Confluent users and usergroups may be limited in privilege to one of the roles: <code>Administrator</code>, <code>Operator</code>, or <code>Monitor</code>. <code>Administrator</code> is the usual full access, <code>Operator</code> is blocked from modifying users/passwords.  <code>Monitor</code> is severely limited to select reead-only access appropriate foruse in monitoring scripts.  This may be done to users or groups.</p> <p>For example, to limit wheel group to not change any passwords or users:</p> <pre><code>confetty set /usergroups/wheel role=Operator\n</code></pre>"},{"location":"release_notes/2019/07/29/230-confluent-release/#improved-discovery-for-xcc-and-smm","title":"Improved discovery for XCC and SMM","text":"<p>Where possible, discovery for XCC and SMM will induce fewer failed login attempts and also will execute more quickly.  Additionally, systems that are configured to not have IPMI available are now able to be discovered.</p>"},{"location":"release_notes/2019/07/29/230-confluent-release/#web-forwarder-now-works-if-confluent-gui-served-from-custom-port","title":"Web forwarder now works if confluent gui served from custom port","text":"<p>The functionality to open endpoint management consoles in web interface now supports custom https ports for the main confluent gui.</p>"},{"location":"release_notes/2019/07/29/230-confluent-release/#storage-configuration-now-supports-custom-strip-sizes-and-modifying-disk-state","title":"Storage configuration now supports custom strip sizes and modifying disk state","text":"<p><code>nodestorage</code> has the <code>-s</code> argument added to specify strip size on array creation.  Additionally, it has added the <code>setdisk</code> subcommand to manage jbod/hotspare state.</p>"},{"location":"release_notes/2019/07/29/230-confluent-release/#fix-confluent-environment-file-for-zsh-users","title":"Fix confluent environment file for zsh users","text":"<p>The bash completion enhancements are now only attempted if the shell is bash</p>"},{"location":"release_notes/2019/07/29/230-confluent-release/#nodelicense-can-now-save-and-delete-licenses-from-lenovo-xccs","title":"<code>nodelicense</code> can now save and delete licenses from Lenovo XCCs","text":"<p>For example, to backup a noderange of license keys to one directory per node: <pre><code>nodelicense rack1 save ./licenses/{node}/\n</code></pre></p>"},{"location":"release_notes/2019/07/29/230-confluent-release/#fix-login-process-died-errors","title":"Fix \"login process died\" errors","text":"<p>In certain specific scenarios, \"login process died\" errors would come from ipmi plugin.  A class of those scenarios has been fixed and an autorecovery mechanism has been put into place to catch any remaining causes.</p>"},{"location":"release_notes/2019/07/29/230-confluent-release/#a-node-may-now-be-more-easily-forced-through-repeating-discovery","title":"A node may now be more easily forced through repeating discovery","text":"<p><code>nodediscover</code> now has a <code>reassign</code> subcommand.  To have discovered node <code>d1</code> repeat discovery procedure: <pre><code>nodediscover reassign -n d1\n</code></pre></p>"},{"location":"release_notes/2019/07/29/230-confluent-release/#new-credentials-are-encrypted-and-validated-using-aes-gcm-instead-of-aes-cbc-and-sha-256","title":"New credentials are encrypted and validated using AES-GCM instead of AES-CBC and SHA-256","text":"<p>As a result, 2.3.0 attribute databases and backups cannot be used with older versions of confluent.</p>"},{"location":"release_notes/2019/07/29/230-confluent-release/#improve-detail-in-the-event-of-unexpected-error-situations","title":"Improve detail in the event of \"Unexpected Error\" situations","text":"<p>Error messages now include some potentially useful information for resolving the issue.</p>"},{"location":"release_notes/2019/07/29/230-confluent-release/#ipmi-now-supports-hmac-sha256hmac-sha256-128","title":"IPMI now supports HMAC-SHA256/HMAC-SHA256-128","text":"<p>xCAT and confluent both try to use HMAC-SHA256 when supported now for IPMI communication.</p>"},{"location":"release_notes/2019/07/29/230-confluent-release/#gui-consoles-now-show-health-summary-in-title-bar","title":"GUI consoles now show health summary in title bar","text":"<p>When using many consoles, it will obscure the normal view.  This brings the health status front and center to be usable in that scenario</p> <p></p>"},{"location":"release_notes/2020/09/10/304-confluent-release/","title":"3.0.4 Confluent release","text":"<p>There is an update to the scale out management stack, bringing xCAT to 2.16.0.lenovo1 (based on 2.16.0) and confluent is now at 3.0.4.</p> <p>The major change in confluent is the addition of OS deployment support. This includes: * Deploy to disk is implemented for RedHat/CentOS 7 and 8, SuSE Enterprise/LEAP 15.3, RHV-H 4.\u00be.4, ESXi 6.7/7, and Ubuntu 20.04 * Boot over USB, as well as over PXE and HTTP/HTTPS over Ethernet, Infiniband, or Omnipath is supported * SSH is enabled early during installations and systems may be sshed into more easily during installer execution for monitoring and debug * HTTPS boot and install support - All installation activity may optionally be protected by HTTPS * TLS CA management - each collective member becomes a TLS certificate authority and signs its own certificate and OS deployment has those   authorities added * SecureBoot support - When using HTTP boot (instead of PXE), SecureBoot may be enabled throughout the deployment process * Encrypted OS disk - For RedHat/CentOS 8.2 and higher, encrypting the OS install disk using the TPM2 is now supported * Built in PXE and ProxyDHCP support - Confluent may either coexist with an existing DHCP server without configuring that DHCP server or operate without any DHCP server at all * A new genesis distribution is provided for optional use, though no longer required even for PXE driven discovery * Partial in-band BMC configuration is available with <code>configbmc</code> facility (can configure dedicated/shared, vlan, and ip address, but user and ipmi config happens remotely) * Autodetection of serial port parameters - No longer requires manual specification of console port and speed, it will be detected from firmware * New SSH infrastructure strategy - SSH CA is configured and used to sign host keys to enable known_hosts and facilitate host based authentication. This eliminates any transfer or reuse of any user or host private keys, while enabling non-administrative users for node-to-node ssh without user managed keys.</p> <p>When deciding whether to use xCAT or confluent for cluster setup, a comparison is provided.</p> <p>Storage volumes with blank names can now be deleted by nodestorage.</p> <p>Additionally, confluent noderanges now understand <code>..</code> (two dots) as a synonym for '-' or ':' to indicate a range of sequential systems.</p>"},{"location":"release_notes/2020/04/23/250-confluent-release/","title":"2.5.0 Confluent release","text":"<p>There is an update to the HPC software stack, bringing xCAT to 2.15.1.lenovo1, based on 2.15.1, and confluent is brought to 2.5.0.</p> <p>Here are some of the highlighted changes:</p>"},{"location":"release_notes/2020/04/23/250-confluent-release/#change-from-pickle-to-msgpack-for-intra-collective-communication","title":"Change from pickle to msgpack for intra-collective communication","text":"<p>Due to changes in the underlying protocol, a collective may not come up until all active collective members are updated.</p>"},{"location":"release_notes/2020/04/23/250-confluent-release/#role-is-now-a-mandatory-attribute-for-users-and-groups","title":"role is now a mandatory attribute for users and groups","text":"<p>When creating a user or group, formerly it defaulted to admin role. Now this must be explicitly specified:</p> <p><code>confetty create /users/name role=admin</code></p>"},{"location":"release_notes/2020/04/23/250-confluent-release/#nodeconfig-performance-improvements-for-xcc-based-systems","title":"nodeconfig performance improvements for XCC based systems","text":"<p>nodeconfig is significantly improved for XCC based systems for most settings. This has required that 'IMM.' settings be relegated to optionally be fetched (using <code>-e</code> option) which will be as slow as nodeeconfig has previously been.</p>"},{"location":"release_notes/2020/04/23/250-confluent-release/#confluent-now-runs-as-confluent-user","title":"Confluent now runs as 'confluent' user","text":"<p>Rather than run as root, confluent will run as confluent user as configured by the packaged systemd unit file.  confluent however does have certain extended capabilities to continue providing the same function.</p>"},{"location":"release_notes/2020/04/23/250-confluent-release/#cumulus-switch-support-through-affluent-package","title":"Cumulus switch support through <code>affluent</code> package.","text":"<p>A debian packaged agent named 'affluent' is available for cumulus switches. This provides more secure and faster access to health and network information to confluent.</p>"},{"location":"release_notes/2020/04/23/250-confluent-release/#collate-adds-a-g-option","title":"collate adds a <code>-g</code> option","text":"<p>collate will list a count of different output groups rather than the actual output when requested.</p>"},{"location":"release_notes/2021/01/21/310-confluent-release/","title":"3.1.0 Confluent release","text":"<p>There is an update to the HPC software stack, bringing xCAT to 2.16.1.lenovo1, and confluent is brought to 3.1.0.</p> <p>Here are some of the highlighted changes:</p>"},{"location":"release_notes/2021/01/21/310-confluent-release/#collective-autofailover-and-restricted-deployment-support","title":"Collective autofailover and restricted deployment support","text":"<p>A new attribute <code>collective.managercandidates</code> can be used to specify a noderange of valid managers for a node. If defined, deployment will not be served from other collective members even if it would otherwise be possible, and a failure of a member of that range will have its managed nodes migrated to another member of that noderange.</p>"},{"location":"release_notes/2021/01/21/310-confluent-release/#implement-sshtrustnodes-to-limit-node-to-node-ssh-trust","title":"Implement <code>ssh.trustnodes</code> to limit node to node ssh trust","text":"<p>A node may define a noderange of trusted nodes to have more limited trust. By default all members of the cluster deployed by confluent trust each other. This attribute allows this to be restricted so that, for example, storage nodes could opt not to allow compute nodes to log in.</p>"},{"location":"release_notes/2021/01/21/310-confluent-release/#new-os-deployment-profiles","title":"New OS deployment profiles","text":"<p>Support has been added for CentOS 8.3 and RedHat 8.3, Oracle Linux 7 and 8, and CentOS Stream 8</p>"},{"location":"release_notes/2021/01/21/310-confluent-release/#most-stock-os-images-now-have-postd-and-firstbootd","title":"Most stock OS images now have 'post.d' and 'firstboot.d'","text":"<p>Scripts may be placed in post.d or firstboot.d to be automatically executed at end of install or on first boot respectively.</p>"},{"location":"release_notes/2021/01/21/310-confluent-release/#os-images-now-have-a-fetch_remote-function-in-etcconfluentfunctions","title":"OS images now have a 'fetch_remote' function in /etc/confluent/functions","text":"<p>OS images can now retrieve arbitrary payloads from it's host directory.  For example:</p> <pre><code>. /etc/confluent/functions\nfetch_remote infiniband/mofed.tgz\n</code></pre> <p>In a script will download mofed.tgz from /var/lib/confluent/public/os/(profilename)/scripts/infiniband/mofed.tgz</p>"},{"location":"release_notes/2021/01/21/310-confluent-release/#os-image-profileyaml-now-have-installedargs","title":"OS image profile.yaml now have 'installedargs'","text":"<p>The current <code>kernelargs</code> controls how the installer is booted. <code>installedargs</code> can be used to control how the installed system boots separate of the installer.</p>"},{"location":"release_notes/2021/01/21/310-confluent-release/#configbmc-will-now-trigger-remote-authentication-configuration","title":"<code>configbmc</code> will now trigger remote authentication configuration","text":"<p>If using in-band BMC configuration rather than remote configuration, it will now request the manager to remotely configure the username and password, to be consistent with out of band and keep the credentials withheld from the OS that is installing.</p>"},{"location":"release_notes/2021/01/21/310-confluent-release/#support-use-of-tpm2-to-persist-node-keys-across-reboot","title":"Support use of TPM2 to persist node keys across reboot","text":"<p>Genesis can now be rebooted without rearming the node token grant. This will facilitate a more secure stateless strategy as well, where node trust is persisted through the TPM2.</p>"},{"location":"release_notes/2021/01/21/310-confluent-release/#web-interface-will-function-better-when-used-in-domain-shared-with-other-web-services","title":"Web interface will function better when used in domain shared with other web services","text":"<p>Other servers in a companies domain would set domain wide cookies that could interfere with confluent web gui operation. Those invalid cookies are now discarded to allow the web interface to work.</p>"},{"location":"release_notes/2021/01/21/310-confluent-release/#improved-error-messages-on-some-commands","title":"Improved error messages on some commands","text":"<p>A few commands provide more specific and useful feedback on failure.</p>"},{"location":"release_notes/2021/01/21/310-confluent-release/#various-fixes-for-esxi-deployment","title":"Various fixes for ESXi deployment","text":"<p>A number of limitations around ESXi deployment have been addressed</p>"},{"location":"release_notes/2021/01/21/310-confluent-release/#new-memory-consolelogging-option","title":"New <code>memory</code> console.logging option","text":"<p>If console.logging is set to <code>memory</code>, then the replay buffer will be maintained, but not committed to disk. This can improve performance on slow /var/log/confluent filesystems.</p>"},{"location":"release_notes/2021/01/21/310-confluent-release/#better-support-for-cisco-ethernet-switches-in-networking-api","title":"Better support for Cisco ethernet switches in /networking/ api","text":"<p>More complex use of vlans on Cisco equipment will no longer make addresses invisible to confluent</p>"},{"location":"release_notes/2021/01/21/310-confluent-release/#add-more-attributes-to-discovery-api-for-lenovo-equipment","title":"Add more attributes to discovery api for Lenovo equipment","text":"<p>Some enduser curated information is made available if detected</p>"},{"location":"release_notes/2021/01/21/310-confluent-release/#genesis-now-starts-ssh-if-booted-without-detected-confluent-server-and-listens-on-3389","title":"Genesis now starts ssh if booted without detected confluent server, and listens on 3389","text":"<p>This change allows a genesis booted through the BMC to be logged into remotely through BMC port forwarding where available. This can be used to diagnose/reconfigure networking when that would normally block remote deployment.</p>"},{"location":"release_notes/2021/01/21/310-confluent-release/#performance-improvements","title":"Performance improvements","text":"<p>Several areas of memory and processor usage have been optimized, particularly in handling PXE requests, discovery scanning, and nodeconfig</p>"},{"location":"release_notes/2021/01/21/310-confluent-release/#various-bugfixes","title":"Various bugfixes","text":"<ul> <li>Remove cursor key mode preservation, which can conflict with firmware setup menu operation</li> <li>Shell sessions no longer leave phantom ssh sessions</li> <li>Fixes to automatic console behavior</li> <li>Improved TSM discoevry as used in SR635 and SR655 servers</li> <li>Relax expectations in nodeconfig batch files, quotes are no longer required for spaces in values</li> <li>UUID handling is now case insensitive, working better with some script injection of id.uuid</li> <li>Fix file descriptor leak in the web forwarder</li> </ul>"},{"location":"release_notes/2021/12/15/332-confluent-release/","title":"3.3.2 Confluent release","text":"<p>3.3.2 has been released with the following changes:</p>"},{"location":"release_notes/2021/12/15/332-confluent-release/#new-diskless-and-cloning-deployment-support","title":"New diskless and cloning deployment support","text":"<p>A new utility <code>imgutil</code> is provided to create diskless and cloning OS profiles.  The diskless support differs from xCAT in the following ways: * By default, a new tethered mode is used, where OS is retrieved block by block on demand, greatly reducing memory usage for large images. A new multipath http filesystem was created for this task. * All writes are compressed to mitigate memory usage, and untethered mode no longer decompresses the root filesystem up front. * Diskless images are no longer 'pruned', making it easier to build an image and using an image is less unusual, facilitated by memory savings above * Greater emphasis is placed on consistent behavior with a disk-installed system (e.g. network management and network names) * Initramfs now persists after boot, allowing administrator to ssh using port 2222 to debug and fix potential issues in the root filesystem * By default, diskless and captured images are encrypted, and nodes must use confluent node API to get decryption key * SSH, image decryption key, crypted root password are now by default linked to the server TPM2 to improve security on reboot * The image no longer contains even an encrypted root password. * Common changes to scripted install also apply to diskless and cloning (e.g. no private SSH keys are transferred). * The product of <code>build</code> now naturally creates the correct initramfs, no need for a <code>geninitrd</code> to apply a kernel update. * A new capability <code>imgutil exec</code> is provided to launch the <code>imgutil build</code> product into a container-style environment for customization and updating with better protection of the build host.</p>"},{"location":"release_notes/2021/12/15/332-confluent-release/#new-confignet-facility-in-os-deployment","title":"New <code>confignet</code> facility in os deployment","text":"<p>Multi-interface configuration including bonding is now possible through the <code>confignet</code> facility.</p>"},{"location":"release_notes/2021/12/15/332-confluent-release/#improved-discovery-performance-and-reliability","title":"Improved discovery performance and reliability","text":"<p>A number of issues were identified and resolved to dramatically improve discovery initial scan and rescan, both in terms of speed and reliability of results being correctly recognized.</p>"},{"location":"release_notes/2021/12/15/332-confluent-release/#alternative-target-names-and-login-name-for-nodeshell","title":"Alternative target names and login name for nodeshell","text":"<p>A new argument <code>-s</code> has been added to nodeshell to allow an expression or suffix to specify something other than nodename as target for ssh, and <code>-l</code> can be used to specify an alternate login.</p>"},{"location":"release_notes/2021/12/15/332-confluent-release/#updated-os-deployment-support","title":"Updated OS deployment support","text":"<p>SUSE Enterprise 15 SP3 and LEAP 15.3 are now supported, as well as CentOS Stream 9 scripted install to disk. Additionally, RedHat CoreOS is now supported with ignition information protected by confluent's private profile facility.</p>"},{"location":"release_notes/2021/12/15/332-confluent-release/#support-multiple-password-prompts-in-web-gui-eg-totp-2fa","title":"Support multiple password prompts in web gui (e.g. TOTP 2FA)","text":"<p>If configured, confluent gui will manifest the conversation prompts and support use of multiple fields for password.</p>"},{"location":"release_notes/2021/12/15/332-confluent-release/#confluent-now-uses-a-distinct-tls-ca-from-webserver-certificate-instead-of-self-signed","title":"Confluent now uses a distinct TLS CA from webserver certificate instead of self-signed","text":"<p>This change enables regenerating webserver certificates due to ip reconfiguration without disrupting trust in site.cpio, boot.img, and existing nodes. It also is compatible with some software that explicitly forbids self signed certificates.</p>"},{"location":"release_notes/2021/12/15/332-confluent-release/#noderange-syntax-now-supports-a-step","title":"Noderange [] syntax now supports a step","text":"<p>For example n[1:200:2] will indicate all odd numbered nodes, and n[2:200:2] will do all even numbered systems between n1 and n200.</p>"},{"location":"release_notes/2021/12/15/332-confluent-release/#improve-boot-attempt-logging-information","title":"Improve boot attempt logging information","text":"<p>More information is now in /var/log/confluent/events to aid in diagnosing configuration issues.</p>"},{"location":"release_notes/2021/12/15/332-confluent-release/#syncfiles-now-supports-merging-into-a-single-file-from-multiple-sources","title":"syncfiles now supports merging into a single file from multiple sources","text":"<p>If two files comprise distinct amendments for /etc/passwd, for example, they may now both point directly to /etc/passwd</p>"},{"location":"release_notes/2021/12/15/332-confluent-release/#partial-ipv6-deployment-support","title":"Partial IPv6 deployment support","text":"<p>HTTP over IPv6 is now supported for the initial kernel/initramfs and genesis can now boot with ipv6 along with or instead of ipv4.</p>"},{"location":"release_notes/2021/12/15/332-confluent-release/#new-utility-confluent2hosts-to-aid-in-creating-and-updating-etchosts","title":"New utility <code>confluent2hosts</code> to aid in creating and updating /etc/hosts","text":"<p>The utility works in lieu of xCAT's <code>makehosts</code> for IPv4 and IPv6 addresses without requiring ip be in an attribute first.</p>"},{"location":"release_notes/2021/12/15/332-confluent-release/#additional-features-for-syncfiles-facility","title":"Additional features for syncfiles facility","text":"<p>Ability to restrict an entry to a specific noderange. Specify user,group,permissions for an entry to explicitly change syncfiles may now use '&lt;' to indicate including another syncfile</p>"},{"location":"release_notes/2021/12/15/332-confluent-release/#plugins-may-now-extend-the-confluent-api","title":"Plugins may now extend the confluent api","text":"<p>A private plugin is now allowed to extend the API. This can be used alongside 'custom.' attributes to have customized plugins for unique needs without coordinating with the upstream project.  Note that while the node/ api may be extended however the user likes, use of the word 'custom' in the path is recommended to not conflict with any future api changes.</p>"},{"location":"release_notes/2021/12/15/332-confluent-release/#ignore-a-certain-likely-invalid-uuid","title":"Ignore a certain likely invalid UUID","text":"<p>Platforms using industry standard UEFI may use a specific UUID if not initialized properly. This UUID is now blacklisted along with other frequent invalid UUIDs</p>"},{"location":"release_notes/2021/12/15/332-confluent-release/#fix-for-affluent-agent-on-cumulus-switches-without-firmware-uuid","title":"Fix for affluent agent on cumulus switches without firmware UUID","text":"<p>The affluent agent had added support for firmware UUID. However, some switches have been found to not implement that feature, and a fallback has been implemented.</p>"},{"location":"release_notes/2021/06/01/320-confluent-release/","title":"3.2.0 Confluent release","text":"<p>3.2.0 has been released with the following changes:</p>"},{"location":"release_notes/2021/06/01/320-confluent-release/#firmware-updates-media-os-import-and-more-no-longer-require-confluent-user-to-have-access","title":"Firmware updates, media, os import, and more no longer require confluent user to have access","text":"<p>When using the CLI client, the end user access is used when possible for the relevant file rather than requiring the confluent user be able to open it independently. This should largely eliminate the need to place files in /tmp and set relaxed permissions for confluent to process them, except when traversing a collective.</p>"},{"location":"release_notes/2021/06/01/320-confluent-release/#lenovo-v2-product-family-is-now-supported","title":"Lenovo v2 product family is now supported","text":"<p>Updates have been performed to support new functions in the v2 family. Notably: * New configurations of v2 dense chassis are supported * <code>nodereseat</code> can now reseat rackmount servers as well as dense for v2 servers</p>"},{"location":"release_notes/2021/06/01/320-confluent-release/#ansible-playbooks-are-now-supported-in-os-profiles","title":"Ansible playbooks are now supported in OS profiles","text":"<p>A profile may contain ansible/post.d/, ansible/firstboot.d/, and/or ansible/onboot.d/ yaml files. If present, then confluent will execute the plays on the management node targeted at a node reaching that phase of deployment. The 'Hosts' line will be provided by confluent, and should be omitted from plays in those directories.  Requires <code>osdeploy initialize -a</code></p>"},{"location":"release_notes/2021/06/01/320-confluent-release/#a-syncfiles-facility-has-been-implemented","title":"A syncfiles facility has been implemented","text":"<p>Profiles now have a <code>syncfiles</code> facility that allow files on the deployment server to be synced to servers during the post phase:</p> <ul> <li>Implements a superset of syntax as xCAT syncfiles</li> <li>Merging passwd and group implicitly creates password disabled corresponding shadow entries as needed</li> <li>syncfiles file in a profile directory directs functionality (samples available in default profiles)</li> <li>Requires <code>osdeploy initialize -a</code></li> </ul>"},{"location":"release_notes/2021/06/01/320-confluent-release/#confluent-genesis-environment-has-received-improvements","title":"Confluent Genesis environment has received improvements","text":"<p>As well as refreshing the general lever of software contained in genesis, some key enhancements have been implemented:</p> <ul> <li>Confluent genesis may now be targeted by ansbile plays</li> <li>Console behavior is enhanced for video console when serial is in use</li> <li>Confluent now supports LVM2 drives for rescue activity</li> </ul>"},{"location":"release_notes/2021/06/01/320-confluent-release/#collective-behavior-has-been-significantly-improved","title":"Collective behavior has been significantly improved","text":"<p>A focus area during 3.2 development was studying collective behavior in very large configurations, and addressing a number of issues: * Improve speed of convergence of state information * Reduce instances of 'lost' collective members missed during startup * Better handling of long-running remote tasks to avoid false errors about collective member going unreachable</p>"},{"location":"release_notes/2021/06/01/320-confluent-release/#switch-interrogation-is-now-subject-to-collectivemanagercandidates","title":"Switch interrogation is now subject to <code>collective.managercandidates</code>","text":"<p>A collective may spsecify which managers are permitted to scan a switch. This can be used to speed up switch interrogation in large clusters with multiple collective members dealing with isolated 'islands' of networking.</p>"},{"location":"release_notes/2021/06/01/320-confluent-release/#numerous-performance-improvements-have-been-implemented","title":"Numerous performance improvements have been implemented","text":"<p>A significant effort was put into profiling and identifying opportunities for significant performance improvement. Notably:</p> <ul> <li>VT-aware buffering is now offloaded and rewritten in C</li> <li>SNMP switch interrogation is offloaded the main process</li> <li>nodeconfig memory consumption has been improved</li> <li>Improved discovery performance</li> <li>Web consoles are migrated to a websocket interface</li> </ul>"},{"location":"release_notes/2021/06/01/320-confluent-release/#improvements-have-been-made-to-os-deployment","title":"Improvements have been made to OS deployment","text":"<p>A number of enhancements were done for OS deployment: * A firstboot.d script may now 'reboot' without breaking firstboot support * Output is now more prominent on console and in /var/log/confluent * A new <code>source_remote_parts</code> is added to let a script source, rather than run, segregated scripts that are remote. * Some envirnonment variables have had 'confluent_' prepended, to avoid conflict with other uses of the common variable names. * Alma, Rocky, CentOS Stream, CentOS, and RedHat are all supported through at least 8.4 version</p>"},{"location":"release_notes/2021/06/01/320-confluent-release/#confluent-private-ssh-keys-are-now-encrypted","title":"Confluent private SSH keys are now encrypted","text":"<p>The private keys are now encrypted on generation, and ssh-agent is used to decrypt. The same protection applied to 'secret.' attributes is extended to private ssh keys used by confluent SSH certificate authority, and the key used for ansible execution and syncfiles operation</p>"},{"location":"release_notes/2021/06/01/320-confluent-release/#various-minor-enhancements-and-fixes-have-been-done","title":"Various minor enhancements and fixes have been done","text":"<p>A large number of minor fixes and enhancements were done. Some changes include:</p> <ul> <li><code>nodesetboot</code> and <code>nodeboot</code> now accept <code>usb</code> as a boot device target</li> <li><code>osdeploy</code> now has a <code>list</code> subcommand to show distributions and profiles</li> <li><code>nodeshell</code> now has a <code>-s</code> argument to allow specifying an alternative name (e.g. <code>bmc-{node}</code>) or suffix (e.g. <code>-eth1</code>) for ssh processes</li> </ul>"},{"location":"release_notes/2022/06/13/350-confluent-release/","title":"3.5.0 Confluent release","text":"<p>3.5.0 has been released with the following changes:</p>"},{"location":"release_notes/2022/06/13/350-confluent-release/#nodeping-command-has-been-added","title":"nodeping command has been added","text":"<p>The <code>nodeping</code> allows easy invocation of ping against a node range, with options to use suffixes or expressions to ping alternate interfaces.</p>"},{"location":"release_notes/2022/06/13/350-confluent-release/#xcc-and-smm-passwords-are-now-unexpired-on-discovery-if-expired","title":"XCC and SMM passwords are now unexpired on discovery if expired","text":"<p>Discovery will now work even if the password on the endpoint is already set, but expired.</p>"},{"location":"release_notes/2022/06/13/350-confluent-release/#nodeconsole-now-has-a-l-option-to-replay-logs","title":"<code>nodeconsole</code> now has a <code>-l</code> option to replay logs","text":"<p>The nodeconsole now has a flag to initiate a log replay of a node. Arrow keys can navigate the console and the titlebar is updated to show time of on-screen content.  Further, any screen clears force a pause in navigation to clearly show errors before they would normally be cleared from the screen.  Search is also supported.</p>"},{"location":"release_notes/2022/06/13/350-confluent-release/#web-ui-now-supports-passwordless-authentication-using-webathn","title":"Web UI now supports passwordless authentication using webathn","text":"<p>If logged in, a user may select 'Register authenticator' to enroll an authenticator. Then if they skip entering password, it will begin the authenticator based login.</p>"},{"location":"release_notes/2022/06/13/350-confluent-release/#improve-web-ui-performance","title":"Improve web UI performance","text":"<p>Consoles and most large scale queries are now performed over a shared socket, resulting in smoother experience and more consoles on screen at a time.</p>"},{"location":"release_notes/2022/06/13/350-confluent-release/#os-deployment-additions","title":"OS deployment additions","text":"<p>Ubuntu 22.04, SuSE 15 SP4, Leap 15.4, RedHat 9, Rocky 9, and Alma 9 support has been added.</p>"},{"location":"release_notes/2022/06/13/350-confluent-release/#diskless-el8-now-has-local-repositories-after-boot","title":"Diskless EL8 now has local repositories after boot","text":"<p>Site repositories are now made available to newly built diskless images.</p>"},{"location":"release_notes/2022/06/13/350-confluent-release/#support-for-select-pdus-have-been-added","title":"Support for select PDUs have been added","text":"<p>Outlet status and control for select Delta, Eaton, and Vertiv PDUs has been added.</p>"},{"location":"release_notes/2022/06/13/350-confluent-release/#add-redhat-9-management-node-support","title":"Add RedHat 9 management node support","text":"<p>RedHat 9 (and related) platforms can now install and run confluent</p>"},{"location":"release_notes/2022/06/13/350-confluent-release/#implement-vroc-support-in-suse-scripted-deployment","title":"Implement VROC support in SuSE scripted deployment","text":"<p>Pre-existing VROC arrays are now properly auto-handled in scripted deployment of SUSE</p>"},{"location":"release_notes/2022/06/13/350-confluent-release/#change-to-bond-from-team-in-suse-distributions","title":"Change to bond from team in SuSE distributions","text":"<p>SuSE never naturally used team, follow their standard behavior and go for bond instead.</p>"},{"location":"release_notes/2022/06/13/350-confluent-release/#updates-to-the-tls-ca","title":"Updates to the TLS CA","text":"<p>New installations will backdate the start validity of certificates and RedHat nodes will retain the internal trust across updates</p>"},{"location":"release_notes/2022/06/13/350-confluent-release/#add-routed-support-for-redhat-coreos-deployment","title":"Add routed support for RedHat CoreOS deployment","text":"<p>CoreOS may now be deployed through a router through pairing an identity image with a deployment image.</p>"},{"location":"release_notes/2022/06/13/350-confluent-release/#confluent-expression-can-now-slice-a-variable","title":"Confluent expression can now slice a variable","text":"<p>For example, a node named <code>node123</code> with {node[-4:]} would show <code>e123</code></p>"},{"location":"release_notes/2022/12/05/360-confluent-release/","title":"3.6.0 Confluent release","text":"<p>3.6.0 has been released with the following changes:</p>"},{"location":"release_notes/2022/12/05/360-confluent-release/#genesis-profiles-must-be-re-generated","title":"Genesis profiles must be re-generated","text":"<p>The new genesis has an incompatibility with existing genesis profile.  <code>osdeploy initialize -g</code> must be done to re-do the genesis profile, after moving or removing the existing genesis profile.</p>"},{"location":"release_notes/2022/12/05/360-confluent-release/#a-self-check-has-been-added-to-help-identify-common-configuration-issues","title":"A self-check has been added to help identify common configuration issues","text":"<p>A new command <code>confluent_selfcheck</code> has been added to examine and highlight configuration issues that are commonly encountered.</p>"},{"location":"release_notes/2022/12/05/360-confluent-release/#remote-discovery-through-new-affluent-version","title":"Remote discovery through new affluent version","text":"<p>The new affluent offers expanded capabilities for auto-detect and enhanced security of discovery.  This also enables the switch to extend the reach of confluent discovery to routed networks.  With this feature, confluent can discover Lenovo SMMv2 and xClarity Controller 2 systems, regardless of VLAN or VRF. In order to use, update affluent on the switch and use <code>nodediscover subscribe &lt;switchname&gt;</code> to subscribe to discovery updates from a switch.</p>"},{"location":"release_notes/2022/12/05/360-confluent-release/#new-verified-discoverypolicy","title":"New <code>verified</code> discovery.policy","text":"<p>When using the aforementioned switch driven discovery through <code>subscribe</code> on nodediscover, a new policy <code>verified</code> is available for discovery.policy.  This allows for a node replacement to be fully automated, if and only if the new node certificate is vetted by the directly attached ethernet switch running affluent.  This only works with Lenovo SMMv2 and Lenovo xClarity 2 based systems.</p>"},{"location":"release_notes/2022/12/05/360-confluent-release/#registration-of-remote-subnets-in-discovery","title":"Registration of remote subnets in discovery","text":"<p>xClarity Controller devices may now be added by IP or Subnet to scan using <code>nodediscover register</code>.  This brings such devices into the nodediscover list for potential assignment.  This can take an IP address, subnet (address/prefix syntax), or range of IP addresses (address1-address2).</p>"},{"location":"release_notes/2022/12/05/360-confluent-release/#the-hardwaremanagementmanager-now-accepts-cidr-syntax","title":"The hardwaremanagement.manager now accepts CIDR syntax","text":"<p>To facilitate remote setup with static addressing, the <code>hardwaremanagement.manager</code> attribute can now have CIDR to indicate the subnet prefix length (1.2.3.4/24).  This can be used with either the <code>register</code> or <code>subscribe</code> discovery targets.</p>"},{"location":"release_notes/2022/12/05/360-confluent-release/#remote-networks-may-now-be-used-for-operating-system-deployment","title":"Remote networks may now be used for operating system deployment","text":"<p>A new attribute <code>trusted.subnets</code> can be used to indicate remote subnets that are allowed to acquire a node API token when the deployment api is armed.  Additionally, a standalone network may redirect boot services to a remote confluent server by offering the IP of a confluent server as 'next-server', and also sending 'PXEClient' as the vendor client identifier. Alternatively, a number of URLs have been added to facilitate delegated HTTP boot (confluent-api/boot/by-mac/${mac:hexhyp}/ipxe or confluent-api/boot/by-uuid/${uuid}/ipxe).  In the latter case the DHCP server can offer an ipxe client that url and confluent will handle routing to the correct profile.  This is supported in select profiles, and currently requires confluent= in the profile.yaml indicated kernel arguments."},{"location":"release_notes/2022/12/05/360-confluent-release/#new-attribute-to-automatically-execute-nodeconfig-on-discovery","title":"New attribute to automatically execute nodeconfig on discovery","text":"<p>The new attribute <code>discovery.nodeconfig</code> allows specifying arguments to nodeconfig to automatically apply upon discovery of a new or replaced system.</p>"},{"location":"release_notes/2022/12/05/360-confluent-release/#new-ipv4_method-to-suppress-any-pxe-or-http-boot-offers","title":"New ipv4_method to suppress any PXE or HTTP boot offers","text":"<p>Setting <code>net.ipv4_method</code> to <code>firmwarenone</code> will now suppress any offer, even if the deployment situation indicates an offer should be made. This enables a fully externally managed DHCP configuration including boot filename for those that desire to externally manage it.</p>"},{"location":"release_notes/2022/12/05/360-confluent-release/#support-rebase-of-os-profiles-moving-forward","title":"Support rebase of OS profiles moving forward","text":"<p>When updating confluent, to date there has been no mechanism to help bring updates to existing OS profiles.  From 3.6 forward, the <code>osdeploy rebase</code> facility is added to enable an administrator to ask that the profile be analyzed for updated content from rpm, skipping any customized files.</p>"},{"location":"release_notes/2022/12/05/360-confluent-release/#add-support-for-custom-roles-on-bmc-devices","title":"Add support for custom roles on BMC devices","text":"<p>In addition to the defined roles for users on BMCs, support use of <code>custom.rolename</code> to enable user to use custom roles created on BMCs.</p>"},{"location":"release_notes/2022/12/05/360-confluent-release/#suse-15-confluent-is-moved-to-python-3","title":"Suse 15 confluent is moved to python 3","text":"<p>Migration has been implemented to take Python 2 data and convert to Python 3 on upgrade.  With this, Suse 15 has been changed to go to python 3 for new and upgraded installations.</p>"},{"location":"release_notes/2022/12/05/360-confluent-release/#support-for-systems-with-xclarity-controller-2-has-been-added","title":"Support for systems with xClarity Controller 2 has been added","text":"<p>New Lenovo servers featuring xClarity Controller 2 are now supported by discovery.</p>"},{"location":"release_notes/2022/12/05/360-confluent-release/#esxi-8-deployment-added","title":"ESXi 8 deployment added","text":"<p>Confluent can now deploy ESXi 8 systems</p>"},{"location":"release_notes/2022/12/05/360-confluent-release/#support-opening-consoles-in-standalone-windows","title":"Support opening consoles in standalone windows","text":"<p>The <code>nodeconsole</code> command now has a <code>-w</code> argument to request that the target nodes be opened in separate windows.</p>"},{"location":"release_notes/2022/12/05/360-confluent-release/#fixes-for-ipv4-free-deployment","title":"Fixes for IPv4-free deployment","text":"<p>Deployment was failing for some IPv6-only environments, this has been corrected to enable an IPv6 deployment to fully complete without an IPv4 address in place at all.</p>"},{"location":"release_notes/2022/12/05/360-confluent-release/#the-web-ui-port-forwarding-feature-is-now-anchored-from-port-3900","title":"The Web UI port forwarding feature is now anchored from port 3900","text":"<p>Previously, when doing port forwarding for a GUI client, a random port assigned by the OS was used. The behavior is changed to now go from port 3900 until the next available port, making firewall rules more reasonable for those that want to preserve the forwarding feature.  Firewall rules may now specify from port 3900 to some number based on how many forwards they anticipate needing.</p>"},{"location":"release_notes/2022/12/05/360-confluent-release/#package-repositories-may-now-be-available-while-modifying-a-diskless-image","title":"Package repositories may now be available while modifying a diskless image.","text":"<p>When running <code>imgutil exec</code>, an attempt is made to connect the build package repositories to the runtime environment. Point dnf to the configuration directory in /tmp/ to leverage the external repositories.</p>"},{"location":"release_notes/2022/12/05/360-confluent-release/#improve-memory-consumption-in-networks-with-large-numbers-of-misbehaving-ssdp-implementations","title":"Improve memory consumption in networks with large numbers of misbehaving SSDP implementations","text":"<p>Large numbers of poorly behaving SSDP implementations could induce memory pressure on confluent.  Improve confluent's SSDP snooping to perform better in such circumstances.</p>"},{"location":"release_notes/2023/01/17/362-confluent-release/","title":"3.6.2 Confluent release","text":"<p>3.6.2 of confluent is released, bringing a number of bug fixes:</p>"},{"location":"release_notes/2023/01/17/362-confluent-release/#restore-routed-media-based-deployment","title":"Restore routed media based deployment","text":"<p>Changes in 3.6.0 had inadvertently broken ability to deploy a routed system using remote media. This release restores that functionality</p>"},{"location":"release_notes/2023/01/17/362-confluent-release/#nfs-is-now-available-to-diskless-initramfs","title":"NFS is now available to diskless initramfs","text":"<p>This can be used by custom work to use nfs as a mechanism to access root filesystem content.</p>"},{"location":"release_notes/2023/01/17/362-confluent-release/#diskless-images-now-build-with-r8192-support","title":"Diskless images now build with r8192 support","text":"<p>This is a popular USB NIC and has been added to newly packed diskless images</p>"},{"location":"release_notes/2023/01/17/362-confluent-release/#suppress-dsa-host-key-errors-during-deployment","title":"Suppress DSA host key errors during deployment","text":"<p>Deployment would note inconsistencies with DSA key due to differences between install time and boot time SSH configuration.  The DSA key is no longer carried forward.</p>"},{"location":"release_notes/2023/01/17/362-confluent-release/#writing-output-of-nodefirmwarenodemedianodersync-has-been-improved","title":"Writing output of nodefirmware/nodemedia/nodersync has been improved","text":"<p>It dramatically reduces output put to screen and interacts better with a running terminal, avoiding forced clear screns</p>"},{"location":"release_notes/2023/01/17/362-confluent-release/#fix-imgutil-working-with-ported-diskless-images","title":"Fix imgutil working with ported diskless images","text":"<p>When a diskless image was carried from one environment to another, without the associated distribution assets, imgutil would have various problems.  imgutil will now properly degrade to allow better function with such images.</p>"},{"location":"release_notes/2023/01/17/362-confluent-release/#prevent-noderename-from-attempting-to-rename-multiple-nodes-to-the-same-target-name","title":"Prevent <code>noderename</code> from attempting to rename multiple nodes to the same target name","text":"<p>If misused, noderename could inadvertently cause loss of nodes by renaming every node to the same value, losing all but one of the source nodes.  This scenario is now blocked.</p>"},{"location":"release_notes/2023/01/17/362-confluent-release/#fix-syncfiles-and-add_local_repositories-in-ipv4-free-environments","title":"Fix syncfiles and add_local_repositories in IPv4-free environments","text":"<p>Confluent deployments in a pure IPv6 environment would formerly fail to correctly add local repositories and execute syncfiles.  These issues are addressed in 3.6.2.</p>"},{"location":"release_notes/2023/03/08/370-confluent-release/","title":"3.7.0 Confluent release","text":"<p>3.7.0 has been released with the following changes:</p>"},{"location":"release_notes/2023/03/08/370-confluent-release/#collective-members-may-be-invited-as-non-voting","title":"collective members may be invited as non-voting","text":"<p>collective invite may now be passed '-n' to have the invited member join as non-voting.  A non-voting collective member will neither contribute nor detract from quorum.  This permits indicating non-critical members to allow larger numbers of the collective to leave without issue.</p>"},{"location":"release_notes/2023/03/08/370-confluent-release/#suse-installer-output-restored-to-automatic-console","title":"SUSE installer output restored to automatic console","text":"<p>A change in SUSE had resulted in the automatic console failing to trigger text mode install when appropriate.  This has been changed and text install is now triggered on automatic text console detection</p>"},{"location":"release_notes/2023/03/08/370-confluent-release/#static-ipv6-configuration-of-bmcs","title":"Static IPv6 configuration of BMCs","text":"<p>Static IPv6 network configuration of redfish and IPMI BMCs has been added, visible in <code>nodeconfig</code></p>"},{"location":"release_notes/2023/03/08/370-confluent-release/#nodeinventory-can-now-gather-uuidserialmodel-information-to-confluent-attributes","title":"nodeinventory can now gather uuid/serial/model information to confluent attributes","text":"<p><code>nodeinventory -s</code> can be used to fill in attributes normally filled in by the discovery process.  This allows users who skip discovery and add nodes manually to use nodeinventory to gather the attributes for informational purposes and directing boot.</p>"},{"location":"release_notes/2023/03/08/370-confluent-release/#nodediscover-may-now-show-affluent-switches","title":"nodediscover may now show affluent switches","text":"<p>In conjunction with changes made to affluent 1.2.0, nodediscover list -t affluent-switch will now show ethernet switches, and what IPv6 and IPv4 addresses may be used to reach them</p>"},{"location":"release_notes/2023/03/08/370-confluent-release/#nodeeventlog-entry-count-and-timeframe","title":"nodeeventlog entry count and timeframe","text":"<p>The <code>nodeeventlog</code> command now has a <code>-l</code> option to request the specified number of most recent entries, or <code>-t</code> to request logs no older than a specified time.</p>"},{"location":"release_notes/2023/03/08/370-confluent-release/#nodeconsole-can-now-open-terminals-in-dedicated-windows","title":"nodeconsole can now open terminals in dedicated windows","text":"<p>The <code>nodeconsole</code> command now has the option <code>-w</code> to request windowed consoles.</p>"},{"location":"release_notes/2023/03/08/370-confluent-release/#network-configuration-management-can-now-deal-with-nic-renaming-through-postfirstboot-on-select-profiles","title":"Network configuration management can now deal with nic renaming through post/firstboot on select profiles","text":"<p>Before, when a post activity would result in a network device name change (e.g. OFED installation changing nVidia ethernet names), the network may have problems coming up.  Some profiles have added support for adapting the configuration prior to firstboot to compensate for the name change.</p>"},{"location":"release_notes/2023/03/08/370-confluent-release/#lenovo-thinksystem-v3-servers-are-officially-supported","title":"Lenovo ThinkSystem V3 servers are officially supported","text":"<p>The new generation of Lenovo ThinkSystem servers have been tested and support enhanced according to new capabilities</p>"},{"location":"release_notes/2023/08/14/380-confluent-release/","title":"3.8.0 Confluent release","text":"<p>3.8.0 has been released with the following changes:</p>"},{"location":"release_notes/2023/08/14/380-confluent-release/#improve-memory-usage-with-large-number-of-unreachable-nodes","title":"Improve memory usage with large number of unreachable nodes","text":"<p>Confluent memory usage over time was growing when trying to deal with unreachable nodes.  This has been improved.</p>"},{"location":"release_notes/2023/08/14/380-confluent-release/#various-improvements-to-ubuntu-deployment-support","title":"Various improvements to Ubuntu deployment support","text":"<p>The limited support for Ubuntu has been expanded</p>"},{"location":"release_notes/2023/08/14/380-confluent-release/#nodeconsole-t-will-now-reuse-existing-tmux-if-started-from-within-tmux","title":"nodeconsole -t will now reuse existing tmux if started from within tmux","text":"<p>This will more intelligently use a detected in-use tmux session.</p>"},{"location":"release_notes/2023/08/14/380-confluent-release/#add-nodesensors-for-cooltera-cdus","title":"Add nodesensors for Cooltera CDUs","text":"<p>Cooltera CDUs will now provide some data to nodesensors.</p>"},{"location":"release_notes/2023/08/14/380-confluent-release/#improve-collective-behaviors","title":"Improve collective behaviors","text":"<ul> <li>When a collective leader goes down, provide better recovery and better ongoing monitoring. </li> <li>non-voting members will no longer be promoted to the role of leader, aligning with likely treatment of non-voting members.</li> <li>Slow dispatch operations will no longer hang up an entire confluent instance</li> </ul>"},{"location":"release_notes/2023/08/14/380-confluent-release/#new-nodeapply-command","title":"New <code>nodeapply</code> command","text":"<p>The <code>nodeapply</code> command serves a similar role as <code>updatenode</code> did in xCAT: shorthand for a number of common operations.</p>"},{"location":"release_notes/2023/08/14/380-confluent-release/#support-to-dump-timestamped-logs-in-nodeconsole","title":"Support to dump timestamped logs in nodeconsole","text":"<p>The <code>nodeconsole</code> command adds the <code>-T</code> option to allow writing a log with in-line timestamps.</p>"},{"location":"release_notes/2023/08/14/380-confluent-release/#el9-is-now-supported-for-cloning","title":"EL9 is now supported for cloning","text":"<p>The command <code>imgutil capture</code> will now work on EL9 based nodes.</p>"},{"location":"release_notes/2023/08/14/380-confluent-release/#custom-roles-support","title":"Custom roles support","text":"<p>Custom roles may now be specified in /etc/confluent/authorization.yaml. The roles are defined in a way similar to <code>auth.py</code>.  This file must be consistent across a collective.</p>"},{"location":"release_notes/2023/08/14/380-confluent-release/#various-bug-fixes","title":"Various bug fixes","text":"<ul> <li>ProxyDHCP functionality is more robust in face of errored clients</li> <li>SLP functionality persists in face of misbehaving SLP responders</li> <li>Correct some misbehaviors on terminals in WebGUI (serialized operations, unrecognized functions)</li> <li>Improve ansible behavior when ansible python version differs from confluent</li> <li>Improve ansible behavior when a partial ansible inventory is provided</li> <li>Fix SSDP behavior in EL9 management nodes</li> </ul>"},{"location":"release_notes/2023/08/29/381-confluent-release/","title":"3.8.1 Confluent release","text":"<p>3.8.1 has been released with the following changes:</p>"},{"location":"release_notes/2023/08/29/381-confluent-release/#fix-hotplug-firmware-for-diskless-boot","title":"Fix hotplug firmware for diskless boot","text":"<p>Diskless boot had been using initramfs firmware for hotplug firmware, even after root filesystem became available. This has been fixed.</p>"},{"location":"release_notes/2023/08/29/381-confluent-release/#eaton-pdu-sensors","title":"Eaton PDU sensors","text":"<p>Some support for sensors on Eaton PDUs has been added</p>"},{"location":"release_notes/2023/08/29/381-confluent-release/#set-autoconnect-on-network-connections-configured-by-confignet","title":"Set autoconnect on network connections configured by confignet","text":"<p>Particularly additional interfaces are now more consistently configured to automatically come up.</p>"},{"location":"release_notes/2023/08/29/381-confluent-release/#nodelist-now-supports-custom-delimiting-of-node-list","title":"nodelist now supports custom delimiting of node list","text":"<p>See <code>nodelist -d</code> for details.</p>"},{"location":"release_notes/2023/08/29/381-confluent-release/#identity-deployment-enhancements-for-el7-ubuntu-2004-and-2204","title":"Identity deployment enhancements for EL7, Ubuntu 20.04 and 22.04,","text":"<p>Identity image based deployments for three platforms has been added.</p>"},{"location":"release_notes/2023/08/29/381-confluent-release/#support-multi-stage-plays-in-ansible-playbooks","title":"Support multi stage plays in ansible playbooks","text":"<p>The ansible support has been extended to support playbooks with multi-stage plays.</p>"},{"location":"release_notes/2023/10/19/390-confluent-release/","title":"3.9.0 Confluent release","text":"<p>3.9.0 has been released with the following changes:</p>"},{"location":"release_notes/2023/10/19/390-confluent-release/#add-cloning-of-ubuntu","title":"Add cloning of Ubuntu","text":"<p>Ubuntu installations may now be cloned</p>"},{"location":"release_notes/2023/10/19/390-confluent-release/#add-ubuntu-2204-diskless","title":"Add Ubuntu 22.04 diskless","text":"<p>Ubuntu 22.04 can now be diskless booted</p>"},{"location":"release_notes/2023/10/19/390-confluent-release/#add-missing-scripting-support-to-ubuntu-scripted-installation","title":"Add missing scripting support to Ubuntu scripted installation","text":"<p>Ubuntu scripted installation did not fully have pre.d, post.d, and firstboot.d.  Add these hooks for more consistent Ubuntu behavior.</p>"},{"location":"release_notes/2023/10/19/390-confluent-release/#add-netplan-support-to-confignet","title":"Add netplan support to confignet","text":"<p>Confignet can now correctly configure netplan in Ubuntu installations</p>"},{"location":"release_notes/2023/10/19/390-confluent-release/#add-openbmc-console-support","title":"Add openbmc console support","text":"<p>For OpenBMC based systems, a new console method 'openbmc' is provided for better performance and security when working with such platforms.</p>"},{"location":"release_notes/2023/10/19/390-confluent-release/#break-out-partitioning-and-package-list-for-el-scripted-profiles","title":"Break out partitioning and package list for EL scripted profiles","text":"<p>Make customization of EL profiles easier by having the partitioning and package list as separate files for new profiles.</p>"},{"location":"release_notes/2023/10/19/390-confluent-release/#nodeattrib-can-now-read-from-a-file","title":"<code>nodeattrib</code> can now read from a file","text":"<p>A nodeattrib batch file can now be specified by <code>nodeattrib -s</code></p>"},{"location":"release_notes/2023/10/19/390-confluent-release/#nodersync-can-now-interact-with-a-non-default-interface","title":"<code>nodersync</code> can now interact with a non-default interface","text":"<p>The <code>nodersync</code> command now has a <code>-s</code> switch consistent with <code>nodeping</code> and <code>nodeshell</code>.</p>"},{"location":"release_notes/2023/10/19/390-confluent-release/#fix-cloning-to-nvme-boot-devices","title":"Fix cloning to NVME boot devices","text":"<p>The cloning would fail when the target was NVME, this is corrected.</p>"},{"location":"release_notes/2023/10/19/390-confluent-release/#imgutil-now-has-non-interactive-operation","title":"imgutil now has non-interactive operation","text":"<p>There is now a <code>-y</code> argument to imgutil to avoid being prompted by zypper or dnf</p>"},{"location":"release_notes/2023/10/19/390-confluent-release/#improved-cooltera-cdu-sensor-behavior","title":"Improved Cooltera CDU sensor behavior","text":"<p>A broader range of firmware is now supported.</p>"},{"location":"release_notes/2023/10/19/390-confluent-release/#improve-imgutil-capture-warnings","title":"Improve imgutil capture warnings","text":"<p>Previously, a user would not be aware of missing parts of a clone until a test deployment. Now a number of key dependencies are checked and fail the capture if it is known the image would have challenges booting.</p>"},{"location":"release_notes/2023/10/19/390-confluent-release/#improved-discovery-performance-and-fixes","title":"Improved discovery performance and fixes.","text":"<p>Discovery activity for known nodes is reduced.  This particularly helps large systems with a collective. Also, a problem where discovery could be terminated due to a bad subscription has been fixed.</p>"},{"location":"release_notes/2023/10/19/390-confluent-release/#improved-collective-behavior","title":"Improved collective behavior","text":"<p>Collective startup uses far less resources in large clusters.  Collective members now skip scanning switches that are not relevant, per collective.managercandidates.  </p>"},{"location":"release_notes/2023/10/19/390-confluent-release/#more-graphical-terminal-support-in-stats","title":"More graphical terminal support in <code>stats</code>","text":"<p>Stats can now specify a terminal format in '-f'.  The default remains sixel, but <code>iterm</code> and <code>kitty</code> are now implemented:</p> <p></p> <p><code>kitty</code> is compatible with konsole, kitty, and wezterm and is the most recommended.  <code>iterm</code> may work in other terminals. <code>sixel</code> is the slowest and most likely to have glitches, but may work with some terminals that support neither iterm nor kitty.</p>"},{"location":"release_notes/2023/10/19/390-confluent-release/#improve-noderange-collation-in-collate","title":"Improve noderange collation in <code>collate</code>","text":"<p>Collate can now abbreviate numerical ranges and leverage bracket support to shorten the result.  For example: <code>grp[1:2,4],t3u[18:25,30],t4u[20:30],t5u[17:24,27:30]</code></p>"},{"location":"release_notes/2023/10/19/390-confluent-release/#mitigate-poor-dns-behavior","title":"Mitigate poor DNS behavior","text":"<p>Slow DNS behavior has long caused issues in confluent. Confluent now enacts an aggressive timeout and makes some formerly sequential name lookup activity concurrent.</p>"},{"location":"release_notes/2023/10/19/390-confluent-release/#confluent-now-has-server-side-rack-layout-api-call","title":"Confluent now has server side rack layout API call","text":"<p>API users now have a call that can more easily organize rack location information, <code>/noderange/[noderange]/layout</code>.</p>"},{"location":"release_notes/2023/10/19/390-confluent-release/#confluent-390-no-longer-has-support-for-rhel-7-as-a-management-node","title":"Confluent 3.9.0 no longer has support for RHEL 7 as a management node","text":"<p>Confluent 3.9.0 will no longer support RHEL 7.x as a management node. Managing nodes running RHEL 7 is still supported. </p>"},{"location":"release_notes/2023/11/17/392-confluent-release/","title":"3.9.2 Confluent release","text":"<p>3.9.2 has been released with the following changes:</p>"},{"location":"release_notes/2023/11/17/392-confluent-release/#nodedeploy-checking-improvement","title":"nodedeploy checking improvement","text":"<p>The <code>nodedeploy</code> command now checks the profile prior to issuing boot overrides or power control.</p>"},{"location":"release_notes/2023/11/17/392-confluent-release/#osdeploy-improvements","title":"osdeploy improvements","text":"<p>The <code>osdeploy</code> initialize command better handles different orders of invocation, eliminating unexpected dependencies in some cases and alerting in others.</p>"},{"location":"release_notes/2023/11/17/392-confluent-release/#expanded-confluent_selfcheck","title":"Expanded confluent_selfcheck","text":"<p>The <code>confluent_selfcheck</code> will now examine networking compatibility between deployment server and specified node.</p>"},{"location":"release_notes/2023/11/17/392-confluent-release/#normalized-sensors-in-api","title":"Normalized sensors in API","text":"<p>Select sensors (average CPU temperature, inlet temperature, overall power utilization) have been made normalized, striving to use industry standard mechanisms, with options for vendors to override and specify in a vendor specific way.</p>"},{"location":"release_notes/2023/11/17/392-confluent-release/#improved-error-reporting-for-syncfiles","title":"Improved error reporting for syncfiles","text":"<p>For issues such as skipping the automation keys, syncfiles will now present a more informative output.</p>"},{"location":"release_notes/2023/11/17/392-confluent-release/#confignet-now-uses-bond-instead-of-team-in-el-distributions","title":"confignet now uses bond instead of team in EL distributions","text":"<p>Following Red Hat guidance, the use of teams in new profiles is disused in favor of the traditional bond approach.</p>"},{"location":"release_notes/2023/11/17/392-confluent-release/#fix-imgutil-capture-with-ubuntu-installed-with-certain-snaps","title":"Fix <code>imgutil capture</code> with Ubuntu installed with certain snaps","text":"<p>Ubuntu cloning with certain snaps installed is fixed.</p>"},{"location":"release_notes/2023/11/17/392-confluent-release/#genesis-is-updated-to-be-centos-stream-9-based","title":"Genesis is updated to be CentOS Stream 9 based","text":"<p>A newer base for the Genesis environment is used.</p>"},{"location":"release_notes/2023/11/17/392-confluent-release/#fix-ubuntu-clone-deployment-to-nvme","title":"Fix Ubuntu clone deployment to NVMe.","text":"<p>Ubuntu is now able to successfully clone to NVMe drives</p>"},{"location":"release_notes/2024/02/13/393-confluent-release/","title":"3.9.3 Confluent release","text":"<p>3.9.3 has been released with the following changes:</p>"},{"location":"release_notes/2024/02/13/393-confluent-release/#update-onboarding-to-support-latest-xclarity-controller-firmware","title":"Update onboarding to support latest xClarity Controller firmware","text":"<p>Recent firmware has removed the ability to rename while any ssh or web sessions are open, adapt by ensuring we are not logged in via any other channel when renaming the user.</p>"},{"location":"release_notes/2024/02/13/393-confluent-release/#relax-restrictions-on-netboot-check-of-collectivecandidatemanagers","title":"Relax restrictions on netboot check of collective.candidatemanagers","text":"<p>If the candidate managers entry was not a valid noderange, it could cause silent failures. Fix this and support simple comma delimited names if it fails to be a noderange.</p>"},{"location":"release_notes/2024/02/13/393-confluent-release/#fix-nodeapply-operation-against-multiple-nodes","title":"Fix nodeapply operation against multiple nodes","text":"<p>nodeapply was erroneously running on a single node rather than each node in a noderange.</p>"},{"location":"release_notes/2024/02/13/393-confluent-release/#fix-lldp-data-when-switch-returns-incomplete-data","title":"Fix LLDP data when switch returns incomplete data.","text":"<p>Some LLDP data was incomplete, this scenario is now handled appropriately.</p>"},{"location":"release_notes/2024/02/13/393-confluent-release/#improve-vt-buffer-communication","title":"Improve VT Buffer communication","text":"<p>The VT buffer emulation component used in nodeconsole now has a faster communication channel with the larger confluent runtime. This should significantly improve performance during lots of console activity.</p>"},{"location":"release_notes/2024/02/13/393-confluent-release/#make-slp-scanning-more-robust","title":"Make SLP scanning more robust","text":"<p>SLP scanning was breaking in the face of partially disabled multicast/broadcast. This issue is fixed.</p>"},{"location":"release_notes/2024/02/13/393-confluent-release/#improve-collate-abbreviation","title":"Improve collate abbreviation","text":"<p>Some mistakes could be made in abbreviating noderange featuring complex names. This has been addressed.</p>"},{"location":"release_notes/2024/02/13/393-confluent-release/#filter-multipath-nvme-while-determining-install-disk","title":"Filter multipath nvme while determining install disk.","text":"<p>nvme devices may materialize path information, which confused the search for install disks. This is now accomodated.</p>"},{"location":"release_notes/2024/02/13/393-confluent-release/#improve-noderange-error-messages-on-certain-cases","title":"Improve noderange error messages on certain cases","text":"<p>Some noderange syntax errors had confusing error messages, and those cases have been given better messages.</p>"},{"location":"release_notes/2024/06/15/3100-confluent-release/","title":"3.10.0 Confluent release","text":"<p>3.10.0 has been released with the following changes:</p>"},{"location":"release_notes/2024/06/15/3100-confluent-release/#ubuntu-2404","title":"Ubuntu 24.04","text":"<p>Ubuntu 24.04 is now supported for deployment.</p>"},{"location":"release_notes/2024/06/15/3100-confluent-release/#a-new-nodebmcpassword-command-is-added","title":"A new <code>nodebmcpassword</code> command is added","text":"<p>This facilitates the process of cycling a BMC password</p>"},{"location":"release_notes/2024/06/15/3100-confluent-release/#a-new-l2traceroute-command-is-added","title":"A new <code>l2traceroute</code> command is added","text":"<p>This will walk LLDP provided neighbor data among switches to reflect a path between nodes.</p>"},{"location":"release_notes/2024/06/15/3100-confluent-release/#deployment-over-usb-attached-storage","title":"Deployment over USB attached storage","text":"<p>Red Hat and similar will now use media as install source if this is detected.</p>"},{"location":"release_notes/2024/06/15/3100-confluent-release/#improved-arm-support","title":"Improved ARM support","text":"<p>More ARM deployments will succeed, including Ubuntu</p>"},{"location":"release_notes/2024/06/15/3100-confluent-release/#nodeattrib-warnings-around-inheritence","title":"nodeattrib warnings around inheritence","text":"<p>As attribute inheritence and clearing/blanking is a common source of confusion, warnings are now added to let the user know that they are manipulating inheritence rather than evicting a value.</p>"},{"location":"release_notes/2024/06/15/3100-confluent-release/#pdu-and-enclosure-operations-are-now-concurrent","title":"PDU and Enclosure operations are now concurrent","text":"<p>Formerly, PDU and enclosure operations were serial, they are now parallel across PDUs and Chassis (though still serial within a PDU or Chassis)</p>"},{"location":"release_notes/2024/06/15/3100-confluent-release/#better-ssh-server-configuration","title":"Better ssh server configuration","text":"<p>In Red Hat 8 and 9, if sshd_config.d is detected, use that rather than modifying the global sshd_config file directly.</p>"},{"location":"release_notes/2024/06/15/3100-confluent-release/#improved-syncfiles-error-behavior","title":"Improved syncfiles error behavior","text":"<p>Syncfiles will now retry on error, and pause deployment, along with providing more useful feedback as to why the sync would be failing</p>"},{"location":"release_notes/2024/06/15/3100-confluent-release/#improved-pxe-support","title":"Improved PXE support","text":"<p>Some relay agents required option 82 be echoed back, these agents are now supported.  iPXE under aarch64 now receives filename directly in the DHCP offer.</p>"},{"location":"release_notes/2024/06/15/3100-confluent-release/#os-deployment-api-enhancements","title":"OS Deployment API enhancements","text":"<p>The API now supports querying an import as a dry run as well as customizing the distribution name and profile information returned under the /deployment/ api</p>"},{"location":"release_notes/2024/06/15/3100-confluent-release/#allow-dev-access-in-the-confluent-systemd-service","title":"Allow /dev access in the confluent systemd service","text":"<p>This prepares for fuse filesystem management under the confluent service.</p>"},{"location":"release_notes/2024/06/15/3100-confluent-release/#provide-api-for-helping-remote-system-access-bmcs-by-their-ip-address","title":"Provide API for helping remote system access BMCs by their IP address","text":"<p>Formerly, a caller could only retrieve the BMC by attribute name, or request a TCP port forward. This adds ability to management node to locally resolve and provide the calling client the IP address.</p>"},{"location":"release_notes/2024/06/15/3100-confluent-release/#rack-layout-information-added-to-api","title":"Rack layout information added to API","text":"<p>A client may now request server side resolution of rack layout, including rack rows, rack numbers, u locations, height, etc.</p>"},{"location":"release_notes/2024/06/15/3100-confluent-release/#numerous-bugfixes","title":"Numerous bugfixes","text":"<ul> <li>servicedata save checking now verifies ability to save file before beginning the servicedata process</li> <li>Diskless boot will have a static hostname set in more circumstances</li> <li>A fallback to UTC timezone has been added if the timezone cannot be detected</li> <li>Numerous fixes for IPv6-only usage</li> <li>Fix an issue where multipath nvme could confuse the install disk logic.</li> <li>When using {} in an attribute expression, an error is now raised rather than just silently dropping {}</li> <li>Better handling of syntax errors within [] in a noderange</li> <li>Fix collate mangling of leading whitespace </li> <li>Fix potential failure to acquire API token if a failure occurs during the exchange</li> <li>Fix firewall behavior in ESXi install to ensure that newer ESXi installations can succeed </li> <li>SLP passive detection is fixed, allowing autosense of SMM and IMM2s once again</li> <li>Disable lldpad during Red Hat installation to avoid network misbehaviors on some NICs</li> </ul>"},{"location":"release_notes/2024/08/27/3110-confluent-release/","title":"3.11.0 Confluent release","text":"<p>3.11.0 has been released with the following changes:</p>"},{"location":"release_notes/2024/08/27/3110-confluent-release/#ubuntu-repository-is-now-available","title":"Ubuntu repository is now available","text":"<p>An apt repository has been provided for Ubuntu 22.04 and Ubuntu 24.04 management servers</p>"},{"location":"release_notes/2024/08/27/3110-confluent-release/#enhanced-inventory-and-sensors-for-geistvertiv-pdus","title":"Enhanced inventory and sensors for Geist/Vertiv PDUs","text":"<p>Geist/Vertiv PDUs will now return more sensor and inventory data</p>"},{"location":"release_notes/2024/08/27/3110-confluent-release/#ubuntu-may-now-install-from-disk-rather-than-network","title":"Ubuntu may now install from disk rather than network","text":"<p>If Ubuntu install detects install media provided by a disk (e.g. virtual USB) it will use that as deployment source.</p>"},{"location":"release_notes/2024/08/27/3110-confluent-release/#ubuntu-install-now-implements-deploymentencryptboot","title":"Ubuntu install now implements deployment.encryptboot","text":"<p>An ubuntu install will now use systemd-cryptsetup to implement disk encryption, sealed to TPM.</p>"},{"location":"release_notes/2024/08/27/3110-confluent-release/#confluentdbutil-now-provides-natural-sort-for-more-values","title":"confluentdbutil now provides natural sort for more values","text":"<p>This produces more stable json content run to run.</p>"},{"location":"release_notes/2024/08/27/3110-confluent-release/#updates-to-discovery-for-modern-xcc-firmware","title":"Updates to discovery for modern XCC firmware","text":"<p>Certain restrictions on capability are accomodeated.</p>"},{"location":"release_notes/2024/08/27/3110-confluent-release/#imgutil-exec-environment-improvements","title":"imgutil exec environment improvements","text":"<p>Some oddities inside an exec are addressed. Specifically, /dev/pts and more normal looking root filesystem mount, particularly to satisfy a number of systemd utilities.</p>"},{"location":"release_notes/2024/08/27/3110-confluent-release/#add-recovery-key-support-for-encrypted-boot","title":"Add recovery key support for encrypted boot","text":"<p>If using encryptboot, a key may now be provided in /var/lib/confluent/private/os//pending/luks.key <p>If it exists, it will be used to encrypt the disk, allowing manual entry of the key if the TPM should become unavailable, to facilitate recovering the boot filesystem.</p>"},{"location":"release_notes/2024/08/27/3110-confluent-release/#preliminary-support-for-lenovo-v4-systems-featuring-xclarity-controller-3","title":"Preliminary support for Lenovo V4 systems featuring xClarity Controller 3","text":"<p>For xClarity controller 3, the recommended console.method is now openbmc and the recommended hardwaremanagement.method is redfish.</p> <p>Discovery support will detect and allow configuration of xClarity Controller 3 based systems.</p>"},{"location":"release_notes/2024/08/27/3110-confluent-release/#enhancements-to-redfish-method-support","title":"Enhancements to redfish method support","text":"<p>The redfish method now supports nodeconfig -r bmc, as well as adding nodeconfig -e support for Lenovo systems.</p>"},{"location":"release_notes/2024/08/27/3110-confluent-release/#confignet-extended-to-support-vlans-and-infiniband-pkeys","title":"Confignet extended to support VLANS and Infiniband PKEYs","text":"<p>The <code>net.vlan_id</code> attribute has been added and implemented for EL style distributions.  See the attribute documentation for details.</p>"},{"location":"release_notes/2024/08/27/3110-confluent-release/#added-confluentdbutil-merge-subcommand","title":"Added confluentdbutil merge subcommand","text":"<p>The confluentdbutil utility has gained a merge subcommand.  This allows adding nodes/groups from another confluent server, whether for merging multiple instances to one or preparing to make them a collective.</p>"},{"location":"release_notes/2024/08/27/3110-confluent-release/#implement-support-for-dhcp-relay-based-deployment","title":"Implement support for dhcp relay based deployment","text":"<p>A confluent server may now be the target of a DHCP relay agent, and conduct PXE based installation over that as a routed network. This also comes with fixes for other routed deployment behaviors.</p>"},{"location":"release_notes/2024/08/27/3110-confluent-release/#improved-dependency-handling","title":"Improved dependency handling","text":"<p>Packages now list versions to induce updates of related packages.</p>"},{"location":"release_notes/2024/08/27/3110-confluent-release/#plugin-for-management-of-enos-switch-has-been-added","title":"Plugin for management of enos switch has been added","text":"<p>Switches running the older ENOS platform can now be monitored</p>"},{"location":"release_notes/2024/08/27/3110-confluent-release/#numerous-bugfixes","title":"Numerous bugfixes","text":"<ul> <li>Fix for OpenBMC duplicate output on 'reopon'</li> <li>Fix for 'power status' in the affluent plugin</li> <li>Fix when root user has multiple ssh public keys during osdeploy initialize -u</li> <li>Fix for missing nodes during SLP and SSDP discovery snooping</li> <li>Improve performance during SLP rescan activity</li> <li>Fixes for Ubuntu diskless boot over infiniband</li> <li>Avoid undesired DHCP activity during static Ubuntu 24.04 deployment</li> <li>Fix firstboot with Ubuntu 22.04 and Ubuntu 24.04</li> <li>Fix untethered boot with Ubuntu diskless</li> <li>Add NTP and timezone data to Ubuntu installations</li> </ul>"},{"location":"release_notes/2025/01/06/3120-confluent-release/","title":"3.12.0 Confluent release","text":"<p>3.12.0 has been released with the following changes:</p>"},{"location":"release_notes/2025/01/06/3120-confluent-release/#support-for-discovery-of-lenovo-v4-systems-with-xcc3","title":"Support for discovery of Lenovo V4 systems with XCC3","text":"<p>The new generation of Lenovo servers are supported, recommended hardwaremanagement.method value of 'redfish' and console.method value of 'openbmc'.</p>"},{"location":"release_notes/2025/01/06/3120-confluent-release/#nodeidentify-now-implements-blink-for-lenovo-systems-with-ipmi","title":"<code>nodeidentify</code> now implements <code>blink</code> for Lenovo systems with IPMI","text":"<p>OEM extensions are used to add the ability despite not being in the standard.</p>"},{"location":"release_notes/2025/01/06/3120-confluent-release/#fix-host-based-authentication-with-suse-diskless","title":"Fix host based authentication with SUSE diskless","text":"<p>Non-root users may now do node to node ssh in SUSE diskless deployments</p>"},{"location":"release_notes/2025/01/06/3120-confluent-release/#fix-noderename-attribute-inheritance","title":"Fix noderename attribute inheritance","text":"<p>Executing <code>noderename</code> was failing to produce the correct attribute values based on node name, this has been corrected.</p>"},{"location":"release_notes/2025/01/06/3120-confluent-release/#add-nvent-pdu-support","title":"Add nVent PDU support","text":"<p>Basic PDU functionality for nVent PDUs has been implemented</p>"},{"location":"release_notes/2025/01/06/3120-confluent-release/#deployment-of-centos-stream-10-and-alma-linux-kitten-10","title":"Deployment of CentOS Stream 10 and Alma Linux Kitten 10","text":"<p>Support has been added for Stream 10/Kitten 10 as a deployment target.</p>"},{"location":"release_notes/2025/01/06/3120-confluent-release/#ability-to-deploy-el9-diskless-profiles-to-disk","title":"Ability to deploy EL9 \"diskless\" profiles to disk","text":"<p>If the profile adds <code>installtodisk</code> to the kernel arguments, it will now install the image to disk, rather than booting it from network.</p>"},{"location":"release_notes/2025/01/06/3120-confluent-release/#fix-nvme-install-support-for-some-configurations","title":"Fix NVMe install support for some configurations","text":"<p>Some NVMe configurations do not manifest a driver, now the 'nvm' subsystem is used as a criteria if no driver detected.</p>"},{"location":"release_notes/2025/01/06/3120-confluent-release/#implement-infiniband-bond-in-confignet","title":"Implement infiniband bond in confignet","text":"<p>Using IB interfaces in a bond is now properly implemented</p>"},{"location":"release_notes/2025/01/06/3120-confluent-release/#improve-ssh-to-localhost","title":"Improve ssh to localhost","text":"<p>localhost has been added as a principal and shosts/hosts.equiv to facilitate the common use case.  This should not pose any additional risk, given the nature of localhost.</p>"},{"location":"release_notes/2025/01/06/3120-confluent-release/#do-not-clear-an-already-off-node-in-nodeconsole","title":"Do not clear an already off node in <code>nodeconsole</code>","text":"<p>Some systems misreport their power state. This caused nodeconsole to insistently clear the screen with a reminder the target system is off.  It will now avoid doing so, and only clear it when it's newly \"off\".  This allows the user to interact with the console, though the initial message will still indicate that the system is off and buffer replay will not happen as a result.</p>"},{"location":"release_notes/2025/01/06/3120-confluent-release/#extend-discovery-to-cover-multi-nic-xccs","title":"Extend discovery to cover multi-nic XCCs","text":"<p>If an XCC has two NICs and is using the second interface during discovery, this is now handled.</p>"},{"location":"release_notes/2025/01/06/3120-confluent-release/#compatibility-with-el95","title":"Compatibility with EL9.5","text":"<p>EL 9.5 introduced some incompatibilities.  Confluent 3.12 has workarounds for dealing with the changes in name resolution associated with the 9.5 update.</p>"},{"location":"release_notes/2025/01/06/3120-confluent-release/#improved-network-setup-in-ubuntu-with-identity-image","title":"Improved network setup in Ubuntu with identity image","text":"<p>The network configuration step is repeated until success, rather than only making a single attempt.</p>"},{"location":"release_notes/2025/01/06/3120-confluent-release/#new-web-gui","title":"New Web GUI","text":""},{"location":"release_notes/2025/01/06/3120-confluent-release/#the-web-gui-now-honors-system-lightdark-theme-preference","title":"The web GUI now honors system light/dark theme preference","text":"<p>When you select a light or dark theme for your desktop, the new confluent GUI will attempt to accomodate that preference.</p>"},{"location":"release_notes/2025/01/06/3120-confluent-release/#import-os-images-through-a-browser","title":"Import OS images through a browser","text":"<p>The <code>browserfs</code> service is now available to facilitate live import through the browser without requiring a full upload up front.</p>"},{"location":"release_notes/2025/01/06/3120-confluent-release/#initiate-deployment-from-the-browser","title":"Initiate deployment from the browser","text":"<p>Deploying an OS to nodes can now be done from the browser.</p>"},{"location":"release_notes/2025/01/06/3120-confluent-release/#browser-based-node-discovery","title":"Browser based node discovery","text":""},{"location":"release_notes/2025/01/06/3120-confluent-release/#support-for-remote-video-for-select-systems","title":"Support for remote video for select systems","text":"<p>Support for OpenBMC based remote video has been added, including the V4 Lenovo systems using XCC3.</p> <p></p>"},{"location":"release_notes/2025/01/06/3120-confluent-release/#ability-to-perform-firmware-updates-added","title":"Ability to perform firmware updates added","text":"<p>The Web GUI can now execute firmware updates.</p>"},{"location":"release_notes/2025/01/06/3120-confluent-release/#passkey-support-has-been-added-where-available","title":"Passkey support has been added, where available","text":"<p>For management systems running EL9, passkey support has been added.</p>"},{"location":"release_notes/2025/01/06/3120-confluent-release/#new-rack-views","title":"New rack views","text":"<p>The traditional rack view has been re-implemented for more flexibility, and a 3D rack view has been implemented.</p> <p> </p>"},{"location":"release_notes/2025/01/16/3121-confluent-release/","title":"3.12.1 Confluent release","text":"<p>3.12.1 has been released with the following changes:</p>"},{"location":"release_notes/2025/01/16/3121-confluent-release/#the-3d-view-rendering-of-partial-enclosures-is-fixed","title":"The 3D view rendering of partial enclosures is fixed","text":""},{"location":"release_notes/2025/01/16/3121-confluent-release/#the-http-api-may-now-be-bound-to-a-unix-socket-instead-of-tcp","title":"The HTTP API may now be bound to a Unix socket instead of TCP","text":""},{"location":"release_notes/2025/01/16/3121-confluent-release/#support-is-added-for-ubuntu-2404-management-nodes","title":"Support is added for Ubuntu 24.04 management nodes","text":""},{"location":"release_notes/2025/01/16/3121-confluent-release/#various-added-functionality-for-lenovo-xcc3-systems-managed-by-redfish","title":"Various added functionality for Lenovo XCC3 systems managed by redfish","text":""},{"location":"release_notes/2025/02/05/3122-confluent-release/","title":"3.12.2 Confluent release","text":"<p>3.12.2 has been released with the following changes:</p>"},{"location":"release_notes/2025/02/05/3122-confluent-release/#the-3d-view-now-sorts-the-racks-in-a-row","title":"The 3D view now sorts the racks in a row","text":"<p>Previously, the 3D view failed to sort the rack consistently with the 2D view, this has been remedied</p>"},{"location":"release_notes/2025/02/05/3122-confluent-release/#improvements-have-been-made-for-xcc3-and-smm3-support","title":"Improvements have been made for XCC3 and SMM3 support","text":"<p>The XCC3 remote video is updated for newer firmware, and general support for SMM3 redfish has been implemented</p>"},{"location":"release_notes/2025/02/05/3122-confluent-release/#fix-bond-modes-in-confignet","title":"Fix bond modes in confignet","text":"<p>confignet has been updated to support more of the bond modes correctly. This change requires an <code>osdeploy rebase</code> to take effect.</p>"},{"location":"release_notes/2025/02/05/3122-confluent-release/#rack-view-updates-for-n1380-chassis","title":"Rack view updates for N1380 chassis","text":"<p>The rack views have been updated to support the vertical node orientation of the N1380 chassis</p>"},{"location":"release_notes/2025/02/05/3122-confluent-release/#implement-mechanism-to-filter-nics-for-dhcp-offers","title":"Implement mechanism to filter nics for DHCP offers","text":"<p>/etc/confluent/service.cfg may now describe NICs to not provide PXE over IPv4 answers.</p> <pre><code># cat /etc/confluent/service.cfg\n[netboot]\nignorenics=enp65s0f1np1,enp65s0f3np3\n</code></pre>"},{"location":"release_notes/2025/02/05/3122-confluent-release/#improvement-for-multiple-nics-connected-to-same-vlan","title":"Improvement for multiple NICs connected to same VLAN","text":"<p>Netboot offers are checked for 'wrong subnet' when subnets are crossed, avoiding sending an offer on the wrong nic when a better NIC also makes an offer.</p>"},{"location":"release_notes/2025/02/05/3122-confluent-release/#support-longer-profile-names","title":"Support longer profile names","text":"<p>If a profile name is longer than can fit in a DHCP offer, a shortening feature is provided. If updating, this will not function until the httpd service is restarted.</p>"},{"location":"release_notes/2025/02/13/3123-confluent-release/","title":"3.12.3 Confluent release","text":"<p>3.12.3 has been released with the following changes:</p>"},{"location":"release_notes/2025/02/13/3123-confluent-release/#fix-for-dhcp-relay-behavior","title":"Fix for DHCP relay behavior","text":"<p>A regression in the DHCP relay behavior has been addressed.</p>"},{"location":"release_notes/2025/02/13/3123-confluent-release/#enhanced-ssh-session-behavior-in-webgui","title":"Enhanced SSH session behavior in WebGUI","text":"<p>SSH sessions will now persist across switching console types and tab reload</p>"},{"location":"release_notes/2025/02/13/3123-confluent-release/#by-default-disable-selinux-in-el9-diskless-image-builds","title":"By default disable SELinux in EL9 diskless image builds","text":"<p>As of EL9.5, SELinux now attempts to load a policy if enabled, and this fails boot.</p>"},{"location":"release_notes/2025/02/13/3123-confluent-release/#recognize-attribute-aliases-when-clearing-attribs-using-nodeattrib","title":"Recognize attribute aliases when clearing attribs using <code>nodeattrib</code>","text":"<p>When using <code>nodeattrib -c</code>, attribute short names will now be recognized (e.g. 'bmc' being short for 'hardwaremanagement.manager')</p>"},{"location":"release_notes/2025/02/13/3123-confluent-release/#remote-media-fix","title":"Remote media fix","text":"<p>Corrected an issue where recent redfish performance enhancements would result in detach of virtual media when working with an xClarity Controller after some time</p>"},{"location":"release_notes/2025/02/13/3123-confluent-release/#more-fixes-for-xclarity-controller-version-3","title":"More fixes for xClarity Controller version 3","text":"<p>Improved inventory handling of Infiniband adapters, more comprehensive health check for this platform</p>"},{"location":"release_notes/2025/02/13/3123-confluent-release/#fix-performance-regression-for-xclarity-controller-2-and-earlier-with-redfish","title":"Fix performance regression for xClarity Controller 2 and earlier with redfish","text":"<p>The new sensor handling code dramatically reduced performance with xClarity 2 and earlier, those platforms are now omitted from the new sensor reading code.</p>"},{"location":"release_notes/2025/02/13/3123-confluent-release/#fix-for-rack-view-when-dealing-with-manually-specified-node-height","title":"Fix for rack view when dealing with manually specified node height","text":"<p>A regression in the new rackview is corrected for users that manually specify node height.</p>"},{"location":"troubleshooting/attributeexpressionstroubleshooting/","title":"Troubleshooting issues with nodeattribute expressions.","text":"<p>An expression will contain some directives wrapped in {} characters.</p> <p>When using nodeattrib substitution there might be the temptation to do substition of username and passwords which will not work. </p>"},{"location":"troubleshooting/attributeexpressionstroubleshooting/#example","title":"Example","text":"<p>when using noderun attribute expressions for bmcuser and bmcpass will not work, this is expected behavior.  <pre><code>noderun &lt;nodename&gt; ipmitool -I lanplus -U \"{bmcuser}\" -P {bmcpass} -H {bmc}\n</code></pre> <pre><code>Password:\nn1052: Error: Unable to establish IPMI v2 / RMCP+ session\n</code></pre></p> <p>The inability to use attribute expressions for passwords is expected behavior for security reasons. Allowing this functionality  would allow passwords and username to be echoed in plane text</p>"},{"location":"troubleshooting/confluentnodefirmwareupdatetroubleshooting/","title":"Troubleshooting issues with nodefirmware and firmware updates","text":""},{"location":"troubleshooting/confluentnodefirmwareupdatetroubleshooting/#known-issues","title":"Known issues:","text":"<ol> <li> <p>Updating the XCC backup firmware on Lenovo servers with nodefirmware may appear to succeed but updates the primary bank instead, when using the default *.zip file such as lnvgy_fw_xcc_qgx306n-1.00_anyos_comp.zip.</p> <p>This can be worked around by extracting the *.zip file and using the *.uxz payload file directly with nodefirmware: <pre><code># unzip lnvgy_fw_xcc_qgx306n-1.00_anyos_comp.zip\n# ls -1 *\n</code></pre></p> <p>index.json lnvgy_fw_xcc_qgx306n-1.00_anyos_comp.chg\\ lnvgy_fw_xcc_qgx306n-1.00_anyos_comp.html\\ lnvgy_fw_xcc_qgx306n-1.00_anyos_comp_index.json\\ lnvgy_fw_xcc_qgx306n-1.00_anyos_comp_inventory.json\\ lnvgy_fw_xcc_qgx306n-1.00_anyos_comp_signature.json\\ lnvgy_fw_xcc_qgx306n-1.00_anyos_comp.txt\\</p> <p>payloads:\\ lnvgy_fw_xcc_qgx306n-1.00_anyos_comp.uxz</p> <p>The *.uxz file under the payloads directory may then be used to update the XCC backup firmware in the usual fashion: <pre><code># nodefirmware &lt;nodename&gt; update payloads/lnvgy_fw_xcc_qgx306n-1.00_anyos_comp.uxz --backup\n</code></pre></p> </li> <li> <p>In some cases updating the XCC primary firmware with nodefirmware on Lenovo servers may fail with an error, such as below, when using the default *.zip file such as lnvgy_fw_xcc_qgx306n-1.00_anyos_comp.zip:</p> <p>Nodes had errors updating (\\)! \\: ('[{\"@odata.type\": \"#Message.v1_1_2.Message\", \"MessageId\": \"Update.1.0.VerificationFailed\", \"MessageSeverity\": \"Critical\", \"Message\": \"Verification of image \\'upload_file\\' at \\'Unknown\\' failed.\", \"Resolution\": \"None.\", \"MessageArgs\": [\"upload_file\", \"Unknown\"]}]',) <p>As in item 1. above, the problem can be worked around by extracting the *.uxz payload file from the *.zip package and using it directly: <pre><code>#nodefirmware &lt;nodename&gt; update payloads/lnvgy_fw_xcc_qgx306n-1.00_anyos_comp.uxz\n</code></pre></p> <li> <p>After updating XCC or UEFI firmware, the \u201cPending\u201d status may not show if the system is managed via Redfish. The update is in fact pending, but the status does not show. To get the status to show, change the management method to IPMI:     <pre><code># nodeattrib &lt;nodename&gt; hardwaremanagement.method=ipmi\n</code></pre></p> </li> <li> <p>nodefirmware may report an error on BMU type update when there is no actual error.     To confirm if the error is actually valid or there is no error. Monitor the update (the boot to BMU and boot back to previous state after firmware update is complete) and check the firmware level after the update. If the firmware is updated then ignore the nodefirmware error message.</p> </li> <li> <p>When doing a nodefirmware update on a BMU type update, nodefirmware will  return a pending status. This is actually the wrong state of the update as the update would be done and the firmware already applied. Reading the firmware should confirm that the update is already applied. </p> </li>"},{"location":"troubleshooting/confluentosdeployts/","title":"IPv6 configuration","text":"<p>Deployment interfaces must have IPv6 enabled, with at least an automatic fe80:: address.  Generally this is default network interface configuration.  IPv6 need only be enabled, it need not be given any address manually, by DHCP, or by route advertisements, the automatic fe80:: addresses suffice.</p>"},{"location":"troubleshooting/confluentosdeployts/#unable-to-import-media-after-aborting-with-control-c-or-an-error-being-encountered","title":"Unable to import media after aborting with control-C or an error being encountered","text":"<p>An attempt to import media after an error or abort may result in:</p> <pre><code>{u'errorcode': 500, u'error': u'Unexpected error - Media import already in progress for this media'}\n</code></pre> <p>In order to proceed, the older import activity must be stopped. This can be done by listing current import activity, and removing it using confetty:</p> <pre><code># osdeploy import CentOS-Stream-8-x86_64-20210118-dvd1.iso \n{'errorcode': 500, 'error': 'Unexpected error - Media import already in progress for this media'}\n# confetty show /deployment/importing\ncentos_stream-8.4-x86_64\n# confetty rm /deployment/importing/centos_stream-8.4-x86_64\nDeleted: deployment/importing/centos_stream-8.4-x86_64\n</code></pre>"},{"location":"troubleshooting/confluentosdeployts/#cant-ssh-from-the-management-node-to-a-managed-node-after-deployment-or-from-a-managed-node-to-another-managed-node-after-deployment","title":"Can't ssh from the management node to a managed node after deployment, or from a managed node to another managed node after deployment","text":"<p>If the ssh ca certificate is changed on the management node, then confluent needs to be updated with this by running \"osdeploy initialize -k\".  This will allow for ssh from the management node to the managed nodes to work.</p> <p>To make sure ssh from one confluent-deployed managed node to another works, after the ssh ca certificate is changed on the management node, if using image-based (versus separate kernel and initrd downloads) deployment, then the OS profile image needs to be updated with \"osdeploy updateboot \" prior to OS deployment."},{"location":"troubleshooting/confluentosdeployts/#cant-access-os-repos-from-managed-nodes-after-confluent-deployment","title":"Can't access OS repos from managed nodes after confluent deployment","text":"<p>The OS repo URLs are set to the specific profile used to perform the deployment with confluent on a managed node.  If that profile is moved, renamed, or deleted on the management node, then the managed node will not longer be able to access those repos.  This is different from how this was done with xCAT where different install profiles pointed to a common install source location (this actually is deduplicated in confluent as well, but the URLs on the managed nodes are specific to the deployment profile).</p>"},{"location":"troubleshooting/confluentosdeployts/#managed-node-may-hang-during-confluent-os-deployment","title":"Managed node may hang during confluent OS deployment","text":"<p>When performing OS deployment with confluent, the managed node may hang, for example at \"Started cancel waiting for multipath siblings of \" when deploying RHEL 8.3.  This can be caused by the collective.managercandidates nodattribute containing a management node that is not actually defined as a node in the confluent database.  Note that this has to be defined exactly as it appears in the \"collective show\" command output.  For example, if the management node is shown in \"collective show\" as \"mn.domain\" then that management node has to be defined with the nodename \"mn.domain\" in confluent, as opposed to just \"mn\"."},{"location":"troubleshooting/confluentosdeployts/#issues-with-ssh-within-a-cluster-after-adding-an-additional-collective-member","title":"Issues with SSH within a cluster after adding an additional collective member","text":"<p>After adding a collective member, it is necessary to run <code>nodeapply -k &lt;noderange&gt;</code> on existing nodes, as well as <code>osdeploy initialize -k</code> on existing collective members after setting up SSH on the new collective member.</p>"},{"location":"troubleshooting/confluentosdeployts/#regenerating-ssh-host-certificates","title":"Regenerating SSH host certificates","text":"<p>If there is a requiremennt to regenerate SSH keys after installation and new certificates are needed, this can be addressed by running <code>nodeapply &lt;noderange&gt; -k</code></p>"},{"location":"troubleshooting/confluentosdeployts/#unable-to-ssh-from-one-managed-node-to-another-on-an-interface-which-has-a-dns-hostname-that-doesnt-match-the-confluent-nodename","title":"Unable to ssh from one managed node to another on an interface which has a DNS hostname that doesn't match the confluent nodename","text":"<p>In some cases ssh from one managed node to another will fail with the following error:</p> <pre><code>Certificate invalid: name is not a listed principal\n</code></pre> <p>This can occur if the net..hostname nodeattribute is not set properly on the managed nodes, and can occur if there was a non-existing managed node so that the ssh configuration on the already existing managed nodes couldn't setup for those nodes at that time.  The ssh configuration for those existing nodes would not be fixed on deployment of the new managed nodes, even if the net..hostname was set correctly on addition and deployment of the new managed node.  To address this, the following script should be run on each managed node that should be able to ssh without a password prompt to others on the interface with a DNS hostname that doesn't match the confluetn nodename: <p>This can be addressed by running `nodeapply -k '"},{"location":"troubleshooting/confluentosdeployts/#confluent-os-profile-updates-are-not-automatically-applied-on-confluent-updates","title":"Confluent OS profile updates are not automatically applied on confluent updates","text":"<p>The default confluent profiles for OSes (e.g. RHEL 8.4, SLE 15.3, etc., including genesis) do occasionally get updates as part of a confluent update.  However, these aren't applied automatically.  To opt into updates, run</p> <pre><code>osdeploy rebase &lt;profile name&gt;\n</code></pre> <p>Note this will try to preserve customization, but heavy customization may make files incompatible.</p>"},{"location":"troubleshooting/confluentosdeployts/#confluent-does-not-support-secure-boot-with-pxe","title":"Confluent does not support secure boot with PXE.","text":"<p>The ipxe boot loader that confluent uses in not signed, because of this an attempt to do secure boot with PXE will result in a secure boot violation. To do a network boot using confluent with secure boot enabled either http or https boot must be used. </p>"},{"location":"troubleshooting/confluentosdeployts/#kvm-virtual-machines-immediately-fail-to-netboot-when-using-uefi-firmware-with-confluent","title":"KVM virtual machines immediately fail to netboot when using UEFI firmware with confluent","text":"<p>This is due to iPXE not being compatible with secureboot.  For now, disable secureboot when using UEFI with KVM virtualization, since the KVM firmware does not support HTTP boot.</p>"},{"location":"troubleshooting/confluentosdeployts/#system-gets-non-desired-ip-address-when-being-deployed-or-booting-genesis","title":"System gets non-desired IP address when being deployed or booting genesis","text":"<p>One possible reason for this to occur is if the net.\\&lt;inteface name&gt;.hostname and net.\\&lt;interface name&gt;.ipv4_address nodeattributes for a node are defined, and the network configuration of the confluent server and network are such that there more than one set of net.\\&lt;interface name&gt;.hostname and net.\\&lt;interface name&gt;.ipv4_address settings that could match a particular L2 network.  In this case which of the net.\\&lt;interface name&gt;.* settings would be applied to the boot interface on the netbooting node may not be consistent from boot to boot.</p> <p>A scenario in which multiple net.\\&lt;interface name&gt;.hostname and net.\\&lt;interface name&gt;.ipv4_address nodeattributes would be set up this way would be if the XCC on a Lenovo server is configured with the XCC in shared NIC mode, and the interface of the XCC setup on the same L2 network as the NIC the XCC is sharing with, but with the XCC set to use a different IP subnet as the NIC being shared with the XCC.  One reason to set these values would be so that the \"confluent2hosts\" command can be used with the \"-a\" switch to populate /etc/hosts with the information from the nodeattributes.  However, this can be done as follows instead (once the hardwaremanagement.manager nodeattribute is defined):</p> <pre><code>confluent2hosts compute -n {node}-&lt;suffix&gt; -i {hardwaremanagement.manager}\n</code></pre> <p>In this way the net.\\&lt;interface name&gt;.hostname and net.\\&lt;interface name&gt;.ipv4_address nodeattributes don't have to be defined, leaving only one set of net.\\&lt;interface name&gt;.hostname and net.\\&lt;interface name&gt;.ipv4_address nodeattributes that match the network configuration for the L2 network that the managed node(s) is/are booting from, eliminating the ambiguity and ensuring that the netbooting nodes get the right address on each boot.</p>"},{"location":"troubleshooting/confluentupdatesles/","title":"Troubleshooting issue with updating confluent on SLES 15","text":""},{"location":"troubleshooting/confluentupdatesles/#known-issue","title":"Known Issue:","text":"<ol> <li> <p>Updating confluent version 3.5 or less to confluent version 3.6.2 on SLES 15 may fail and show a message such as below:</p> <p>There is an update candidate for 'confluent_client' from vendor 'Lenovo', while the current vendor is 'Jarrod Johnson jjohnson2@lenovo.com'.</p> </li> <li> <p>Solution:</p> <p>Run the zypper up command with --allow-vendor-change option specified: <pre><code># zypper up --allow-vendor-change\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/nodeshelltroubleshooting/","title":"Confluent nodeshell and apt-get command","text":""},{"location":"troubleshooting/nodeshelltroubleshooting/#running-the-apt-get-install-command-can-be-interactive-and-so-not-suited-for-running-through-confluent-nodeshell-command","title":"Running the <code>apt-get install</code> command can be interactive and so not suited for running through Confluent <code>nodeshell</code> command.","text":"<p>Here is an example of a command that requires interaction and the failure output.  <pre><code>[root@n790 ~]# nodeshell bf3 \"apt-get install net-tools\" | collate\nn1812: debconf: unable to initialize frontend: Dialog\nn1812: debconf: (TERM is not set, so the dialog frontend is not usable.)\nn1812: debconf: falling back to frontend: Readline\nn1812: debconf: unable to initialize frontend: Readline\nn1812: debconf: (This frontend requires a controlling tty.)\nn1812: debconf: falling back to frontend: Teletype\nn1812: dpkg-preconfigure: unable to re-open stdin:\n</code></pre></p> <p>Modifying the <code>nodeshell</code> command to have the DEBIAN_FRONTENT set to noninteractive will fix this issue</p> <p><code>[root@n790 ~]# nodeshell bf3 \"DEBIAN_FRONTEND=noninteractive apt-get -y install net-tools\" | collate</code></p>"},{"location":"troubleshooting/xcatosdeploymentts/","title":"xCAT OS deployment or diskless image boot fails with message regarding ib=dhcp","text":"<p>The ib=dhcp kernel command line argument is added by default to the bootloader configuration files on the xCAT management server at /tftpboot/xcat/xnba/nodes/* .  When a kernel command line paramer is set to set the ip= argument more explicitly, for example using bootparams.addkcmdline for boot over IB, then the ip=dhcp argument in the kernel command line arguments in the bootloader configuration file is superfluous and can cause problems.  To work-around this error the \"ip=dhcp\" entry in the bootloader configuration file should be removed.  Note, this will have to be re-done, after performing nodeset."},{"location":"troubleshooting/xcatosdeploymentts/#after-creating-an-xcat-extreme-cluster-administration-toolkit-stateless-image-of-sles-152-and-deploying-it-ssh-connections-to-the-booted-sles-152-image-fail","title":"After creating an xCAT (Extreme Cluster Administration Toolkit) stateless image of SLES 15.2 and deploying it, SSH connections to the booted SLES 15.2 image fail","text":"<p>This presumes the creation of an xCAT stateless image via the process described at</p> <p>https://sourceforge.net/p/xcat/wiki/Building_a_Stateless_Image_of_a_Different_Architecture_or_OS_Old/ </p> <p>and will reference that process.                                </p> <p>In order to work around the described issue, the sshd service must be manually configured to start automatically when the stateless image is deployed. This is accomplished by using the <code>chroot</code> command to enter the image as an environment on the server where it was created.                                    </p> <p>Presuming that the image has been created in the <code>/imagebuild</code> directory on the build server, the image may be entered as a running environment using the following commands from the Linux command prompt:                                                 </p> <ol> <li> <p>To use the build server's OS environment to enable the image environment:                                          </p> <pre><code>for i in dev sys proc; do mount -o bind /$i /imagebuild/rootimg/$i ; done\n</code></pre> </li> <li> <p>To enter the image environment:                             </p> <pre><code>chroot /imagebuild/rootimg\n</code></pre> </li> <li> <p>To configure the sshd service to start after deployment:    </p> <pre><code>chkconfig sshd on\n</code></pre> </li> <li> <p>To exit the image environment:                             </p> <pre><code>exit\n</code></pre> </li> <li> <p>IMPORTANT - umount the build server environment from the image:                                                     </p> <pre><code>for i in dev sys proc; do umount /imagebuild/rootimg/$i ; done\n</code></pre> <p><code>/dev</code> will occasionally report that it is busy. If this happens, do</p> <pre><code>umount -l /imagebuild/rootimg/dev\n</code></pre> <p>Confirm success by running the <code>mount</code> command and make sure nothing is mounted under <code>/imagebuild/rootimg</code> </p> </li> <li> <p>Proceed with the process step \"Copy the local genimage output to the correct location on the Management Node:\"    </p> </li> </ol> <p> Note, this is due to the xCAT genimage application failing to set the sshd service to start automatically during stateless image creation of SLES 15.2.  As a result, the image is not reachable via SSH after deployment.  Configuring the sshd service to start using the workaround procedure restores SSH access to the image on deployment.       </p>"},{"location":"user_reference/attributeexpressions/","title":"Attribute Expressions","text":"<p>In confluent, any attribute may either be a straightforward value, or an expression to generate the value.</p> <p>An expression will contain some directives wrapped in '{}' characters.  Within {} are a number of potential substitute values and operations.</p> <p>The most common operation is to extract a number from the nodename.  These values are available as n1, n2, etc.  So for example attributes for a node named b1o2r3u4 would have {n1} as 1, {n2} as 2, {n3} as 3, and {n4} as 4.  Additionally, {n0} is special as representing the last number in a name, so in the b1o2r3u4 example, {n0} would be 4.</p> <p>Frequently a value derives from a number in the node name, but must undergo a transform to be useful.  As an example, if we have a scheme where nodes are numbered n1-n512, and they are arranged 1-42 in rack1, 43-84 in rack2, and so forth, it is convenient to perform arithmetic on the extracted number.  Here is an example of codifying the above scheme, and setting the u to the remainder:</p> <pre><code>location.rack=rack{(n1-1)/42+1}\nlocation.u={(n1-1)%42+1}\n</code></pre> <p>Note how text may be mixed into expressions, only data within {} will receive special treatment. Here we also had to adjust by subtracting 1 and adding it back to make the math work as expected.</p> <p>It is sometimes the case that the number must be formatted a different way, either specifying 0 padding or converting to hexadecimal.  This can be done by a number of operators at the end to indicate formatting changes.</p> <pre><code>{n1:02x} - Zero pad to two decimal places, and convert to hexadecimal, as might be used for generating MAC addresses\n{n1:x} - Hexadecimal without padding, as may be used in a generated IPv6 address\n{n1:X} - Uppercase hexadecimal\n{n1:02d} - Zero pad a normal numeric representation of the number.\n</code></pre> <p>Another common element to pull into an expression is the node name in whole:</p> <pre><code>hardwaremanagement.manager={nodename}-imm\n</code></pre> <p>Additionally other attributes may be pulled in:</p> <pre><code>net.switchport={location.u}\n</code></pre> <p>Multiple expressions are permissible within a single attribute:</p> <pre><code>hardwaremanagement.manager={nodename}-{hardwaremanagement.method}\n</code></pre> <p>A note to developers: in general the API layer will automatically recognize a generic set attribute to string with expression syntax and import it as an expression.  For example, submitting the following JSON:</p> <pre><code>{ 'location.rack': '{n1}' }\n</code></pre> <p>Will auto-detect {n1} as an expression and assign it normally.  If wanting to set that value verbatim, it can either be escaped by doubling the {} or by explicitly declaring it as a value:</p> <pre><code>{ 'location.rack': '{% raw %}{{n1}}{% endraw %}' }\n\n{ 'location.rack': { 'value': '{n1}' } }\n</code></pre>"},{"location":"user_reference/centosdeploy/","title":"OS Deployment Notes for CentOS","text":"<p>When deploying CentOS, the default behavior is to have the CentOS internet repositories available.  If it is desired to not receive updates from CentOS' internet site, create a postscript to execute one of the following commands:</p> <p>Disable the repositories (requires yum-utils package to be installed):</p> <pre><code>yum-config-manager --disable CentOS-*\n</code></pre> <p>If yum-utils is not available, the repositories may instead be removed:</p> <pre><code>rm /etc/yum.repos.d/CentOS-*repo\n</code></pre> <p>If executing genimage multiple times, it may be required to delete the image between runs. This is due to certain assumptions that, among other things, could erase /etc/passwd without recreating the pertinent accounts.</p>"},{"location":"user_reference/chainedsmmdiscovery/","title":"Discovery with chained ThinkSystem D2 enclosures","text":"<p>The ThinkSystem D2 enclosure (which houses SD530 servers) has a variant of System Management Module (SMM) that supports chaining enclosures together.  For the usual discovery flow in confluent, it is not obvious how this should work.  </p> <p>There are two strategies.  The first is more resilient and easier, but requires confluent 1.8.0 together with SMM firmware 1.04.</p> <p>The other works with older chained SMM firmware, but requires nodes to attempt PXE boot.</p>"},{"location":"user_reference/chainedsmmdiscovery/#fully-out-of-band-discovery","title":"Fully out of band discovery","text":"<ul> <li>The Ethernet switch must have LLDP enabled.</li> <li>Confirm that you have confluent version 1.8.0, and that all SMMs will at   least have firmware 1.04.</li> <li>Set the <code>net.switch</code> and <code>net.switchport</code> attributes only on the SMM directly connected to a switch.</li> <li>For other SMMs, set <code>enclosure.extends</code> attribute to a directly connected adjacent SMM.  For example, with   three SMMs, smm1 would have <code>net</code> attributes to describe connecting to switch, smm2 would have    <code>enclosure.extends==smm1</code>, and smm3 would have <code>enclosure.extends==smm2</code></li> <li>It is not required to have <code>net</code> attributes defined for any of the nodes.</li> <li>Discovery proceeds normally in accordance with the general documentation of   discovery here.</li> </ul>"},{"location":"user_reference/chainedsmmdiscovery/#pxe-driven-discovery","title":"PXE Driven Discovery","text":"<p>If using older SMM firmware in a chain, or else wanting to drive discovery from the node network side rather than the SMM side, the method with PXE may be used.</p> <ul> <li>Do not set any switch attributes for any SMM (verify by running <code>nodeattrib &lt;noderange&gt; net</code> and seeing they are all empty).</li> <li>Ensure that all the nodes have correct enclosure.manager/enclosure.bay attribute (<code>nodeattrib &lt;noderange&gt; enclosure</code>)</li> <li>All the nodes must have either <code>permissive,pxe</code> or <code>open</code> as the <code>discovery.policy</code> attribute (<code>nodeattrib &lt;noderange&gt; discovery.policy=permissive,pxe</code>) to enable   PXE discovery.  The recommended discovery policy is <code>permissive,pxe</code> for a balance of automatic behavior versus security.</li> <li>Provide net.*.switch/net.*.switchport values for the ethernet ports that will PXE boot of the SD530 servers.</li> <li>Induce the servers to PXE boot (generally by turning them on).  The PXE attempt need not be able to succeed, but confluent must be on the same VLAN (regardless of IP configuration).</li> </ul> <p>The procedure will then automatically proceed as follows:</p> <ul> <li>As a matter of course, <code>nodediscover list</code> should show <code>lenovo-xcc</code> devices, without identifying them.</li> <li>When the server transmits the DHCPDISCOVER packet to initiate PXE, confluent will detect the packet and begin a search of the ethernet switches for a match.</li> <li>When the node identity is determined, it will commit to that node attribute the UUID of the node as the attribute <code>id.uuid</code>.</li> <li>If there is a detected XCC that matches the uuid, that XCC gets discovered and configured appropriately, and the SMM is enabled, if not previously enabled.</li> <li>When an SMM is detected that has a UUID that matches the enclosure UUID indicated by a relevant XCC, that SMM is discovered and autoconfigured.</li> </ul> <p>Trobuleshooting:</p> <ul> <li>If no lenovo-smm devices are appearing, it may be worth doing <code>nodediscover rescan</code>.</li> <li>It may be the case that the XCCs were otherwise configured without enabling SMM.  To rediscover XCC to try to enable SMM, <code>nodeattrib &lt;noderange&gt; pubkeys.tls_hardwaremanager=</code>.  This will induce the SMM enablement process that is normally part of XCC discovery.</li> <li>If using older SD530 firmware, confluent may not be able to link XCC and SMM.  If this is the case, XCC discovery sholud still work and enable XCC firmware updates to proceed.</li> </ul>"},{"location":"user_reference/confluentconfignotes/","title":"Confluent configuration and troubleshooting notes for Lenovo hardware","text":""},{"location":"user_reference/confluentconfignotes/#sn2010-rack-view","title":"SN2010 rack view","text":"<p>The SN2010* Ethernet switch is half-wide and 1U tall, but also doesn\u2019t install into an enclosure.  Due to this, it doesn\u2019t fit into the normal way of setting up location information for the confluent nodeattributes for it so that it would be displayed in the rack view in the confluent GUI.  In order to get it to be displayed properly in the confluent GUI rack view (when there are two installed side-by-side in the same rack unit), a dummy enclosure node has to be setup, and the two switches in that rack unit have to have their enclosure node attributes set to that enclosure.  The enclosure.bay nodeattribute should be set to 1 for the switch installed to the left (as seen from the front of the rack) and to 2 for the switch installed in the right.  The following is an example of the confluent nodeattributes to set for this:</p> <pre><code>mn10:/opt/exerciser # nodeattrib switch90\nswitch90: discovery.policy: open\nswitch90: dns.domain: cluster1.e1350\nswitch90: enclosure.bay: 1\nswitch90: enclosure.manager: switch9091\nswitch90: groups: everything\n\nmn10:/opt/exerciser # nodeattrib switch91\nswitch91: discovery.policy: open\nswitch91: dns.domain: cluster1.e1350\nswitch91: enclosure.bay: 2\nswitch91: enclosure.manager: switch9091\nswitch91: groups: everything\n\nmn10:/opt/exerciser # nodeattrib switch9091\nswitch9091: discovery.policy: open\nswitch9091: dns.domain: cluster1.e1350\nswitch9091: groups: everything\nswitch9091: location.height: 1\nswitch9091: location.rack: CR021.2\nswitch9091: location.row: 2\nswitch9091: location.u: 41\n</code></pre> <p>And here is the result of this in the confluent rack view:</p> <p></p>"},{"location":"user_reference/confluentconfignotes/#nodeconfig-may-take-a-few-seconds-to-reflect-submitted-changes","title":"nodeconfig may take a few seconds to reflect submitted changes","text":"<p>When using nodeconfig to submit a system configuration change, it exits when the target device has accepted the change. However, an endpoint may take some time to activate the change so that it will be visible when showing the configuration.</p>"},{"location":"user_reference/confluentconfignotes/#ipv6-and-domain-name-resolution-may-not-work-for-redfish-managed-nodes","title":"IPv6 and Domain name resolution may not work for Redfish-managed nodes","text":"<p>For SR655 nodes configured to be managed with Redfish, IPv6 and domain name resolution may not work for node attribute values. For example, it is known to not work in the case of the <code>hardwaremanagement.manager</code> attribute. In the example below:</p> <pre><code># nodeattrib node1 hardwaremanagement.method\nnode1:  hardwaremanagement.method:  redfish\n\n# nodeattrib node1 hardwaremanagement.manager\nnode1:  hardwaremanagement.manager: node1-mgt\n</code></pre> <p>Or:</p> <pre><code># nodeattrib node1 hardwaremanagement.manager\nnode1:  hardwaremanagement.manager: fe80::3ee1:a1ff:fec7:e627%eno1\n</code></pre> <p>The domain name <code>node1-mgt1</code> will trigger an error on the target TSM, causing the following error:</p> <pre><code># nodefirmware node1\n\nTraceback (most recent call last):\n  File \"/opt/confluent/bin/nodefirmware\", line 166, in &lt;module&gt;\n    show_firmware(session)\n  File \"/opt/confluent/bin/nodefirmware\", line 152, in show_firmware\n    exitcode |= client.printerror(res['databynode'][node], node)\n  File \"/opt/confluent/lib/python/confluent/client.py\", line 116, in printerror\n    sys.stderr.write('{0}: {1}\\n'.format(node, res['error']))\nUnicodeEncodeError: 'ascii' codec can't encode characters in position 175-254: ordinal not in range(128)\n</code></pre> <p>Or IPv6 will trigger this error:</p> <pre><code> # nodefirmware node1\n node1: Unexpected Error: /redfish/v1/Managers/Self:&lt;pre style=\"font-size:12px; font-family:monospace; color:#8B0000;\"&gt;[web.lua] Error in RequestHandler, thread: 0x758476e8 is dead.\n</code></pre> <p>There are two options to address the problem:</p> <ul> <li>Use a literal IP address for the node attribute in question:</li> </ul> <pre><code>    nodeattrib node1 hardwaremanagement.manager=10.19.67.83\n    node1:  10.19.67.13\n</code></pre> <ul> <li>Switch to IPMI management:</li> </ul> <pre><code>    nodeattrib node1 hardwaremanagement.method=ipmi\n    node1:  ipmi\n</code></pre>"},{"location":"user_reference/confluentconfignotes/#redfish-management-method-not-supported-on-fpc-smm-or-smm2","title":"Redfish management method not supported on FPC, SMM or SMM2","text":"<p>The Lenovo FPC, SMM and SMM2 chassis management modules do not support redfish--use ipmi for their hardwaremanagement methods.</p>"},{"location":"user_reference/confluentconfignotes/#xcat-genesis-does-not-include-support-for-intel-e810-or-mellanox-connectx-6-lx-ethernet-adapters","title":"xCAT genesis does not include support for Intel E810 or Mellanox ConnectX-6 Lx Ethernet adapters","text":"<p>xCAT genesis does not currently include support for Intel E810 or Mellanox ConnectX-6 Lx Ethernet adapters--confluent genesis should be used instead.</p>"},{"location":"user_reference/confluentconfignotes/#occasional-privilege-errors-from-confluent-commands","title":"Occasional privilege errors from confluent commands","text":"<p>Occasionally confluent out-of-band management commands may report \"Error: Insufficient privilege level or firmware firewall\".  If this occurs, the hardwaremanagement.manager node attribute on the node that the problem occurred on to something other than the actual IP or hostname of the hardwaremanagement manager for that node, and then set it back to the previous (correct) value.  After that the problem should no longer occur.</p>"},{"location":"user_reference/confluentconfignotes/#xcc-web-interfaces-opened-from-the-confluent-web-gui-may-spontaneously-log-out-when-entering-the-firwmare-update-page","title":"XCC web interfaces opened from the confluent web GUI may spontaneously log out when entering the firwmare update page","text":"<p>When opening the XCC web interface for more than one XCC from the confluent GUI web interface, so that the URLs for those XCC web interfaces are forwarded ports with the same IP (the IP of the confluent server), when entering the firmware update page on the XCC web interface, the XCC web interface on one or more of the XCC web interfaces opened this way may spontaneously log out.  To work around this issue, either open just one XCC web interface through the confluent GUI or setup a socks proxy to access the XCC web interfaces (or access them directly if the network configuration allows for this) so that each XCC web interface is accessed through a separate IP address.</p>"},{"location":"user_reference/confluentconfignotes/#lenovo-thinksystem-generation-v3-systems-may-spontaneously-reboot-when-using-the-nodefirmware-command-for-certain-firmware-updates","title":"Lenovo ThinkSystem generation \"V3\" systems may spontaneously reboot when using the nodefirmware command for certain firmware updates","text":"<p>Certain firmware update packages for Lenovo V3 systems are performed in a system built-in Linux environment that the system has to reboot into to do the update, even though the update is initiated out-of-band.  In these cases the node will spontaneously and without warning reboot into that environment.  To avoid improper shutdown of a running OS on the system, the system can be turned off before running the nodefirmware command for these types of updates.</p>"},{"location":"user_reference/confluentdiscovery/","title":"Node discovery and autoconfiguration with confluent","text":"<p>Note that discovery is an optional portion of confluent that may be skipped. Further, the discovery process does not require that the user log into the target and do anything like change password or network configuration. It is designed to specifically help when a target has not been configured at all and implements everything it needs to automatically change password and adjust networking as required. If you do adjust networking, user, and password through other means, then this portion may be skipped.</p> <p>While it is possible to use confluent by directly specifying the pre-configured  address, username, and password of a BMC, confluent also has the ability to  automate the deployment of configuration of Integrated Management Module and xClarity Controller devices without knowing the addresses ahead of time. It is even possible to avoid ever provisioning a viable network configuration at all.</p> <p>For optimal results, the confluent server should be on the same network as the management ports.  Additionally, it is more robust if IPv6 is enabled, though no IPv6 addresses need to be configured (it can use the fe80::  addresseses that appear by default on network interfaces). Also, the general default configuration for Lenovo servers is to only have the dedicated management port enabled. As such, servers wired such that only the interface available to the OS is available will be unlikely to complete this procedure.</p> <p>With the node definition complete, discovery can now be approached in one of two ways, automatic or manual.  The automatic approach is good for environments that have a well defined map of servers or server enclosures to ethernet switch ports, and the manual approach is good for scenarios like matching nodes up by serial numbers or having a small number of servers to configure or replacing a server or system board.</p>"},{"location":"user_reference/confluentdiscovery/#following-the-discovery-process","title":"Following the discovery process","text":"<p>Discovery can be followed by examining <code>/var/log/confluent/events</code>, Using <code>tail -f</code> for example:</p> <pre><code>May 25 16:28:25 {\"info\": \"Discovered n1 (XCC)\"} \nMay 25 16:28:37 {\"info\": \"Discovered n4 (XCC)\"}\nMay 25 16:28:38 {\"info\": \"Discovered n2 (XCC)\"} \nMay 25 16:28:40 {\"info\": \"Discovered n3 (XCC)\"}\n</code></pre>"},{"location":"user_reference/confluentdiscovery/#manual-discovery","title":"Manual discovery","text":"<p>Manual discovery provides a more interactive approach to deploying systems. This can also aid in debugging attempts at setting up automatic discovery, or repairing the discovery state of a few miswired or misconfigured systems in an otherwise automatic, but locked down discovery configuration.</p>"},{"location":"user_reference/confluentdiscovery/#using-the-nodediscover-command","title":"Using the <code>nodediscover</code> command","text":"<p>The <code>nodediscover</code> command is intended to aid in exploring available endpoints that may be discovered:</p> <pre><code># nodediscover  list\n           Node|          Model|         Serial|                                UUID|      Mac Address|        Type|                            Current IP Addresses\n---------------|---------------|---------------|------------------------------------|-----------------|------------|------------------------------------------------\n               |        5462AC1|        E2YV870|15e55533-8f37-300f-a5f6-f4954e1fec66|08:94:ef:00:f5:0d| lenovo-imm2|      10.240.38.58,fe80::a94:efff:fe00:f50d%eth0\n               |        8869AC1|        J110D40|89fdadbc-3d0c-11e6-b9fa-0894ef1b4ed7|08:94:ef:1b:4e:dc| lenovo-imm2|     10.240.38.193,fe80::a94:efff:fe1b:4edc%eth0\n               |        8869AC1|        J10VEKX|8be3221c-49e9-11e6-a963-0894ef222409|08:94:ef:22:24:0e| lenovo-imm2|                                   10.240.37.211\n               |               |               |4980a05b-f2ec-e611-86af-c3c7e68a9e00|08:94:ef:3b:de:d4|  lenovo-smm|       172.30.33.1,fe80::a94:efff:fe3b:ded4%eth1\n               |     7X07CTO1WW|       J30002HG|2b44751a-3481-11e7-bc9b-0a94ef3c8185|08:94:ef:3c:81:83|  lenovo-xcc|    172.30.254.244,fe80::a94:efff:fe3c:8183%eth1\n               |     7X2104Z000|       DEV00003|cc099cf9-f9a5-11e6-84c7-db06face6280|08:94:ef:3f:e0:af|  lenovo-xcc|    172.30.254.193,fe80::a94:efff:fe3f:e0af%eth1\n               |     7X2104Z000|       DEV00001|00b043c4-029b-11e7-ad41-c7027e3a94d2|08:94:ef:40:87:21|  lenovo-xcc|    172.30.254.251,fe80::a94:efff:fe40:8721%eth1\n               |     7X2104Z000|       DEV00002|78b36a03-0356-11e7-9043-a5a2961a0e5c|08:94:ef:40:89:31|  lenovo-xcc|       172.30.34.2,fe80::a94:efff:fe40:8931%eth1\n               |     7X2104Z000|       DEV00001|00b043c4-029b-11e7-ad41-c7027e3a94d2|08:94:ef:40:8a:96|  pxe-client|                                                \n               |     7X2104Z000|       DEV00004|58962b3d-088b-11e7-b8b8-9e59e5cf61db|08:94:ef:41:01:b5|  lenovo-xcc|        172.30.92.4,fe80::a94:efff:fe41:1b5%eth1\n               |     7X18CTO1WW|       J30007Y4|4dce618a-82f5-11e7-badd-0a94ef4a132f|08:94:ef:4a:13:2d|  lenovo-xcc|       172.30.78.2,fe80::a94:efff:fe4a:132d%eth1\n</code></pre> <p>Note in the above we have examples of Integrated Management Module 2, xClarity Controller, D2 SMM, and PXE client.  Also note that it recognizes the relationship between a pxe-client and the managing xcc.</p>"},{"location":"user_reference/confluentdiscovery/#assigning-from-a-spreadsheet-csv-based-on-serial-numbers","title":"Assigning from a spreadsheet (.csv) based on serial numbers","text":"<p>One common scenario is having a spreadsheet of desired configuration together with the serial number.  To do this, create a csv file with a header describing the available data followed by records to import.  For example:</p> <pre><code>node,serial,bmc,bmcuser,bmcpass\nr1,J30002HG,172.30.30.1,admin,Passw0rd12\nr2,J30007Y4,172.30.30.2,admin,Passw0rd12\n</code></pre> <p>Then use the <code>nodediscover assign</code> command to deploy the requested configuration:</p> <pre><code># nodediscover assign -i serials.csv \nDefined r1\nDiscovered r1\nDefined r2\nDiscovered r2\n</code></pre> <p>At this point, the systems are ready for management:</p> <pre><code># nodehealth everything|collate\n====================================\nr1,r2\n====================================\nok\n</code></pre>"},{"location":"user_reference/confluentdiscovery/#using-networkingmacs","title":"Using <code>/networking/macs</code>","text":"<p>If there are switches defined, their mac address tables can be navigated through the <code>/networking/macs</code> interface.  Using the mac address example from above:</p> <pre><code>/ -&gt; show /networking/macs/by-mac/40-f2-e9-b9-10-1d\npossiblenode=\"\"\nmac: 40:f2:e9:b9:10:1d\nports=[\n {\n  \"switch\": \"r8e1\", \n  \"macsonport\": 1, \n  \"port\": \"Ethernet28\"\n }\n]\n/ -&gt;\n</code></pre> <p>You may also use this to get the mac addresses from an ethernet port, if you do not know the mac address:</p> <pre><code>/ -&gt; show /networking/macs/by-switch/r8e1/by-port/Ethernet13/by-mac\n08-94-ef-41-01-f0\n</code></pre> <p>This can help provide additional context to a mac address observed in <code>nodediscover</code> or to debug or help formulate a way to use automatic discovery.</p>"},{"location":"user_reference/confluentdiscovery/#automatic-discovery","title":"Automatic discovery","text":"<p>As a prelude for automatic discovery, first define the node using the values that it should be configured with at the end, regardless of current configuration. For example, we will define 42 nodes (<code>n1</code> through <code>n42</code>) that upon completion should have an xClarity Controller with the address '10.2.3.(node number)', and the username and  password of your choice.  Here we will use a group to hold the patterns and just define the nodes with just the single group membership:</p> <pre><code>nodegroupdefine compute bmc=10.2.3.{n1}\nnodegroupattrib compute -p bmcuser bmcpass\nnodegroupattrib compute net.&lt;name&gt;.ipv4_gateway=&lt;IP of gateway for xClarity Controllers to use)\nnodedefine n1-n42 groups=compute\n</code></pre> <p>This will interactively prompt for username and password. This is the desired username and password not necessarily the current. If the devices are at factory default, then they will be changed automatically to the password and username given.</p> <p>If no value is provided for <code>bmc</code> it will not try to program IPv4 addresses, but will instead collect fe80:: ip addresses.  This is useful to have confluent commands work regardless of IPv4 misconfiguration, but may not be obvious to all users.  Setting net.. ipv4_gateway setting is optional, but needs to be set for the IPV4 gateway setting of the xClarity Controller to be configured by confluent on discovery of the xClarity Controller.  The  value is arbitrary, but it is useful to use the name of a network, e.g., \"mgt\" for a management network (IPv4 subnet).  The value of this IPv4 gateway address is determined not by this network name in confluent, but by whether it matches in the same IP subnet of the IPv4 addresses set for the \"bmc\" value.  Note that the subnet  is typically automatically determined based on the subnet of the interface on the management node for this network (the subnet mask of this inteface is leveraged to determine the subnet mask of the bmc.) If using xCAT's <code>makeconfluentcfg</code> and you want to mandate IPv4 configuration rather than configuring confluent directly, ensure that <code>ipmi. bmc</code> is set on nodes in xCAT. This is normally a natural thing to do, but might not be done for certain nodes like ThinkSystem D2 SMMs."},{"location":"user_reference/confluentdiscovery/#selecting-a-discovery-policy","title":"Selecting a discovery policy","text":"<p>The first step is to opt into an automatic discovery policy.  There are three policies:</p> <ul> <li><code>manual</code> disables automatic discovery, this is the default behavior.</li> <li><code>open</code> will always allow a candidate node to be configured as the actual node, regardless of current certificate.  This allows the most hands off automation in the face of actions such as replacing a server or system board, but if an attacker can spoof the mac address of a valid management device they could use the discovery process to get the username and password intended for a management device as well as install a certificate of their choosing as trusted to be that node.</li> <li><code>permissive</code> will allow automatic discovery only if the proposed node identity does not already have a known certificate (in the nodes <code>pubkeys.tls_hardwaremanager</code> attribute), allowing new nodes to fill out defined nodes not yet bound to an actual node.  Note that nodes that are defined, but not yet discovered are a risk to the same scenario as described in <code>open</code></li> <li><code>pxe</code> allows free replacement of PXE related data (mac addresses and UUID), but will not allow free replacement of secure data.  This can be a standalone policy or combined with permissive by using the value <code>permissive,pxe</code>.  This allows relaxing the policy to <code>open</code>, but only for PXE data, which cannot have meaningful protections to automate.  In this mode, ethernet mac addresses will be collected to a <code>net.&lt;n&gt;.hwaddr</code> field if the corresponding <code>net.&lt;n&gt;.bootable</code> is true.</li> </ul> <p>The policy can be defined on a per node basis or by group.  Here we will select <code>permissive,pxe</code> across the board, and enable PXE collection to a field called <code>net.pxe.hwaddr</code>:</p> <pre><code>nodegroupattrib everything discovery.policy=permissive,pxe net.pxe.bootable=true\n</code></pre> <p>The policy can be changed on the fly, if for example you want <code>open</code> or <code>permissive</code> during initial deployment, but change to <code>manual</code> after systems are up:</p> <pre><code>nodegroupattrib everything discovery.policy=manual\n</code></pre> <p>If you have a system that needs to be replaced, you can use manual discovery as documented in the previous section or temporarily override the policy for just the one node:</p> <pre><code>nodeattrib n3 discovery.policy=open\n</code></pre>"},{"location":"user_reference/confluentdiscovery/#defining-required-attributes-on-the-nodes-enclosure-managers-and-switches","title":"Defining required attributes on the nodes, enclosure managers, and switches","text":"<p>In this example, we have 4 ThinkSystem SD530 servers in a D2 enclosure.  That enclosure  has a management port plugged into a switch called <code>r8e1</code> on port 8.</p> <p>First we set the enclosure attributes on the nodes:</p> <pre><code>nodeattrib n1-n4 enclosure.manager=enc1 enclosure.bay={n1}\n</code></pre> <p>We then make sure the enclosure manager is a node and configure the location of it's switch port:</p> <pre><code>nodeattrib enc1 net.switchport=8 net.switch=r8e1\n</code></pre> <p>By default, confluent will assume it can use SNMPv1/v2c, community string <code>public</code> to communicate with the switch.  To use a different SNMP community string, make sure the ethernet switch is defined as a node and set a value for secret.snmpcommunity:</p> <pre><code>nodedefine r8e1 secret.snmpcommunity=otherpublic\n</code></pre> <p>Or for SNMPv3, use secret.hardwaremanagementuser and hardwaremanagementpassword:</p> <pre><code>nodedefine r8e1 secret.hardwaremanagementuser=snmpv3user secret.hardwaremanagementpassword=snmpv3password\n</code></pre> <p>In the event of a rackmount system, such as the Thinksystem SD650, simply assign net attributes directly to the node:</p> <pre><code>nodeattrib n1-n20 net.switchport={n1} net.switch=r8e1\n</code></pre>"},{"location":"user_reference/confluentdiscovery/#resetting-automatic-discovery-process-for-nodes","title":"Resetting automatic discovery process for nodes","text":"<p>If the wiring or configuration of set of nodes was incorrect at time of discovery, the situation can be corrected by doing manual discovery or by resetting the discovery process for the nodes.  Resetting the automatic discovery process can be done by clearing the <code>pubkeys.tls_hardwaremanager</code> attribute:</p> <pre><code>nodeattrib n1-n4 pubkeys.tls_hardwaremanager=\n</code></pre> <p>This can be combined with a configuration change.  For example, if we decide that the previous scheme of 10.2.3.{n1} really should be 10.2.4.{n1}:</p> <pre><code>nodeattrib n1-n42 hardwaremanagement.manager=10.2.4.{n1} pubkeys.tls_hardwaremanager=\n</code></pre> <p>This will change the desired ip address and reset the discovery process for those nodes to apply the requested change.</p>"},{"location":"user_reference/confluentrackview/","title":"Setting up the confluent rackview","text":"<p>Confluent's web interface offers a rackview for rackmount and enclosure based systems. It can show where nodes are located in racks and organize the racks into rows in the datacenter:</p> <p></p>"},{"location":"user_reference/confluentrackview/#setting-up-a-rackmount-system","title":"Setting up a rackmount system","text":"<p>The three attributes relevant for a node are location.rack, location.u, and location.row. Ensure all three are set to a value. For multi-u systems, specify the lowest U. It is optional, though recommended to also set location.height, as that will help the rackview draw more quickly than auto-detecting the component height.</p> <p>Here is an example of how o2 was defined:</p> <pre><code># nodeattrib o2 location.rack location.u location.row location.height\no2: location.height: 2\no2: location.rack: 4\no2: location.row: 1\no2: location.u: 32\n</code></pre>"},{"location":"user_reference/confluentrackview/#setting-up-an-enclosuredense-system","title":"Setting up an enclosure/dense system","text":"<p>The recommended attributes to set are for the enclosure to be specified according to the same instructions as a rackmount system above. The servers themselves should not have any location information, as their location will be defined by enclosure.manager and enclosure.bay within the chassis definition.</p> <p>Here is an example of a server (d1) inside an enclosure (smm1):</p> <pre><code># nodeattrib d1 enclosure.manager enclosure.bay\nd1: enclosure.bay: 1\nd1: enclosure.manager: smm1\n# nodeattrib smm1 location.rack location.u location.row location.height\nsmm1: location.height: 2\nsmm1: location.rack: 4\nsmm1: location.row: 1\nsmm1: location.u: 35\n</code></pre>"},{"location":"user_reference/el7deploy/","title":"OS Deployment Notes for RedHat Enterprise Linux 7","text":"<p>If executing genimage multiple times, it may be required to delete the image between runs. This is due to certain assumptions that, among other things, could erase /etc/passwd without recreating the pertinent accounts.</p>"},{"location":"user_reference/node_attributes/","title":"Node Attributes","text":"<p>Confluent uses a variety of attributes on nodes to be configured and provide information.  The currently recognized attributes are as follows.</p>"},{"location":"user_reference/node_attributes/#collective","title":"collective","text":""},{"location":"user_reference/node_attributes/#collectivemanager","title":"collective.manager","text":"When in collective mode, the member of the collective currently considered to be responsible for this node.  At a future date, this may be modified automatically if another attribute indicates candidate managers, either for high availability or load balancing purposes."},{"location":"user_reference/node_attributes/#collectivemanagercandidates","title":"collective.managercandidates","text":"A noderange of nodes permitted to be a manager for the node. This controls failover and deployment.  If not defined, all managers may deploy and no automatic failover will be performed. Using this requires that collective members be defined as nodes for noderange expansion"},{"location":"user_reference/node_attributes/#console","title":"console","text":""},{"location":"user_reference/node_attributes/#consolelogging","title":"console.logging","text":"Indicate logging level to apply to console. Defaults to \"full\". Valid values: <code>full</code>, <code>memory</code>, <code>interactive</code>, <code>none</code>"},{"location":"user_reference/node_attributes/#consolemethod","title":"console.method","text":"Indicate the method used to access the console of the managed node.  If not specified, then console is disabled.  \"ipmi\" should be specified for most systems if console is desired. Valid values: <code>ssh</code>, <code>ipmi</code>, <code>openbmc</code>, <code>tsmsol</code>, <code>vcenter</code>"},{"location":"user_reference/node_attributes/#crypted","title":"crypted","text":""},{"location":"user_reference/node_attributes/#cryptedgrubpassword","title":"crypted.grubpassword","text":"Password required to modify grub behavior at boot"},{"location":"user_reference/node_attributes/#cryptedrootpassword","title":"crypted.rootpassword","text":"The password of the local root password. This is stored as a non-recoverable hash. If unspecified and confluent is used to deploy, then login at console using password will be impossible and only key based login can work for root."},{"location":"user_reference/node_attributes/#cryptedselfapikey","title":"crypted.selfapikey","text":"Crypt of api key for self api requests by node"},{"location":"user_reference/node_attributes/#deployment","title":"deployment","text":""},{"location":"user_reference/node_attributes/#deploymentapiarmed","title":"deployment.apiarmed","text":"Indicates whether the node authentication token interface is armed.  If set to once, it will grant only the next request. If set to continuous, will allow many requests, which greatly reduces security, particularly when connected to untrusted networks. Should not be set unless an OS deployment is pending on the node. Generally this is not directly modified, but is modified by the \"nodedeploy\" command Valid values: <code>once</code>, <code>continuous</code>, <code></code>"},{"location":"user_reference/node_attributes/#deploymentencryptboot","title":"deployment.encryptboot","text":"Specify a strategy for encrypting the volume. Support for this setting is currently only enabled for RedHat 8 and CentOS 8 profiles. If blank or unset, no encryption is done. If set to \"tpm2\" then the OS will freely decrypt so long as the same Trusted Platform Module is available to decrypt the volume. Note that versions earlier than 8.2 may malfunction at boot time if this feature is attempted, depending on configuration. Valid values: <code>tpm2</code>, <code>none</code>, <code></code>"},{"location":"user_reference/node_attributes/#deploymentlock","title":"deployment.lock","text":"Indicates whether deployment actions should be impeded. If locked, it indicates that a pending profile should not be applied. If \"autolock\", then locked will be set when current pending deployment completes.  Valid values: <code>autolock</code>, <code>locked</code>"},{"location":"user_reference/node_attributes/#deploymentpendingprofile","title":"deployment.pendingprofile","text":"An OS profile that is pending deployment.  This indicates to the network boot subsystem what should be offered when a potential network boot request comes in"},{"location":"user_reference/node_attributes/#deploymentprofile","title":"deployment.profile","text":"The profile that has most recently reported completion of deployment. Note that an image may opt to leave itself both current and pending, for example a stateless profile would be both after first boot."},{"location":"user_reference/node_attributes/#deploymentsealedapikey","title":"deployment.sealedapikey","text":"This attribute is used by some images to save a sealed version of a node apikey, so that a subsequent run with same TPM2 will use the TPM2 to protect the API key rather than local network verification. If this is set, then an api key request will receive this if the api key grant is not armed"},{"location":"user_reference/node_attributes/#deploymentstagedprofile","title":"deployment.stagedprofile","text":"A profile that has been staged, but is awaiting final boot to be activated. This allows an OS profile to remove itself from netboot without indicating completion to any watcher."},{"location":"user_reference/node_attributes/#deploymentstate","title":"deployment.state","text":"Profiles may push more specific state, for example, it may set the state to \"failed\" or \"succeded\""},{"location":"user_reference/node_attributes/#deploymentstate_detail","title":"deployment.state_detail","text":"Detailed state information as reported by an OS profile, when available"},{"location":"user_reference/node_attributes/#deploymentuseinsecureprotocols","title":"deployment.useinsecureprotocols","text":"What phase(s) of boot are permitted to use insecure protocols (TFTP and HTTP without TLS.  By default, only HTTPS is used.  However this is not compatible with most firmware in most scenarios.  Using \"firmware\" as the setting will still use HTTPS after the initial download, though be aware that a successful attack during the firmware phase will negate future TLS protections.  The value \"always\" will result in tftp/http being used for most of the deployment.  The value \"never\" will allow HTTPS only. Note that Ubuntu will still use HTTP without TLS for a phase of the installation process. Valid values: <code>always</code>, <code>firmware</code>, <code>never</code>"},{"location":"user_reference/node_attributes/#discovery","title":"discovery","text":""},{"location":"user_reference/node_attributes/#discoverynodeconfig","title":"discovery.nodeconfig","text":"Set of nodeconfig arguments to apply after automatic discovery"},{"location":"user_reference/node_attributes/#discoverypasswordrules","title":"discovery.passwordrules","text":"Any specified rules shall be configured on the BMC upon discovery.  \"expiration=no,loginfailures=no,complexity=no,reuse=no\" would disable password expiration, login failures triggering a lockout, password complexity requirements,and any restrictions around reusing an old password. Valid values: <code>expiration</code>, <code>loginfailures</code>, <code>complexity</code>, <code>reuse</code>"},{"location":"user_reference/node_attributes/#discoverypolicy","title":"discovery.policy","text":"Policy to use for auto-configuration of discovered and identified nodes. \"manual\" means nodes are detected, but not autoconfigured until a user approves. \"permissive\" indicates to allow discovery, so long as the node has no existing public key. \"open\" allows discovery even if a known public key is already stored Valid values: <code>manual</code>, <code>permissive</code>, <code>pxe</code>, <code>open</code>, <code>verified</code>"},{"location":"user_reference/node_attributes/#dns","title":"dns","text":""},{"location":"user_reference/node_attributes/#dnsdomain","title":"dns.domain","text":"DNS Domain searched by default by the system"},{"location":"user_reference/node_attributes/#dnsservers","title":"dns.servers","text":"DNS Server or servers to provide to node"},{"location":"user_reference/node_attributes/#enclosure","title":"enclosure","text":""},{"location":"user_reference/node_attributes/#enclosurebay","title":"enclosure.bay","text":"The bay in the enclosure, if any"},{"location":"user_reference/node_attributes/#enclosureextends","title":"enclosure.extends","text":"When using an extendable enclosure, this is the node representing the manager that is one closer to the uplink."},{"location":"user_reference/node_attributes/#enclosuremanager","title":"enclosure.manager","text":"The management device for this node's chassis"},{"location":"user_reference/node_attributes/#groups","title":"groups","text":""},{"location":"user_reference/node_attributes/#groups_1","title":"groups","text":"List of static groups for which this node is considered a member"},{"location":"user_reference/node_attributes/#hardwaremanagement","title":"hardwaremanagement","text":""},{"location":"user_reference/node_attributes/#hardwaremanagementmanager","title":"hardwaremanagement.manager","text":"The management address dedicated to this node.  This is the address of, for example, the Lenovo XCC.  It may optionally include / CIDR suffix to indicate subnet length, which is autodetected by default where possible."},{"location":"user_reference/node_attributes/#hardwaremanagementmethod","title":"hardwaremanagement.method","text":"The method used to perform operations such as power control, get sensor data, get inventory, and so on. ipmi is used if not specified."},{"location":"user_reference/node_attributes/#hardwaremanagementport","title":"hardwaremanagement.port","text":"The port the BMC should be configured to connect to network.  This only has effect during deployment and does not apply to out of band discovery. Example values include \"ocp\", \"ml2\", \"lom\" (for on board port shared with operating system), or \"dedicated\""},{"location":"user_reference/node_attributes/#hardwaremanagementvlan","title":"hardwaremanagement.vlan","text":"The vlan that a BMC should be configured to tag traffic. This only has effect during OS deployment and does not apply to out of band discovery."},{"location":"user_reference/node_attributes/#id","title":"id","text":""},{"location":"user_reference/node_attributes/#idmodel","title":"id.model","text":"The model number of a node.  In scenarios where there is both a name and a model number, it is generally expected that this would be the generally more specific model number."},{"location":"user_reference/node_attributes/#idserial","title":"id.serial","text":"The manufacturer serial number of node"},{"location":"user_reference/node_attributes/#iduuid","title":"id.uuid","text":"The UUID of the node as presented in DMI."},{"location":"user_reference/node_attributes/#info","title":"info","text":""},{"location":"user_reference/node_attributes/#infonote","title":"info.note","text":"A field used for administrators to make arbitrary notations about nodes. This is meant entirely for human use and not programmatic use, so it can be freeform text data without concern for issues in how the server will process it."},{"location":"user_reference/node_attributes/#location","title":"location","text":""},{"location":"user_reference/node_attributes/#locationheight","title":"location.height","text":"Height in RU of the system (defaults to query the systems)"},{"location":"user_reference/node_attributes/#locationrack","title":"location.rack","text":"Rack number of the rack the node is in"},{"location":"user_reference/node_attributes/#locationroom","title":"location.room","text":"Room description for the node"},{"location":"user_reference/node_attributes/#locationrow","title":"location.row","text":"Row description for the rack the node is in"},{"location":"user_reference/node_attributes/#locationu","title":"location.u","text":"Position in the rack of the node"},{"location":"user_reference/node_attributes/#net","title":"net","text":""},{"location":"user_reference/node_attributes/#netbootable","title":"net.bootable","text":"Whether or not the indicated network interface is to be used for booting.  This is used by the discovery process to decide where to place the mac address of a detected PXE nic."},{"location":"user_reference/node_attributes/#netconnection_name","title":"net.connection_name","text":"Name to use when specifiying a name for connection and/or interface name for a team.  This may be the name of a team interface, the connection name in network manager for the interface, or may be installed as an altname as supported by the respective OS deployment profiles.  Default is to accept default name for a team consistent with the respective OS, or to use the matching original port name as connection name."},{"location":"user_reference/node_attributes/#nethostname","title":"net.hostname","text":"Used to specify hostnames per interface. Can be a comma delimited list to indicate aliases"},{"location":"user_reference/node_attributes/#nethwaddr","title":"net.hwaddr","text":"The hardware address, aka MAC address of the interface indicated, generally populated by the PXE discovery mechanism"},{"location":"user_reference/node_attributes/#netinterface_names","title":"net.interface_names","text":"Interface name or comma delimited list of names to match for this interface. It is generally recommended to leave this blank unless needing to set up interfaces that are not on a common subnet with a confluent server, as confluent servers provide autodetection for matching the correct network definition to an interface. This would be the default name per the deployed OS and can be a comma delimited list to denote members of a team or a single interface for VLAN/PKEY connections."},{"location":"user_reference/node_attributes/#netipv4_address","title":"net.ipv4_address","text":"When configuring static, use this address.  If unspecified, it will check if the node name resolves to an IP address.  Additionally, the subnet prefix may be specified with a suffix, e.g. \"/16\".  If not specified, it will attempt to autodetect based on current network configuration."},{"location":"user_reference/node_attributes/#netipv4_gateway","title":"net.ipv4_gateway","text":"The IPv4 gateway to use if applicable.  As is the case for other net attributes, net.eth0.ipv4_gateway and similar is accepted."},{"location":"user_reference/node_attributes/#netipv4_method","title":"net.ipv4_method","text":"Whether to use static or dhcp when configuring this interface for IPv4. \"firmwaredhcp\" means to defer to external DHCP server during firmware execution, but use static for OS. \"firmwarenone\" means to suppress even the no-IP dhcp offers, to fully delegate to an external dhcp/pxe configuration, even for confluent deployment. Valid values: <code>dhcp</code>, <code>static</code>, <code>firmwaredhcp</code>, <code>firmwarenone</code>, <code>none</code>"},{"location":"user_reference/node_attributes/#netipv6_address","title":"net.ipv6_address","text":"When configuring static, use this address.  If unspecified, it will check if the node name resolves to an IP address.  Additionally, the subnet prefix may be specified with a suffix, e.g. \"/64\".  If not specified, it will attempt to autodetect based on current network configuration."},{"location":"user_reference/node_attributes/#netipv6_gateway","title":"net.ipv6_gateway","text":"The IPv6 gateway to use if applicable.  As is the case for other net attributes, net.eth0.ipv6_gateway and similar is accepted."},{"location":"user_reference/node_attributes/#netipv6_method","title":"net.ipv6_method","text":"Whether to use static or dhcp when configuring this interface for IPv6. \"firmwaredhcp\" means to defer to external DHCP server during firmware execution, but use static for OS. \"firmwarenone\" means to suppress even the no-IP dhcp offers, to fully delegate to an external dhcp/pxe configuration, even for confluent deployment Valid values: <code>dhcp</code>, <code>static</code>, <code>firmwaredhcp</code>, <code>firmwarenone</code>, <code>none</code>"},{"location":"user_reference/node_attributes/#netswitch","title":"net.switch","text":"An ethernet switch the node is connected to.  Note that net.* attributes may be indexed by interface. For example instead of using net.switch, it is possible to use net.eth0.switch and net.eth1.switch or net.0.switch and net.1.switch to define multiple sets of net connectivity associated with each other."},{"location":"user_reference/node_attributes/#netswitchport","title":"net.switchport","text":"The port on the switch that corresponds to this node. See information on net.switch for more on the flexibility of net.* attributes."},{"location":"user_reference/node_attributes/#netteam_mode","title":"net.team_mode","text":"Indicates that this interface should be a team and what mode or runner to use when teamed. If this covers a deployment interface, one of the member interfaces may be brought up as a standalone interface until deployment is complete, as supported by the OS deployment profile. To support this scenario, the switch should be set up to allow independent operation of member ports (e.g. lacp bypass mode or fallback mode). Valid values: <code>lacp</code>, <code>loadbalance</code>, <code>roundrobin</code>, <code>activebackup</code>, <code>none</code>"},{"location":"user_reference/node_attributes/#netvlan_id","title":"net.vlan_id","text":"Ethernet VLAN or InfiniBand PKEY to use for this connection. Specify the parent device using net.interface_names."},{"location":"user_reference/node_attributes/#ntp","title":"ntp","text":""},{"location":"user_reference/node_attributes/#ntpservers","title":"ntp.servers","text":"NTP server or servers to provide to node during deployment. An OS profile may default to internet NTP, depending on default configuration of the respective operating system"},{"location":"user_reference/node_attributes/#power","title":"power","text":""},{"location":"user_reference/node_attributes/#poweroutlet","title":"power.outlet","text":"Species the outlet identifier on the PDU associoted with a power input on the node"},{"location":"user_reference/node_attributes/#powerpdu","title":"power.pdu","text":"Specifies the managed PDU associated with a power input on the node"},{"location":"user_reference/node_attributes/#pubkeys","title":"pubkeys","text":""},{"location":"user_reference/node_attributes/#pubkeysaddpolicy","title":"pubkeys.addpolicy","text":"Policy to use when encountering unknown public keys.  Choices are \"automatic\" to accept and store new key if no key known and \"manual\" to always reject a new key, even if no key knownNote that if the trusted CA verifies the certificate, that is accepted ignoring this policy.  Default policy is \"automatic\" Valid values: <code>automatic</code>, <code>manual</code>"},{"location":"user_reference/node_attributes/#pubkeysssh","title":"pubkeys.ssh","text":"Fingerprint of the SSH key of the OS running on the system."},{"location":"user_reference/node_attributes/#pubkeystls","title":"pubkeys.tls","text":"Fingerprint of the TLS certificate for service running on host."},{"location":"user_reference/node_attributes/#pubkeystls_hardwaremanager","title":"pubkeys.tls_hardwaremanager","text":"Fingerprint of the TLS certificate recognized asbelonging to the hardware manager of the server"},{"location":"user_reference/node_attributes/#secret","title":"secret","text":""},{"location":"user_reference/node_attributes/#secrethardwaremanagementpassword","title":"secret.hardwaremanagementpassword","text":"Password to use when connecting to the hardware manager.  Aliases for this attribute include bmcpass and switchpass"},{"location":"user_reference/node_attributes/#secrethardwaremanagementuser","title":"secret.hardwaremanagementuser","text":"The username to use when connecting to the hardware manager. Aliases for this attribute include bmcuser and switchuser"},{"location":"user_reference/node_attributes/#secretipmikg","title":"secret.ipmikg","text":"Optional Integrity key for IPMI communication.  This should generally be ignored, as mutual authentication is normally done with the password alone (which is a shared secret in IPMI)"},{"location":"user_reference/node_attributes/#secretselfapiarmtoken","title":"secret.selfapiarmtoken","text":"A one-time use shared secret to authenticate a node api token"},{"location":"user_reference/node_attributes/#secretsnmpcommunity","title":"secret.snmpcommunity","text":"SNMPv1 community string, it is highly recommended tostep up to SNMPv3"},{"location":"user_reference/node_attributes/#ssh","title":"ssh","text":""},{"location":"user_reference/node_attributes/#sshtrustnodes","title":"ssh.trustnodes","text":"Nodes that are allowed to ssh into the node, expressed in noderange syntax.  This is used during deployment if the confluent SSH certificate authority is configured.  Default behavior is for all nodes to trust each other."},{"location":"user_reference/node_attributes/#trusted","title":"trusted","text":""},{"location":"user_reference/node_attributes/#trustedsubnets","title":"trusted.subnets","text":"Remote subnets in CIDR notation that should be considered as trusted as local networks"},{"location":"user_reference/node_attributes/#type","title":"type","text":""},{"location":"user_reference/node_attributes/#type_1","title":"type","text":"The type of node.  This may be switch, server, rackmount, dense, enclosure or not set to be generic. Valid values: <code>switch</code>, <code>server</code>, <code>rackmount</code>, <code>dense</code>, <code>enclosure</code>, <code></code>"},{"location":"user_reference/noderange/","title":"Noderange Syntax","text":"<p>Confluent implements a powerful language to indicate a target set of nodes.  It incorporates the concepts of ranged names, regular expression search, attribute criteria match, groups, and set arithmetic.</p> <p>The simplest noderange is a single node name:</p> <pre><code>n1\n</code></pre> <p>Nodes and groups may be used interchangeably.  The following may be used in any context where n1 would be accepted as a noderange:</p> <pre><code>rack1\n</code></pre> <p>Commonly, there is a desire to target a range of elements.  There are a few identically behaving syntaxes for the purpose.</p> <pre><code>n1:n20\nn1-n20\nn[1-20]\n</code></pre> <p>Note that numbers may be zero padded or not, it will automatically detect the padding amount and adjust members of the range accordingly.  Ranges also can understand multiple numeric values changing:</p> <pre><code>r[1-3]u[01-10]\nr1u01-r3u10\n</code></pre> <p>Ranges can also be applied to group names, and all above syntaxes are compatible:</p> <pre><code>rack1-rack10\nrack[1-10]\n</code></pre> <p>Also, regular expressions may be used to indicate nodes with names matching certain patterns:</p> <pre><code>~r1u..\n</code></pre> <p>The other major noderange primitive is indicating nodes by some attribute value:</p> <pre><code>location.rack=7\n</code></pre> <p>Commas can be used to indicate multiple nodes, and can mix and match any of the above primitives.  The following can be a valid single noderange, combining any and all members of each comma separated component</p> <pre><code>n1,n2,rack1,storage,location.rack=9,~s1..,n20-n30\n</code></pre> <p>Exclusions can be done by prepending a '-' before a portion of a noderange:</p> <pre><code>rack1,-n2\ncompute,-rack1\ncompute,-location.row=12\n</code></pre> <p>To indicate nodes that match multiple selections at once (set intersection), the @ symbol may be used:</p> <pre><code>compute@rack1\nlocation.rack=10@compute\n</code></pre> <p>For complex expressions, () may be used to indicate order of expanding the noderange to be explicit</p> <pre><code>rack1,-(console.logging=full@compute)\n</code></pre> <p>Noderange syntax can also indicate 'pagination', or separating the nodes into well defined chunks.  &gt; is used to indicate how many nodes to display at a time, and &lt; is used to indicate how many nodes to skip into a noderange:</p> <pre><code>rack1&gt;3&lt;6\n</code></pre> <p>The above would show the seventh through ninth nodes of the rack1 group.  Like all other noderange operations, this may be combined with any of the above, but must appear as the very last operation.  Ordering is done with a natural sort.</p>"},{"location":"user_reference/suse15deploy/","title":"OS Deployment Notes for SLE/SUSE 15","text":"<p>Note that if using xCAT and wanting to use the <code>reboot</code> postscript, it must be specified as in <code>postbootscripts</code> rather than <code>postscripts</code>.</p> <p>If executing genimage multiple times, it may be required to delete the image between runs. This is due to certain assumptions that, among other things, could erase /etc/passwd without recreating the pertinent accounts.</p>"},{"location":"user_reference/switchportattribs/","title":"Configuring network port attributes","text":"<p>In xCAT and confluent, the discovery process can use ethernet switch connectivity to assess real node identity to use in deploying configuration and gathering info such as mac addresses.</p> <p>Both support a variety of switches, using snmp v1/v2c/v3.  Using v3 is recommended where feasible.  In xCAT if using SNMPv1, you can indicate your community globally in site: <pre><code>chtab key=snmpc site.value=public\n</code></pre></p> <p>SNMPv3 and an alternative method to specify SNMPv1 is through the switches table:</p> <pre><code>nodegrpch switches switches.snmpversion=3 switches.username=snmp3user switches.password=Passw0rd12 switches.privacy=des switches.auth=sha\n</code></pre> <p>For confluent, the relevant attributes are <code>secret.hardwaremanagementuser</code> and <code>secret.hardwaremanagementpassword</code> for SNMPv3, and <code>secret.snmpcommunity</code> if SNMPv1.</p> <pre><code>nodegroupattrib switches secret.hardwaremanagementuser=snmp3user secret.hardwaremanagementpassword=Passw0rd12\n</code></pre> <p>Also in both cases, the software will try to determine the correct interface name from the given description.  For example, if the switch offers <code>Ethernet17</code>, then either the literal value <code>Ethernet17</code> or simply <code>17</code> will suffice.  However, caution is warranted when using breakout cables as you may do with a switch like a G8332 to connect 4 systems to a single QSFP port.  If you simply specify <code>3</code>, it would not only consider <code>Ethernet3</code> a match, but also <code>Ethernet1/3</code>, <code>Ethernet2/3</code>, and so forth.  In such a case, it is required to provide the full string <code>Ethernet3</code> to avoid confusion between breakout and non-breakout connections.  For the breakout connections, either <code>2/3</code> or <code>Ethernet2/3</code> would be valid values that are unambiguous.</p> <p>Note that in in confluent, the interface names that a particular switch uses can be found using the following command: <pre><code>confetty show /networking/macs/by-switch/&lt;switch name&gt;/by-port/\n</code></pre></p> <p>For xCAT, this values are in the <code>switch</code> table.  The following command is an example of setting the values for a single node:</p> <pre><code>nodech n1 switch.switch=switch1 switch.port=1\n</code></pre> <p>This can be set at a group level, leveraging formulaic expansion to indicate 42 nodes per switch connected sequentially (n1-n42 on switch1, n43-n84 on switch2, etc):</p> <pre><code>nodegrpch compute switch.switch='|switch(($1-1)/42+1)|' switch.port='|(($1-1)%42+1)|'\n</code></pre> <p>Note that in order to repeatedly count from 1 to 42 while skipping 0, the above arithmetic is required.  If the node naming scheme were r{rack}u{u}, an alternative may be:</p> <pre><code>nodegrpch compute switch.switch='|switch($1)|' switch.port='|($2)|'\n</code></pre> <p>To migrate this data to confluent, <code>makeconfluentcfg</code> will copy the data over.  Alternatively, the attribute names with confluent can be directly set as follows:</p> <pre><code>nodeattrib n1 net.switch=switch1 net.switchport=1\n</code></pre> <p>Additionally, if wanting to potentially indicate multiple interfaces and grouping the data together, you can elect to inject a network name of your choosing into the attribute:</p> <pre><code>nodeattrib n1 net.xcc.switch=mgtsw1 net.xcc.switchport=1\n</code></pre> <p>The same group inheritance and expansion is supported, albeit with a slightly different syntax:</p> <pre><code>nodegroupattrib compute net.switch=switch{(n1-1)/42+1} net.switchport={(n1-1)%42+1}\n</code></pre> <p>As with xCAT, a different name scheme can be used and extract distinct numbers from the name into different values:</p> <pre><code>nodegroupattrib compute net.switch=switch{n1} net.switchport={n2}\n</code></pre>"},{"location":"user_reference/thermalpowerconfluent/","title":"Power and Cooling Monitoring with Confluent","text":"<p>Confluent provides access to various power and cooling data on the monitored hardware. Here we will go through two general strategies to accessing the data, from a shell such as bash, or using an API (over the web, via python, or using the confetty CLI API browser).</p>"},{"location":"user_reference/thermalpowerconfluent/#from-a-shell","title":"From a shell","text":"<p>Exceptional thermal and power conditions warranting attention are provided by the <code>nodehealth</code> command, alongside conditions such as bad hardware components.</p> <pre><code># nodehealth n507\nn507: failed (Fan 1A Tach:0.0RPM,lower critical threshold,Fan 1B Tach:0.0RPM,lower critical threshold,Fan 2A Tach:0.0RPM,lower critical threshold,Fan 2B Tach:0.0RPM,lower critical threshold,Power Supply 1:Present,Failure,PS1 12Vaux Fault:Non-recoverable,Sys Boot Status:Boot error)\n</code></pre> <p>This may include fan failures, bad temperature conditions, performance impact due to throttling, and so on.</p> <p>For telemetry, the <code>nodesensors</code> command provides access to available power and cooling related data.  A key sensor of interest is the 'DC Energy' sensor:</p> <pre><code># nodesensors n1 dc_energy\nn1: DC Energy: 19.5191344589 kWh\n</code></pre> <p>Using this value before and after some interval enables you to know the  kilowatt hours have been consumed over that time.  You can use this information to calculate average power over an interval of your choosing.  For example, to know the average power before and after a 2 minute job (using sleep 120 as an example):</p> <pre><code># nodesensors -c -n 1 n1 dc_energy; sleep 120; nodesensors -c -n 1 n1 dc_energy\ntime,node,DC Energy (kWh)\n2016-10-17T10:39:37,n1,19.5271293078\ntime,node,DC Energy (kWh)\n2016-10-17T10:41:37,n1,19.5294681086\n</code></pre> <p>We take the difference in the kWh (0.0023388008) and divide by time elapsed in hours according to the timestamps (in bash, the timestamps may be subtracted):</p> <pre><code># echo $((`date -d 2016-10-17T10:41:37 +%s`-`date -d 2016-10-17T10:39:37 +%s`))\n120\n</code></pre> <p>So we can use the change in kWh divided by the interval in hours (dividing  seconds by 3600):</p> <pre><code># echo 'scale=3;0.0023388008/(120/3600.0)'|bc\n.070\n</code></pre> <p>This means the system used on average 0.070 kW (70 Watts) over the interval.</p> <p>Various other data is available under nodesensors.  For example, to retrieve all the temperature sensors in a system in CSV format over time for 5 seconds:</p> <pre><code># nodesensors n721 temperature -c -i 1 -n 5\ntime,node,Ambient Temp (\u00b0C),CPU 1 OverTemp,CPU 2 OverTemp,CPU1 Temp (\u00b0C),CPU1 VR OverTemp,CPU2 Temp (\u00b0C),CPU2 VR OverTemp,GPU Outlet Temp (\u00b0C),HDD Inlet Temp (\u00b0C),PCH Temp (\u00b0C),PCI 2 Temp,PCI 3 Temp,PCI 4 Temp,PCI 5 Temp,PCI Riser 1 Temp (\u00b0C),PCI Riser 2 Temp (\u00b0C),PIB Ambient Temp (\u00b0C),Riser1 8764 Temp (\u00b0C),Riser2 8764 Temp (\u00b0C)\n2016-10-17T11:28:07,n721,21.0,Ok,Ok,24.0,,26.0,,25.0,25.0,31.0,Ok,Ok,Ok,Ok,21.0,25.0,24.0,29.0,28.0\n2016-10-17T11:28:08,n721,21.0,Ok,Ok,24.0,,26.0,,25.0,25.0,31.0,Ok,Ok,Ok,Ok,21.0,25.0,24.0,29.0,28.0\n2016-10-17T11:28:09,n721,21.0,Ok,Ok,24.0,,26.0,,25.0,25.0,31.0,Ok,Ok,Ok,Ok,21.0,25.0,24.0,29.0,28.0\n2016-10-17T11:28:10,n721,21.0,Ok,Ok,24.0,,27.0,,25.0,25.0,31.0,Ok,Ok,Ok,Ok,21.0,25.0,24.0,29.0,28.0\n2016-10-17T11:28:11,n721,21.0,Ok,Ok,24.0,,27.0,,25.0,25.0,31.0,Ok,Ok,Ok,Ok,21.0,25.0,24.0,29.0,28.0\n</code></pre>"},{"location":"user_reference/thermalpowerconfluent/#using-the-api-python-or-web","title":"Using the API (python or web)","text":"<p>Live power and cooling data is available from confluent via the 'sensors' portion of the API.  See the API reference for a general introduction to general usage of the API.</p> <p>Specifically, the sensors of interest are under the <code>/sensors/hardware/temperature</code> and <code>/sensors/hardware/power</code> categories.  Here is an example using curl to illustrate retrieving a single temperature on a single system:</p> <pre><code># curl -u apiuser:apipassword http://localhost:4005/nodes/n721/sensors/hardware/temperature/cpu1_temp.json\n{\n    \"_links\": {\n    \"collection\": {\n        \"href\": \"./.json\"\n    }, \n    \"self\": {\n        \"href\": \"./cpu1_temp.json\"\n    }\n    }, \n    \"sensors\": [\n    {\n        \"health\": \"ok\", \n        \"name\": \"CPU1 Temp\", \n        \"state_ids\": [], \n        \"states\": [], \n        \"type\": \"Temperature\", \n        \"units\": \"\u00b0C\", \n        \"value\": 24.0\n    }\n    ]\n}\n</code></pre> <p>As in all the confluent API, a single bulk request can be done against a noderange:</p> <pre><code># curl -u apiuser:apipassword http://localhost:4005/noderange/n721-n723/sensors/hardware/temperature/cpu1_temp.json\n{\n    \"_links\": {\n    \"collection\": {\n        \"href\": \"./.json\"\n    }, \n    \"self\": {\n        \"href\": \"./cpu1_temp.json\"\n    }\n    }, \n    \"databynode\": [\n    {\n        \"n723\": {\n        \"error\": \"timeout\"\n        }\n    }, \n    {\n        \"n722\": {\n        \"sensors\": [\n            {\n            \"health\": \"ok\", \n            \"name\": \"CPU1 Temp\", \n            \"state_ids\": [], \n            \"states\": [], \n            \"type\": \"Temperature\", \n            \"units\": \"\u00b0C\", \n            \"value\": 27.0\n            }\n        ]\n        }\n    }, \n    {\n        \"n721\": {\n        \"sensors\": [\n            {\n            \"health\": \"ok\", \n            \"name\": \"CPU1 Temp\", \n            \"state_ids\": [], \n            \"states\": [], \n            \"type\": \"Temperature\", \n            \"units\": \"\u00b0C\", \n            \"value\": 24.0\n            }\n        ]\n        }\n    }\n    ]\n}\n</code></pre>"},{"location":"user_reference/ubuntudeploy/","title":"OS Deployment Notes for Ubuntu","text":"<p>Troubleshooting name resolution issues </p> <p>When the <code>nameserver</code> nodeattribute is set on a node/nodegroup and Ubuntu OS is deployed to the node(s), the Confluent server  will add the <code>nameserver</code> argument to all the interfaces that are configured in the <code>/etc/netplan</code> folder on the  managed node(s). If all the interfaces cannot reach the nameservers this might result in name resolution failures.  To fix this issue identify the interface that can reliably reach the <code>nameserver</code> and then remove the nameserver argument from all the other interfaces.</p> <p>Troubleshooting Network config issues</p> <p>Confluent server will setup up interface files in the <code>/etc/netplan</code> folder of the deployed node(s). In some cases the <code>00-installer-config.yaml</code> is set up in addition to the <code>{interface}-confluentcfg.yaml</code> files that Confluent sets up  when you deploy. Looking at the <code>00-installer-config.yaml</code> file, interfaces that are already defined by confluent will  also be defined in the installer conflig file. see example below: </p> <pre><code>root@n866:/etc/netplan# ls -l\ntotal 12\n-rw------- 1 root root 263 Aug 12 16:32 00-installer-config.yaml\n-rw------- 1 root root 265 Aug 12 16:35 eno1-confluentcfg.yaml\n-rw------- 1 root root 185 Aug 12 16:35 eno2-confluentcfg.yaml\n</code></pre> <p>when we read the <code>00-installer-config.yaml</code> file and the <code>eno1-confluentcfg.yaml</code> we will see that eno1 interface is  defined in both files. If you are having issues with the network on the node, we recommend removing the  <code>00-installer-config.yaml</code> file given that you have the right networking config in the interface file configured by  confluent. </p> <p>Note: The values set in the <code>{interface}-confluentcfg.yaml</code> file are retrieved from the nodeattributes set for that particular node</p>"},{"location":"user_reference/updatesw_rhel/","title":"Applying software updates to RedHat/CentOS","text":"<p>After adding the correct repository as indicated in the download page, you can update all the software provided by the repository using yum.  If you want to restrict updates only to the HPC related software, you may instruct yum to do so by:</p> <pre><code>yum --disablerepo=* --enablerepo=lenovo-hpc update\n</code></pre>"},{"location":"release_notes/archive/2025/","title":"2025","text":""},{"location":"release_notes/archive/2024/","title":"2024","text":""},{"location":"release_notes/archive/2023/","title":"2023","text":""},{"location":"release_notes/archive/2022/","title":"2022","text":""},{"location":"release_notes/archive/2021/","title":"2021","text":""},{"location":"release_notes/archive/2020/","title":"2020","text":""},{"location":"release_notes/archive/2019/","title":"2019","text":""},{"location":"release_notes/archive/2018/","title":"2018","text":""},{"location":"release_notes/archive/2017/","title":"2017","text":""},{"location":"release_notes/page/2/","title":"Release notes","text":""},{"location":"release_notes/page/3/","title":"Release notes","text":""}]}